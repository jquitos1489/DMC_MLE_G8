2025-10-09 01:44:44,806:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-09 01:44:44,806:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-09 01:44:44,806:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-09 01:44:44,806:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-09 01:49:46,336:INFO:PyCaret RegressionExperiment
2025-10-09 01:49:46,336:INFO:Logging name: reg-default-name
2025-10-09 01:49:46,337:INFO:ML Usecase: MLUsecase.REGRESSION
2025-10-09 01:49:46,338:INFO:version 3.3.2
2025-10-09 01:49:46,338:INFO:Initializing setup()
2025-10-09 01:49:46,339:INFO:self.USI: 62c8
2025-10-09 01:49:46,339:INFO:self._variable_keys: {'data', 'transform_target_param', '_ml_usecase', 'y_test', 'target_param', 'fold_generator', 'n_jobs_param', 'idx', 'fold_shuffle_param', 'pipeline', 'y', 'X_test', 'html_param', 'logging_param', 'gpu_n_jobs_param', 'gpu_param', 'exp_id', 'exp_name_log', 'fold_groups_param', 'X', 'X_train', '_available_plots', 'log_plots_param', 'y_train', 'seed', 'memory', 'USI'}
2025-10-09 01:49:46,339:INFO:Checking environment
2025-10-09 01:49:46,339:INFO:python_version: 3.11.0
2025-10-09 01:49:46,339:INFO:python_build: ('main', 'Oct 24 2022 18:26:48')
2025-10-09 01:49:46,339:INFO:machine: AMD64
2025-10-09 01:49:46,340:INFO:platform: Windows-10-10.0.19045-SP0
2025-10-09 01:49:46,346:INFO:Memory: svmem(total=12713988096, available=1446539264, percent=88.6, used=11267448832, free=1446539264)
2025-10-09 01:49:46,346:INFO:Physical Core: 4
2025-10-09 01:49:46,346:INFO:Logical Core: 8
2025-10-09 01:49:46,346:INFO:Checking libraries
2025-10-09 01:49:46,346:INFO:System:
2025-10-09 01:49:46,346:INFO:    python: 3.11.0 (main, Oct 24 2022, 18:26:48) [MSC v.1933 64 bit (AMD64)]
2025-10-09 01:49:46,346:INFO:executable: c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\python.exe
2025-10-09 01:49:46,346:INFO:   machine: Windows-10-10.0.19045-SP0
2025-10-09 01:49:46,346:INFO:PyCaret required dependencies:
2025-10-09 01:49:46,435:INFO:                 pip: 25.2
2025-10-09 01:49:46,435:INFO:          setuptools: 65.5.0
2025-10-09 01:49:46,436:INFO:             pycaret: 3.3.2
2025-10-09 01:49:46,436:INFO:             IPython: 9.6.0
2025-10-09 01:49:46,436:INFO:          ipywidgets: 8.1.7
2025-10-09 01:49:46,436:INFO:                tqdm: 4.67.1
2025-10-09 01:49:46,436:INFO:               numpy: 1.26.4
2025-10-09 01:49:46,436:INFO:              pandas: 2.1.4
2025-10-09 01:49:46,436:INFO:              jinja2: 3.1.6
2025-10-09 01:49:46,436:INFO:               scipy: 1.11.4
2025-10-09 01:49:46,436:INFO:              joblib: 1.3.2
2025-10-09 01:49:46,436:INFO:             sklearn: 1.4.2
2025-10-09 01:49:46,436:INFO:                pyod: 2.0.5
2025-10-09 01:49:46,436:INFO:            imblearn: 0.14.0
2025-10-09 01:49:46,436:INFO:   category_encoders: 2.7.0
2025-10-09 01:49:46,436:INFO:            lightgbm: 4.6.0
2025-10-09 01:49:46,436:INFO:               numba: 0.62.1
2025-10-09 01:49:46,436:INFO:            requests: 2.32.5
2025-10-09 01:49:46,436:INFO:          matplotlib: 3.7.5
2025-10-09 01:49:46,436:INFO:          scikitplot: 0.3.7
2025-10-09 01:49:46,436:INFO:         yellowbrick: 1.5
2025-10-09 01:49:46,436:INFO:              plotly: 6.3.1
2025-10-09 01:49:46,436:INFO:    plotly-resampler: Not installed
2025-10-09 01:49:46,436:INFO:             kaleido: 1.1.0
2025-10-09 01:49:46,436:INFO:           schemdraw: 0.15
2025-10-09 01:49:46,436:INFO:         statsmodels: 0.14.5
2025-10-09 01:49:46,436:INFO:              sktime: 0.26.0
2025-10-09 01:49:46,436:INFO:               tbats: 1.1.3
2025-10-09 01:49:46,436:INFO:            pmdarima: 2.0.4
2025-10-09 01:49:46,437:INFO:              psutil: 7.1.0
2025-10-09 01:49:46,437:INFO:          markupsafe: 3.0.3
2025-10-09 01:49:46,437:INFO:             pickle5: Not installed
2025-10-09 01:49:46,437:INFO:         cloudpickle: 3.1.1
2025-10-09 01:49:46,437:INFO:         deprecation: 2.1.0
2025-10-09 01:49:46,437:INFO:              xxhash: 3.6.0
2025-10-09 01:49:46,437:INFO:           wurlitzer: Not installed
2025-10-09 01:49:46,437:INFO:PyCaret optional dependencies:
2025-10-09 01:49:46,456:INFO:                shap: Not installed
2025-10-09 01:49:46,456:INFO:           interpret: Not installed
2025-10-09 01:49:46,456:INFO:                umap: Not installed
2025-10-09 01:49:46,456:INFO:     ydata_profiling: Not installed
2025-10-09 01:49:46,456:INFO:  explainerdashboard: Not installed
2025-10-09 01:49:46,456:INFO:             autoviz: Not installed
2025-10-09 01:49:46,456:INFO:           fairlearn: Not installed
2025-10-09 01:49:46,456:INFO:          deepchecks: Not installed
2025-10-09 01:49:46,456:INFO:             xgboost: Not installed
2025-10-09 01:49:46,456:INFO:            catboost: Not installed
2025-10-09 01:49:46,456:INFO:              kmodes: Not installed
2025-10-09 01:49:46,456:INFO:             mlxtend: Not installed
2025-10-09 01:49:46,456:INFO:       statsforecast: Not installed
2025-10-09 01:49:46,456:INFO:        tune_sklearn: Not installed
2025-10-09 01:49:46,457:INFO:                 ray: Not installed
2025-10-09 01:49:46,457:INFO:            hyperopt: Not installed
2025-10-09 01:49:46,457:INFO:              optuna: Not installed
2025-10-09 01:49:46,457:INFO:               skopt: Not installed
2025-10-09 01:49:46,457:INFO:              mlflow: Not installed
2025-10-09 01:49:46,457:INFO:              gradio: Not installed
2025-10-09 01:49:46,457:INFO:             fastapi: Not installed
2025-10-09 01:49:46,457:INFO:             uvicorn: Not installed
2025-10-09 01:49:46,457:INFO:              m2cgen: Not installed
2025-10-09 01:49:46,457:INFO:           evidently: Not installed
2025-10-09 01:49:46,457:INFO:               fugue: Not installed
2025-10-09 01:49:46,457:INFO:           streamlit: Not installed
2025-10-09 01:49:46,457:INFO:             prophet: Not installed
2025-10-09 01:49:46,457:INFO:None
2025-10-09 01:49:46,457:INFO:Set up data.
2025-10-09 01:49:46,472:INFO:Set up folding strategy.
2025-10-09 01:49:46,472:INFO:Set up train/test split.
2025-10-09 01:49:46,510:INFO:Set up index.
2025-10-09 01:49:46,511:INFO:Assigning column types.
2025-10-09 01:49:46,514:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-09 01:49:46,514:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-10-09 01:49:46,519:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-09 01:49:46,526:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-09 01:49:46,586:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-09 01:49:46,632:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-09 01:49:46,632:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 01:49:46,633:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 01:49:46,633:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-10-09 01:49:46,638:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-09 01:49:46,642:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-09 01:49:46,707:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-09 01:49:46,755:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-09 01:49:46,756:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 01:49:46,756:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 01:49:46,756:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-10-09 01:49:46,761:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-09 01:49:46,766:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-09 01:49:46,820:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-09 01:49:46,865:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-09 01:49:46,866:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 01:49:46,866:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 01:49:46,871:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-09 01:49:46,876:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-09 01:49:46,935:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-09 01:49:46,982:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-09 01:49:46,982:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 01:49:46,983:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 01:49:46,983:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-10-09 01:49:46,992:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-09 01:49:47,057:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-09 01:49:47,106:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-09 01:49:47,107:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 01:49:47,107:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 01:49:47,117:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-09 01:49:47,176:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-09 01:49:47,221:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-09 01:49:47,222:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 01:49:47,222:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 01:49:47,223:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-10-09 01:49:47,284:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-09 01:49:47,325:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-09 01:49:47,325:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 01:49:47,326:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 01:49:47,390:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-09 01:49:47,432:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-09 01:49:47,433:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 01:49:47,433:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 01:49:47,433:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-09 01:49:47,495:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-09 01:49:47,536:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 01:49:47,536:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 01:49:47,597:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-09 01:49:47,640:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 01:49:47,640:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 01:49:47,641:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-10-09 01:49:47,744:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 01:49:47,744:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 01:49:47,850:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 01:49:47,850:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 01:49:47,854:INFO:Preparing preprocessing pipeline...
2025-10-09 01:49:47,854:INFO:Set up simple imputation.
2025-10-09 01:49:47,862:INFO:Set up encoding of categorical features.
2025-10-09 01:49:47,862:INFO:Set up feature normalization.
2025-10-09 01:49:47,915:INFO:Finished creating preprocessing pipeline.
2025-10-09 01:49:47,923:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\jjqs_\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['area_m2', 'num_habitaciones',
                                             'num_banos', 'antiguedad_anos',
                                             'vista_mar'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['distrito'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['distrito'],
                                    transformer=OneHotEncoder(cols=['distrito'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2025-10-09 01:49:47,923:INFO:Creating final display dataframe.
2025-10-09 01:49:48,052:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            precio
2                   Target type        Regression
3           Original data shape          (100, 7)
4        Transformed data shape         (100, 10)
5   Transformed train set shape          (70, 10)
6    Transformed test set shape          (30, 10)
7              Numeric features                 5
8          Categorical features                 1
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                    Normalize              True
16             Normalize method            zscore
17               Fold Generator             KFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  reg-default-name
23                          USI              62c8
2025-10-09 01:49:48,179:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 01:49:48,180:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 01:49:48,284:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 01:49:48,285:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 01:49:48,285:INFO:setup() successfully completed in 1.96s...............
2025-10-09 01:55:33,704:INFO:Initializing compare_models()
2025-10-09 01:55:33,705:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B253D45090>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001B253D45090>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2025-10-09 01:55:33,705:INFO:Checking exceptions
2025-10-09 01:55:33,707:INFO:Preparing display monitor
2025-10-09 01:55:33,732:INFO:Initializing Linear Regression
2025-10-09 01:55:33,732:INFO:Total runtime is 0.0 minutes
2025-10-09 01:55:33,736:INFO:SubProcess create_model() called ==================================
2025-10-09 01:55:33,736:INFO:Initializing create_model()
2025-10-09 01:55:33,736:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B253D45090>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B251858950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 01:55:33,736:INFO:Checking exceptions
2025-10-09 01:55:33,737:INFO:Importing libraries
2025-10-09 01:55:33,737:INFO:Copying training dataset
2025-10-09 01:55:33,746:INFO:Defining folds
2025-10-09 01:55:33,747:INFO:Declaring metric variables
2025-10-09 01:55:33,753:INFO:Importing untrained model
2025-10-09 01:55:33,761:INFO:Linear Regression Imported successfully
2025-10-09 01:55:33,772:INFO:Starting cross validation
2025-10-09 01:55:33,785:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 01:55:42,879:INFO:Calculating mean and std
2025-10-09 01:55:42,880:INFO:Creating metrics dataframe
2025-10-09 01:55:42,883:INFO:Uploading results into container
2025-10-09 01:55:42,884:INFO:Uploading model into container now
2025-10-09 01:55:42,884:INFO:_master_model_container: 1
2025-10-09 01:55:42,884:INFO:_display_container: 2
2025-10-09 01:55:42,885:INFO:LinearRegression(n_jobs=-1)
2025-10-09 01:55:42,885:INFO:create_model() successfully completed......................................
2025-10-09 01:55:42,975:INFO:SubProcess create_model() end ==================================
2025-10-09 01:55:42,975:INFO:Creating metrics dataframe
2025-10-09 01:55:42,982:INFO:Initializing Lasso Regression
2025-10-09 01:55:42,982:INFO:Total runtime is 0.15416204929351807 minutes
2025-10-09 01:55:42,986:INFO:SubProcess create_model() called ==================================
2025-10-09 01:55:42,987:INFO:Initializing create_model()
2025-10-09 01:55:42,987:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B253D45090>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B251858950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 01:55:42,987:INFO:Checking exceptions
2025-10-09 01:55:42,987:INFO:Importing libraries
2025-10-09 01:55:42,987:INFO:Copying training dataset
2025-10-09 01:55:42,991:INFO:Defining folds
2025-10-09 01:55:42,991:INFO:Declaring metric variables
2025-10-09 01:55:42,996:INFO:Importing untrained model
2025-10-09 01:55:43,003:INFO:Lasso Regression Imported successfully
2025-10-09 01:55:43,014:INFO:Starting cross validation
2025-10-09 01:55:43,017:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 01:55:43,301:INFO:Calculating mean and std
2025-10-09 01:55:43,302:INFO:Creating metrics dataframe
2025-10-09 01:55:43,304:INFO:Uploading results into container
2025-10-09 01:55:43,305:INFO:Uploading model into container now
2025-10-09 01:55:43,306:INFO:_master_model_container: 2
2025-10-09 01:55:43,306:INFO:_display_container: 2
2025-10-09 01:55:43,306:INFO:Lasso(random_state=123)
2025-10-09 01:55:43,306:INFO:create_model() successfully completed......................................
2025-10-09 01:55:43,403:INFO:SubProcess create_model() end ==================================
2025-10-09 01:55:43,404:INFO:Creating metrics dataframe
2025-10-09 01:55:43,411:INFO:Initializing Ridge Regression
2025-10-09 01:55:43,411:INFO:Total runtime is 0.16132315397262573 minutes
2025-10-09 01:55:43,415:INFO:SubProcess create_model() called ==================================
2025-10-09 01:55:43,415:INFO:Initializing create_model()
2025-10-09 01:55:43,415:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B253D45090>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B251858950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 01:55:43,415:INFO:Checking exceptions
2025-10-09 01:55:43,415:INFO:Importing libraries
2025-10-09 01:55:43,415:INFO:Copying training dataset
2025-10-09 01:55:43,419:INFO:Defining folds
2025-10-09 01:55:43,420:INFO:Declaring metric variables
2025-10-09 01:55:43,423:INFO:Importing untrained model
2025-10-09 01:55:43,428:INFO:Ridge Regression Imported successfully
2025-10-09 01:55:43,436:INFO:Starting cross validation
2025-10-09 01:55:43,438:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 01:55:43,658:INFO:Calculating mean and std
2025-10-09 01:55:43,659:INFO:Creating metrics dataframe
2025-10-09 01:55:43,663:INFO:Uploading results into container
2025-10-09 01:55:43,663:INFO:Uploading model into container now
2025-10-09 01:55:43,664:INFO:_master_model_container: 3
2025-10-09 01:55:43,664:INFO:_display_container: 2
2025-10-09 01:55:43,664:INFO:Ridge(random_state=123)
2025-10-09 01:55:43,665:INFO:create_model() successfully completed......................................
2025-10-09 01:55:43,738:INFO:SubProcess create_model() end ==================================
2025-10-09 01:55:43,738:INFO:Creating metrics dataframe
2025-10-09 01:55:43,745:INFO:Initializing Elastic Net
2025-10-09 01:55:43,745:INFO:Total runtime is 0.1668904383977254 minutes
2025-10-09 01:55:43,748:INFO:SubProcess create_model() called ==================================
2025-10-09 01:55:43,748:INFO:Initializing create_model()
2025-10-09 01:55:43,748:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B253D45090>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B251858950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 01:55:43,748:INFO:Checking exceptions
2025-10-09 01:55:43,749:INFO:Importing libraries
2025-10-09 01:55:43,749:INFO:Copying training dataset
2025-10-09 01:55:43,753:INFO:Defining folds
2025-10-09 01:55:43,753:INFO:Declaring metric variables
2025-10-09 01:55:43,756:INFO:Importing untrained model
2025-10-09 01:55:43,760:INFO:Elastic Net Imported successfully
2025-10-09 01:55:43,770:INFO:Starting cross validation
2025-10-09 01:55:43,772:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 01:55:43,943:INFO:Calculating mean and std
2025-10-09 01:55:43,943:INFO:Creating metrics dataframe
2025-10-09 01:55:43,946:INFO:Uploading results into container
2025-10-09 01:55:43,947:INFO:Uploading model into container now
2025-10-09 01:55:43,947:INFO:_master_model_container: 4
2025-10-09 01:55:43,947:INFO:_display_container: 2
2025-10-09 01:55:43,948:INFO:ElasticNet(random_state=123)
2025-10-09 01:55:43,948:INFO:create_model() successfully completed......................................
2025-10-09 01:55:44,019:INFO:SubProcess create_model() end ==================================
2025-10-09 01:55:44,020:INFO:Creating metrics dataframe
2025-10-09 01:55:44,026:INFO:Initializing Least Angle Regression
2025-10-09 01:55:44,026:INFO:Total runtime is 0.17157490253448485 minutes
2025-10-09 01:55:44,030:INFO:SubProcess create_model() called ==================================
2025-10-09 01:55:44,030:INFO:Initializing create_model()
2025-10-09 01:55:44,030:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B253D45090>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B251858950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 01:55:44,030:INFO:Checking exceptions
2025-10-09 01:55:44,030:INFO:Importing libraries
2025-10-09 01:55:44,030:INFO:Copying training dataset
2025-10-09 01:55:44,034:INFO:Defining folds
2025-10-09 01:55:44,034:INFO:Declaring metric variables
2025-10-09 01:55:44,037:INFO:Importing untrained model
2025-10-09 01:55:44,040:INFO:Least Angle Regression Imported successfully
2025-10-09 01:55:44,047:INFO:Starting cross validation
2025-10-09 01:55:44,049:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 01:55:44,231:INFO:Calculating mean and std
2025-10-09 01:55:44,232:INFO:Creating metrics dataframe
2025-10-09 01:55:44,234:INFO:Uploading results into container
2025-10-09 01:55:44,234:INFO:Uploading model into container now
2025-10-09 01:55:44,235:INFO:_master_model_container: 5
2025-10-09 01:55:44,235:INFO:_display_container: 2
2025-10-09 01:55:44,235:INFO:Lars(random_state=123)
2025-10-09 01:55:44,235:INFO:create_model() successfully completed......................................
2025-10-09 01:55:44,312:INFO:SubProcess create_model() end ==================================
2025-10-09 01:55:44,312:INFO:Creating metrics dataframe
2025-10-09 01:55:44,320:INFO:Initializing Lasso Least Angle Regression
2025-10-09 01:55:44,320:INFO:Total runtime is 0.1764758547147115 minutes
2025-10-09 01:55:44,323:INFO:SubProcess create_model() called ==================================
2025-10-09 01:55:44,323:INFO:Initializing create_model()
2025-10-09 01:55:44,324:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B253D45090>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B251858950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 01:55:44,324:INFO:Checking exceptions
2025-10-09 01:55:44,324:INFO:Importing libraries
2025-10-09 01:55:44,324:INFO:Copying training dataset
2025-10-09 01:55:44,328:INFO:Defining folds
2025-10-09 01:55:44,328:INFO:Declaring metric variables
2025-10-09 01:55:44,331:INFO:Importing untrained model
2025-10-09 01:55:44,335:INFO:Lasso Least Angle Regression Imported successfully
2025-10-09 01:55:44,346:INFO:Starting cross validation
2025-10-09 01:55:44,349:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 01:55:44,541:INFO:Calculating mean and std
2025-10-09 01:55:44,542:INFO:Creating metrics dataframe
2025-10-09 01:55:44,544:INFO:Uploading results into container
2025-10-09 01:55:44,545:INFO:Uploading model into container now
2025-10-09 01:55:44,545:INFO:_master_model_container: 6
2025-10-09 01:55:44,545:INFO:_display_container: 2
2025-10-09 01:55:44,546:INFO:LassoLars(random_state=123)
2025-10-09 01:55:44,546:INFO:create_model() successfully completed......................................
2025-10-09 01:55:44,635:INFO:SubProcess create_model() end ==================================
2025-10-09 01:55:44,635:INFO:Creating metrics dataframe
2025-10-09 01:55:44,645:INFO:Initializing Orthogonal Matching Pursuit
2025-10-09 01:55:44,645:INFO:Total runtime is 0.1818849484125773 minutes
2025-10-09 01:55:44,649:INFO:SubProcess create_model() called ==================================
2025-10-09 01:55:44,650:INFO:Initializing create_model()
2025-10-09 01:55:44,650:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B253D45090>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B251858950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 01:55:44,650:INFO:Checking exceptions
2025-10-09 01:55:44,650:INFO:Importing libraries
2025-10-09 01:55:44,650:INFO:Copying training dataset
2025-10-09 01:55:44,654:INFO:Defining folds
2025-10-09 01:55:44,655:INFO:Declaring metric variables
2025-10-09 01:55:44,659:INFO:Importing untrained model
2025-10-09 01:55:44,665:INFO:Orthogonal Matching Pursuit Imported successfully
2025-10-09 01:55:44,679:INFO:Starting cross validation
2025-10-09 01:55:44,680:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 01:55:44,874:INFO:Calculating mean and std
2025-10-09 01:55:44,874:INFO:Creating metrics dataframe
2025-10-09 01:55:44,877:INFO:Uploading results into container
2025-10-09 01:55:44,877:INFO:Uploading model into container now
2025-10-09 01:55:44,878:INFO:_master_model_container: 7
2025-10-09 01:55:44,878:INFO:_display_container: 2
2025-10-09 01:55:44,878:INFO:OrthogonalMatchingPursuit()
2025-10-09 01:55:44,878:INFO:create_model() successfully completed......................................
2025-10-09 01:55:44,954:INFO:SubProcess create_model() end ==================================
2025-10-09 01:55:44,954:INFO:Creating metrics dataframe
2025-10-09 01:55:44,961:INFO:Initializing Bayesian Ridge
2025-10-09 01:55:44,961:INFO:Total runtime is 0.18714412053426105 minutes
2025-10-09 01:55:44,964:INFO:SubProcess create_model() called ==================================
2025-10-09 01:55:44,965:INFO:Initializing create_model()
2025-10-09 01:55:44,965:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B253D45090>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B251858950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 01:55:44,965:INFO:Checking exceptions
2025-10-09 01:55:44,965:INFO:Importing libraries
2025-10-09 01:55:44,965:INFO:Copying training dataset
2025-10-09 01:55:44,970:INFO:Defining folds
2025-10-09 01:55:44,970:INFO:Declaring metric variables
2025-10-09 01:55:44,974:INFO:Importing untrained model
2025-10-09 01:55:44,979:INFO:Bayesian Ridge Imported successfully
2025-10-09 01:55:44,990:INFO:Starting cross validation
2025-10-09 01:55:44,992:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 01:55:45,179:INFO:Calculating mean and std
2025-10-09 01:55:45,179:INFO:Creating metrics dataframe
2025-10-09 01:55:45,182:INFO:Uploading results into container
2025-10-09 01:55:45,183:INFO:Uploading model into container now
2025-10-09 01:55:45,183:INFO:_master_model_container: 8
2025-10-09 01:55:45,183:INFO:_display_container: 2
2025-10-09 01:55:45,184:INFO:BayesianRidge()
2025-10-09 01:55:45,184:INFO:create_model() successfully completed......................................
2025-10-09 01:55:45,260:INFO:SubProcess create_model() end ==================================
2025-10-09 01:55:45,260:INFO:Creating metrics dataframe
2025-10-09 01:55:45,268:INFO:Initializing Passive Aggressive Regressor
2025-10-09 01:55:45,268:INFO:Total runtime is 0.1922607898712158 minutes
2025-10-09 01:55:45,272:INFO:SubProcess create_model() called ==================================
2025-10-09 01:55:45,272:INFO:Initializing create_model()
2025-10-09 01:55:45,272:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B253D45090>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B251858950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 01:55:45,272:INFO:Checking exceptions
2025-10-09 01:55:45,272:INFO:Importing libraries
2025-10-09 01:55:45,273:INFO:Copying training dataset
2025-10-09 01:55:45,276:INFO:Defining folds
2025-10-09 01:55:45,276:INFO:Declaring metric variables
2025-10-09 01:55:45,279:INFO:Importing untrained model
2025-10-09 01:55:45,283:INFO:Passive Aggressive Regressor Imported successfully
2025-10-09 01:55:45,293:INFO:Starting cross validation
2025-10-09 01:55:45,295:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 01:55:45,378:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-10-09 01:55:45,379:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-10-09 01:55:45,380:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-10-09 01:55:45,381:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-10-09 01:55:45,384:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-10-09 01:55:45,389:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-10-09 01:55:45,398:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-10-09 01:55:45,428:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-10-09 01:55:45,463:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-10-09 01:55:45,469:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-10-09 01:55:45,503:INFO:Calculating mean and std
2025-10-09 01:55:45,503:INFO:Creating metrics dataframe
2025-10-09 01:55:45,506:INFO:Uploading results into container
2025-10-09 01:55:45,506:INFO:Uploading model into container now
2025-10-09 01:55:45,507:INFO:_master_model_container: 9
2025-10-09 01:55:45,507:INFO:_display_container: 2
2025-10-09 01:55:45,507:INFO:PassiveAggressiveRegressor(random_state=123)
2025-10-09 01:55:45,508:INFO:create_model() successfully completed......................................
2025-10-09 01:55:45,589:INFO:SubProcess create_model() end ==================================
2025-10-09 01:55:45,590:INFO:Creating metrics dataframe
2025-10-09 01:55:45,599:INFO:Initializing Huber Regressor
2025-10-09 01:55:45,599:INFO:Total runtime is 0.19777796268463133 minutes
2025-10-09 01:55:45,603:INFO:SubProcess create_model() called ==================================
2025-10-09 01:55:45,603:INFO:Initializing create_model()
2025-10-09 01:55:45,603:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B253D45090>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B251858950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 01:55:45,603:INFO:Checking exceptions
2025-10-09 01:55:45,603:INFO:Importing libraries
2025-10-09 01:55:45,603:INFO:Copying training dataset
2025-10-09 01:55:45,607:INFO:Defining folds
2025-10-09 01:55:45,607:INFO:Declaring metric variables
2025-10-09 01:55:45,610:INFO:Importing untrained model
2025-10-09 01:55:45,626:INFO:Huber Regressor Imported successfully
2025-10-09 01:55:45,657:INFO:Starting cross validation
2025-10-09 01:55:45,658:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 01:55:45,881:INFO:Calculating mean and std
2025-10-09 01:55:45,881:INFO:Creating metrics dataframe
2025-10-09 01:55:45,884:INFO:Uploading results into container
2025-10-09 01:55:45,885:INFO:Uploading model into container now
2025-10-09 01:55:45,885:INFO:_master_model_container: 10
2025-10-09 01:55:45,885:INFO:_display_container: 2
2025-10-09 01:55:45,886:INFO:HuberRegressor()
2025-10-09 01:55:45,886:INFO:create_model() successfully completed......................................
2025-10-09 01:55:45,971:INFO:SubProcess create_model() end ==================================
2025-10-09 01:55:45,971:INFO:Creating metrics dataframe
2025-10-09 01:55:45,983:INFO:Initializing K Neighbors Regressor
2025-10-09 01:55:45,983:INFO:Total runtime is 0.2041789611180623 minutes
2025-10-09 01:55:45,987:INFO:SubProcess create_model() called ==================================
2025-10-09 01:55:45,988:INFO:Initializing create_model()
2025-10-09 01:55:45,988:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B253D45090>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B251858950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 01:55:45,988:INFO:Checking exceptions
2025-10-09 01:55:45,988:INFO:Importing libraries
2025-10-09 01:55:45,988:INFO:Copying training dataset
2025-10-09 01:55:45,992:INFO:Defining folds
2025-10-09 01:55:45,992:INFO:Declaring metric variables
2025-10-09 01:55:45,996:INFO:Importing untrained model
2025-10-09 01:55:46,001:INFO:K Neighbors Regressor Imported successfully
2025-10-09 01:55:46,012:INFO:Starting cross validation
2025-10-09 01:55:46,015:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 01:55:46,285:INFO:Calculating mean and std
2025-10-09 01:55:46,285:INFO:Creating metrics dataframe
2025-10-09 01:55:46,287:INFO:Uploading results into container
2025-10-09 01:55:46,288:INFO:Uploading model into container now
2025-10-09 01:55:46,288:INFO:_master_model_container: 11
2025-10-09 01:55:46,288:INFO:_display_container: 2
2025-10-09 01:55:46,288:INFO:KNeighborsRegressor(n_jobs=-1)
2025-10-09 01:55:46,289:INFO:create_model() successfully completed......................................
2025-10-09 01:55:46,358:INFO:SubProcess create_model() end ==================================
2025-10-09 01:55:46,358:INFO:Creating metrics dataframe
2025-10-09 01:55:46,366:INFO:Initializing Decision Tree Regressor
2025-10-09 01:55:46,366:INFO:Total runtime is 0.21057445208231604 minutes
2025-10-09 01:55:46,370:INFO:SubProcess create_model() called ==================================
2025-10-09 01:55:46,370:INFO:Initializing create_model()
2025-10-09 01:55:46,370:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B253D45090>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B251858950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 01:55:46,370:INFO:Checking exceptions
2025-10-09 01:55:46,370:INFO:Importing libraries
2025-10-09 01:55:46,370:INFO:Copying training dataset
2025-10-09 01:55:46,373:INFO:Defining folds
2025-10-09 01:55:46,373:INFO:Declaring metric variables
2025-10-09 01:55:46,376:INFO:Importing untrained model
2025-10-09 01:55:46,379:INFO:Decision Tree Regressor Imported successfully
2025-10-09 01:55:46,386:INFO:Starting cross validation
2025-10-09 01:55:46,388:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 01:55:46,581:INFO:Calculating mean and std
2025-10-09 01:55:46,582:INFO:Creating metrics dataframe
2025-10-09 01:55:46,587:INFO:Uploading results into container
2025-10-09 01:55:46,587:INFO:Uploading model into container now
2025-10-09 01:55:46,588:INFO:_master_model_container: 12
2025-10-09 01:55:46,588:INFO:_display_container: 2
2025-10-09 01:55:46,589:INFO:DecisionTreeRegressor(random_state=123)
2025-10-09 01:55:46,589:INFO:create_model() successfully completed......................................
2025-10-09 01:55:46,683:INFO:SubProcess create_model() end ==================================
2025-10-09 01:55:46,684:INFO:Creating metrics dataframe
2025-10-09 01:55:46,695:INFO:Initializing Random Forest Regressor
2025-10-09 01:55:46,721:INFO:Total runtime is 0.21649221579233802 minutes
2025-10-09 01:55:46,726:INFO:SubProcess create_model() called ==================================
2025-10-09 01:55:46,726:INFO:Initializing create_model()
2025-10-09 01:55:46,726:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B253D45090>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B251858950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 01:55:46,726:INFO:Checking exceptions
2025-10-09 01:55:46,726:INFO:Importing libraries
2025-10-09 01:55:46,726:INFO:Copying training dataset
2025-10-09 01:55:46,731:INFO:Defining folds
2025-10-09 01:55:46,732:INFO:Declaring metric variables
2025-10-09 01:55:46,735:INFO:Importing untrained model
2025-10-09 01:55:46,746:INFO:Random Forest Regressor Imported successfully
2025-10-09 01:55:46,757:INFO:Starting cross validation
2025-10-09 01:55:46,759:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 01:55:47,469:INFO:Calculating mean and std
2025-10-09 01:55:47,470:INFO:Creating metrics dataframe
2025-10-09 01:55:47,471:INFO:Uploading results into container
2025-10-09 01:55:47,472:INFO:Uploading model into container now
2025-10-09 01:55:47,473:INFO:_master_model_container: 13
2025-10-09 01:55:47,473:INFO:_display_container: 2
2025-10-09 01:55:47,473:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-10-09 01:55:47,473:INFO:create_model() successfully completed......................................
2025-10-09 01:55:47,546:INFO:SubProcess create_model() end ==================================
2025-10-09 01:55:47,546:INFO:Creating metrics dataframe
2025-10-09 01:55:47,554:INFO:Initializing Extra Trees Regressor
2025-10-09 01:55:47,554:INFO:Total runtime is 0.23037025531133012 minutes
2025-10-09 01:55:47,558:INFO:SubProcess create_model() called ==================================
2025-10-09 01:55:47,558:INFO:Initializing create_model()
2025-10-09 01:55:47,559:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B253D45090>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B251858950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 01:55:47,559:INFO:Checking exceptions
2025-10-09 01:55:47,559:INFO:Importing libraries
2025-10-09 01:55:47,559:INFO:Copying training dataset
2025-10-09 01:55:47,562:INFO:Defining folds
2025-10-09 01:55:47,563:INFO:Declaring metric variables
2025-10-09 01:55:47,565:INFO:Importing untrained model
2025-10-09 01:55:47,568:INFO:Extra Trees Regressor Imported successfully
2025-10-09 01:55:47,578:INFO:Starting cross validation
2025-10-09 01:55:47,579:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 01:55:48,113:INFO:Calculating mean and std
2025-10-09 01:55:48,113:INFO:Creating metrics dataframe
2025-10-09 01:55:48,115:INFO:Uploading results into container
2025-10-09 01:55:48,116:INFO:Uploading model into container now
2025-10-09 01:55:48,116:INFO:_master_model_container: 14
2025-10-09 01:55:48,117:INFO:_display_container: 2
2025-10-09 01:55:48,117:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-10-09 01:55:48,117:INFO:create_model() successfully completed......................................
2025-10-09 01:55:48,211:INFO:SubProcess create_model() end ==================================
2025-10-09 01:55:48,211:INFO:Creating metrics dataframe
2025-10-09 01:55:48,222:INFO:Initializing AdaBoost Regressor
2025-10-09 01:55:48,222:INFO:Total runtime is 0.2414954304695129 minutes
2025-10-09 01:55:48,227:INFO:SubProcess create_model() called ==================================
2025-10-09 01:55:48,227:INFO:Initializing create_model()
2025-10-09 01:55:48,227:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B253D45090>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B251858950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 01:55:48,228:INFO:Checking exceptions
2025-10-09 01:55:48,228:INFO:Importing libraries
2025-10-09 01:55:48,228:INFO:Copying training dataset
2025-10-09 01:55:48,233:INFO:Defining folds
2025-10-09 01:55:48,233:INFO:Declaring metric variables
2025-10-09 01:55:48,238:INFO:Importing untrained model
2025-10-09 01:55:48,242:INFO:AdaBoost Regressor Imported successfully
2025-10-09 01:55:48,259:INFO:Starting cross validation
2025-10-09 01:55:48,262:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 01:55:49,022:INFO:Calculating mean and std
2025-10-09 01:55:49,023:INFO:Creating metrics dataframe
2025-10-09 01:55:49,028:INFO:Uploading results into container
2025-10-09 01:55:49,029:INFO:Uploading model into container now
2025-10-09 01:55:49,030:INFO:_master_model_container: 15
2025-10-09 01:55:49,030:INFO:_display_container: 2
2025-10-09 01:55:49,030:INFO:AdaBoostRegressor(random_state=123)
2025-10-09 01:55:49,031:INFO:create_model() successfully completed......................................
2025-10-09 01:55:49,151:INFO:SubProcess create_model() end ==================================
2025-10-09 01:55:49,151:INFO:Creating metrics dataframe
2025-10-09 01:55:49,162:INFO:Initializing Gradient Boosting Regressor
2025-10-09 01:55:49,162:INFO:Total runtime is 0.25716277360916134 minutes
2025-10-09 01:55:49,168:INFO:SubProcess create_model() called ==================================
2025-10-09 01:55:49,168:INFO:Initializing create_model()
2025-10-09 01:55:49,168:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B253D45090>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B251858950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 01:55:49,168:INFO:Checking exceptions
2025-10-09 01:55:49,168:INFO:Importing libraries
2025-10-09 01:55:49,168:INFO:Copying training dataset
2025-10-09 01:55:49,174:INFO:Defining folds
2025-10-09 01:55:49,174:INFO:Declaring metric variables
2025-10-09 01:55:49,180:INFO:Importing untrained model
2025-10-09 01:55:49,186:INFO:Gradient Boosting Regressor Imported successfully
2025-10-09 01:55:49,201:INFO:Starting cross validation
2025-10-09 01:55:49,204:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 01:55:49,707:INFO:Calculating mean and std
2025-10-09 01:55:49,709:INFO:Creating metrics dataframe
2025-10-09 01:55:49,712:INFO:Uploading results into container
2025-10-09 01:55:49,713:INFO:Uploading model into container now
2025-10-09 01:55:49,713:INFO:_master_model_container: 16
2025-10-09 01:55:49,713:INFO:_display_container: 2
2025-10-09 01:55:49,714:INFO:GradientBoostingRegressor(random_state=123)
2025-10-09 01:55:49,714:INFO:create_model() successfully completed......................................
2025-10-09 01:55:49,816:INFO:SubProcess create_model() end ==================================
2025-10-09 01:55:49,816:INFO:Creating metrics dataframe
2025-10-09 01:55:49,825:INFO:Initializing Light Gradient Boosting Machine
2025-10-09 01:55:49,825:INFO:Total runtime is 0.2682109912236531 minutes
2025-10-09 01:55:49,828:INFO:SubProcess create_model() called ==================================
2025-10-09 01:55:49,828:INFO:Initializing create_model()
2025-10-09 01:55:49,829:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B253D45090>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B251858950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 01:55:49,829:INFO:Checking exceptions
2025-10-09 01:55:49,829:INFO:Importing libraries
2025-10-09 01:55:49,829:INFO:Copying training dataset
2025-10-09 01:55:49,833:INFO:Defining folds
2025-10-09 01:55:49,833:INFO:Declaring metric variables
2025-10-09 01:55:49,837:INFO:Importing untrained model
2025-10-09 01:55:49,841:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-09 01:55:49,849:INFO:Starting cross validation
2025-10-09 01:55:49,851:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 01:55:50,299:INFO:Calculating mean and std
2025-10-09 01:55:50,301:INFO:Creating metrics dataframe
2025-10-09 01:55:50,303:INFO:Uploading results into container
2025-10-09 01:55:50,305:INFO:Uploading model into container now
2025-10-09 01:55:50,306:INFO:_master_model_container: 17
2025-10-09 01:55:50,306:INFO:_display_container: 2
2025-10-09 01:55:50,307:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-10-09 01:55:50,307:INFO:create_model() successfully completed......................................
2025-10-09 01:55:50,403:INFO:SubProcess create_model() end ==================================
2025-10-09 01:55:50,403:INFO:Creating metrics dataframe
2025-10-09 01:55:50,413:INFO:Initializing Dummy Regressor
2025-10-09 01:55:50,413:INFO:Total runtime is 0.27802195151646925 minutes
2025-10-09 01:55:50,417:INFO:SubProcess create_model() called ==================================
2025-10-09 01:55:50,417:INFO:Initializing create_model()
2025-10-09 01:55:50,417:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B253D45090>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B251858950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 01:55:50,418:INFO:Checking exceptions
2025-10-09 01:55:50,418:INFO:Importing libraries
2025-10-09 01:55:50,418:INFO:Copying training dataset
2025-10-09 01:55:50,422:INFO:Defining folds
2025-10-09 01:55:50,422:INFO:Declaring metric variables
2025-10-09 01:55:50,426:INFO:Importing untrained model
2025-10-09 01:55:50,430:INFO:Dummy Regressor Imported successfully
2025-10-09 01:55:50,440:INFO:Starting cross validation
2025-10-09 01:55:50,442:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 01:55:50,735:INFO:Calculating mean and std
2025-10-09 01:55:50,738:INFO:Creating metrics dataframe
2025-10-09 01:55:50,745:INFO:Uploading results into container
2025-10-09 01:55:50,747:INFO:Uploading model into container now
2025-10-09 01:55:50,747:INFO:_master_model_container: 18
2025-10-09 01:55:50,747:INFO:_display_container: 2
2025-10-09 01:55:50,748:INFO:DummyRegressor()
2025-10-09 01:55:50,748:INFO:create_model() successfully completed......................................
2025-10-09 01:55:50,909:INFO:SubProcess create_model() end ==================================
2025-10-09 01:55:50,909:INFO:Creating metrics dataframe
2025-10-09 01:55:50,929:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-10-09 01:55:50,940:INFO:Initializing create_model()
2025-10-09 01:55:50,940:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B253D45090>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 01:55:50,940:INFO:Checking exceptions
2025-10-09 01:55:50,943:INFO:Importing libraries
2025-10-09 01:55:50,943:INFO:Copying training dataset
2025-10-09 01:55:50,947:INFO:Defining folds
2025-10-09 01:55:50,948:INFO:Declaring metric variables
2025-10-09 01:55:50,948:INFO:Importing untrained model
2025-10-09 01:55:50,948:INFO:Declaring custom model
2025-10-09 01:55:50,948:INFO:Linear Regression Imported successfully
2025-10-09 01:55:50,949:INFO:Cross validation set to False
2025-10-09 01:55:50,949:INFO:Fitting Model
2025-10-09 01:55:50,997:INFO:LinearRegression(n_jobs=-1)
2025-10-09 01:55:50,997:INFO:create_model() successfully completed......................................
2025-10-09 01:55:51,103:INFO:_master_model_container: 18
2025-10-09 01:55:51,104:INFO:_display_container: 2
2025-10-09 01:55:51,104:INFO:LinearRegression(n_jobs=-1)
2025-10-09 01:55:51,104:INFO:compare_models() successfully completed......................................
2025-10-09 02:04:33,287:INFO:Initializing create_model()
2025-10-09 02:04:33,287:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B253D45090>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:04:33,287:INFO:Checking exceptions
2025-10-09 02:04:33,304:INFO:Importing libraries
2025-10-09 02:04:33,304:INFO:Copying training dataset
2025-10-09 02:04:33,309:INFO:Defining folds
2025-10-09 02:04:33,309:INFO:Declaring metric variables
2025-10-09 02:04:33,312:INFO:Importing untrained model
2025-10-09 02:04:33,317:INFO:Linear Regression Imported successfully
2025-10-09 02:04:33,326:INFO:Starting cross validation
2025-10-09 02:04:33,329:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:04:42,799:INFO:Calculating mean and std
2025-10-09 02:04:42,801:INFO:Creating metrics dataframe
2025-10-09 02:04:42,807:INFO:Finalizing model
2025-10-09 02:04:42,862:INFO:Uploading results into container
2025-10-09 02:04:42,863:INFO:Uploading model into container now
2025-10-09 02:04:42,875:INFO:_master_model_container: 19
2025-10-09 02:04:42,876:INFO:_display_container: 3
2025-10-09 02:04:42,876:INFO:LinearRegression(n_jobs=-1)
2025-10-09 02:04:42,876:INFO:create_model() successfully completed......................................
2025-10-09 02:06:32,096:INFO:Initializing tune_model()
2025-10-09 02:06:32,096:INFO:tune_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B253D45090>, estimator=LinearRegression(n_jobs=-1), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-10-09 02:06:32,096:INFO:Checking exceptions
2025-10-09 02:06:32,116:INFO:Copying training dataset
2025-10-09 02:06:32,119:INFO:Checking base model
2025-10-09 02:06:32,120:INFO:Base model : Linear Regression
2025-10-09 02:06:32,125:INFO:Declaring metric variables
2025-10-09 02:06:32,133:INFO:Defining Hyperparameters
2025-10-09 02:06:32,134:INFO:10 is bigger than total combinations 2, setting search algorithm to grid
2025-10-09 02:06:32,275:INFO:Tuning with n_jobs=-1
2025-10-09 02:06:32,275:INFO:Initializing GridSearchCV
2025-10-09 02:06:32,732:INFO:best_params: {'actual_estimator__fit_intercept': True}
2025-10-09 02:06:32,732:INFO:Hyperparameter search completed
2025-10-09 02:06:32,732:INFO:SubProcess create_model() called ==================================
2025-10-09 02:06:32,733:INFO:Initializing create_model()
2025-10-09 02:06:32,733:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B253D45090>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B25305FF10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'fit_intercept': True})
2025-10-09 02:06:32,733:INFO:Checking exceptions
2025-10-09 02:06:32,733:INFO:Importing libraries
2025-10-09 02:06:32,733:INFO:Copying training dataset
2025-10-09 02:06:32,737:INFO:Defining folds
2025-10-09 02:06:32,737:INFO:Declaring metric variables
2025-10-09 02:06:32,740:INFO:Importing untrained model
2025-10-09 02:06:32,740:INFO:Declaring custom model
2025-10-09 02:06:32,745:INFO:Linear Regression Imported successfully
2025-10-09 02:06:32,752:INFO:Starting cross validation
2025-10-09 02:06:32,753:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:06:32,987:INFO:Calculating mean and std
2025-10-09 02:06:32,987:INFO:Creating metrics dataframe
2025-10-09 02:06:32,993:INFO:Finalizing model
2025-10-09 02:06:33,044:INFO:Uploading results into container
2025-10-09 02:06:33,044:INFO:Uploading model into container now
2025-10-09 02:06:33,045:INFO:_master_model_container: 20
2025-10-09 02:06:33,046:INFO:_display_container: 4
2025-10-09 02:06:33,046:INFO:LinearRegression(n_jobs=-1)
2025-10-09 02:06:33,046:INFO:create_model() successfully completed......................................
2025-10-09 02:06:33,148:INFO:SubProcess create_model() end ==================================
2025-10-09 02:06:33,149:INFO:choose_better activated
2025-10-09 02:06:33,153:INFO:SubProcess create_model() called ==================================
2025-10-09 02:06:33,153:INFO:Initializing create_model()
2025-10-09 02:06:33,153:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B253D45090>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:06:33,153:INFO:Checking exceptions
2025-10-09 02:06:33,155:INFO:Importing libraries
2025-10-09 02:06:33,156:INFO:Copying training dataset
2025-10-09 02:06:33,161:INFO:Defining folds
2025-10-09 02:06:33,161:INFO:Declaring metric variables
2025-10-09 02:06:33,161:INFO:Importing untrained model
2025-10-09 02:06:33,161:INFO:Declaring custom model
2025-10-09 02:06:33,161:INFO:Linear Regression Imported successfully
2025-10-09 02:06:33,161:INFO:Starting cross validation
2025-10-09 02:06:33,162:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:06:33,406:INFO:Calculating mean and std
2025-10-09 02:06:33,406:INFO:Creating metrics dataframe
2025-10-09 02:06:33,408:INFO:Finalizing model
2025-10-09 02:06:33,445:INFO:Uploading results into container
2025-10-09 02:06:33,446:INFO:Uploading model into container now
2025-10-09 02:06:33,446:INFO:_master_model_container: 21
2025-10-09 02:06:33,446:INFO:_display_container: 5
2025-10-09 02:06:33,447:INFO:LinearRegression(n_jobs=-1)
2025-10-09 02:06:33,447:INFO:create_model() successfully completed......................................
2025-10-09 02:06:33,542:INFO:SubProcess create_model() end ==================================
2025-10-09 02:06:33,542:INFO:LinearRegression(n_jobs=-1) result for R2 is 0.9593
2025-10-09 02:06:33,543:INFO:LinearRegression(n_jobs=-1) result for R2 is 0.9593
2025-10-09 02:06:33,543:INFO:LinearRegression(n_jobs=-1) is best model
2025-10-09 02:06:33,543:INFO:choose_better completed
2025-10-09 02:06:33,543:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-10-09 02:06:33,554:INFO:_master_model_container: 21
2025-10-09 02:06:33,554:INFO:_display_container: 4
2025-10-09 02:06:33,554:INFO:LinearRegression(n_jobs=-1)
2025-10-09 02:06:33,554:INFO:tune_model() successfully completed......................................
2025-10-09 02:08:56,927:INFO:Initializing evaluate_model()
2025-10-09 02:08:56,927:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B253D45090>, estimator=LinearRegression(n_jobs=-1), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-10-09 02:08:56,940:INFO:Initializing plot_model()
2025-10-09 02:08:56,940:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B253D45090>, estimator=LinearRegression(n_jobs=-1), plot=pipeline, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 02:08:56,940:INFO:Checking exceptions
2025-10-09 02:08:56,942:INFO:Preloading libraries
2025-10-09 02:08:56,943:INFO:Copying training dataset
2025-10-09 02:08:56,943:INFO:Plot type: pipeline
2025-10-09 02:08:57,458:INFO:Visual Rendered Successfully
2025-10-09 02:08:57,564:INFO:plot_model() successfully completed......................................
2025-10-09 02:09:07,287:INFO:Initializing plot_model()
2025-10-09 02:09:07,287:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B253D45090>, estimator=LinearRegression(n_jobs=-1), plot=parameter, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 02:09:07,287:INFO:Checking exceptions
2025-10-09 02:09:07,289:INFO:Preloading libraries
2025-10-09 02:09:07,289:INFO:Copying training dataset
2025-10-09 02:09:07,289:INFO:Plot type: parameter
2025-10-09 02:09:07,293:INFO:Visual Rendered Successfully
2025-10-09 02:09:07,440:INFO:plot_model() successfully completed......................................
2025-10-09 02:09:08,262:INFO:Initializing plot_model()
2025-10-09 02:09:08,262:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B253D45090>, estimator=LinearRegression(n_jobs=-1), plot=residuals, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 02:09:08,262:INFO:Checking exceptions
2025-10-09 02:09:08,264:INFO:Preloading libraries
2025-10-09 02:09:08,264:INFO:Copying training dataset
2025-10-09 02:09:08,265:INFO:Plot type: residuals
2025-10-09 02:09:08,455:INFO:Fitting Model
2025-10-09 02:09:08,456:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names
  warnings.warn(

2025-10-09 02:09:08,492:INFO:Scoring test/hold-out set
2025-10-09 02:09:08,901:INFO:Visual Rendered Successfully
2025-10-09 02:09:08,977:INFO:plot_model() successfully completed......................................
2025-10-09 02:09:08,987:INFO:Initializing plot_model()
2025-10-09 02:09:08,987:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B253D45090>, estimator=LinearRegression(n_jobs=-1), plot=error, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 02:09:08,987:INFO:Checking exceptions
2025-10-09 02:09:08,989:INFO:Preloading libraries
2025-10-09 02:09:08,989:INFO:Copying training dataset
2025-10-09 02:09:08,989:INFO:Plot type: error
2025-10-09 02:09:09,135:INFO:Fitting Model
2025-10-09 02:09:09,135:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names
  warnings.warn(

2025-10-09 02:09:09,136:INFO:Scoring test/hold-out set
2025-10-09 02:09:09,339:INFO:Visual Rendered Successfully
2025-10-09 02:09:09,418:INFO:plot_model() successfully completed......................................
2025-10-09 02:09:09,475:INFO:Initializing plot_model()
2025-10-09 02:09:09,476:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B253D45090>, estimator=LinearRegression(n_jobs=-1), plot=cooks, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 02:09:09,476:INFO:Checking exceptions
2025-10-09 02:09:09,478:INFO:Preloading libraries
2025-10-09 02:09:09,478:INFO:Copying training dataset
2025-10-09 02:09:09,478:INFO:Plot type: cooks
2025-10-09 02:09:09,609:INFO:Fitting Model
2025-10-09 02:09:09,788:INFO:Visual Rendered Successfully
2025-10-09 02:09:09,878:INFO:plot_model() successfully completed......................................
2025-10-09 02:09:10,112:INFO:Initializing plot_model()
2025-10-09 02:09:10,112:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B253D45090>, estimator=LinearRegression(n_jobs=-1), plot=rfe, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 02:09:10,112:INFO:Checking exceptions
2025-10-09 02:09:10,113:INFO:Preloading libraries
2025-10-09 02:09:10,114:INFO:Copying training dataset
2025-10-09 02:09:10,114:INFO:Plot type: rfe
2025-10-09 02:09:10,249:INFO:Fitting Model
2025-10-09 02:09:10,898:INFO:Visual Rendered Successfully
2025-10-09 02:09:10,974:INFO:plot_model() successfully completed......................................
2025-10-09 02:09:11,034:INFO:Initializing plot_model()
2025-10-09 02:09:11,034:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B253D45090>, estimator=LinearRegression(n_jobs=-1), plot=learning, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 02:09:11,034:INFO:Checking exceptions
2025-10-09 02:09:11,036:INFO:Preloading libraries
2025-10-09 02:09:11,037:INFO:Copying training dataset
2025-10-09 02:09:11,037:INFO:Plot type: learning
2025-10-09 02:09:11,195:INFO:Fitting Model
2025-10-09 02:09:11,589:INFO:Visual Rendered Successfully
2025-10-09 02:09:11,667:INFO:plot_model() successfully completed......................................
2025-10-09 02:09:11,991:INFO:Initializing plot_model()
2025-10-09 02:09:11,991:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B253D45090>, estimator=LinearRegression(n_jobs=-1), plot=manifold, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 02:09:11,991:INFO:Checking exceptions
2025-10-09 02:09:11,993:INFO:Preloading libraries
2025-10-09 02:09:11,994:INFO:Copying training dataset
2025-10-09 02:09:11,994:INFO:Plot type: manifold
2025-10-09 02:09:12,159:INFO:Fitting & Transforming Model
2025-10-09 02:09:12,709:INFO:Visual Rendered Successfully
2025-10-09 02:09:12,806:INFO:plot_model() successfully completed......................................
2025-10-09 02:09:13,605:INFO:Initializing plot_model()
2025-10-09 02:09:13,605:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B253D45090>, estimator=LinearRegression(n_jobs=-1), plot=vc, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 02:09:13,605:INFO:Checking exceptions
2025-10-09 02:09:13,607:INFO:Preloading libraries
2025-10-09 02:09:13,607:INFO:Copying training dataset
2025-10-09 02:09:13,607:INFO:Plot type: vc
2025-10-09 02:09:13,608:INFO:Determining param_name
2025-10-09 02:09:16,214:INFO:Initializing plot_model()
2025-10-09 02:09:16,215:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B253D45090>, estimator=LinearRegression(n_jobs=-1), plot=feature, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 02:09:16,215:INFO:Checking exceptions
2025-10-09 02:09:16,217:INFO:Preloading libraries
2025-10-09 02:09:16,217:INFO:Copying training dataset
2025-10-09 02:09:16,217:INFO:Plot type: feature
2025-10-09 02:09:16,411:INFO:Visual Rendered Successfully
2025-10-09 02:09:16,510:INFO:plot_model() successfully completed......................................
2025-10-09 02:09:17,074:INFO:Initializing plot_model()
2025-10-09 02:09:17,074:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B253D45090>, estimator=LinearRegression(n_jobs=-1), plot=feature_all, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 02:09:17,074:INFO:Checking exceptions
2025-10-09 02:09:17,077:INFO:Preloading libraries
2025-10-09 02:09:17,077:INFO:Copying training dataset
2025-10-09 02:09:17,077:INFO:Plot type: feature_all
2025-10-09 02:09:17,248:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\_tight_bbox.py:67: RuntimeWarning: divide by zero encountered in scalar divide
  fig.patch.set_bounds(x0 / w1, y0 / h1,

2025-10-09 02:09:17,248:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\_tight_bbox.py:68: RuntimeWarning: divide by zero encountered in scalar divide
  fig.bbox.width / w1, fig.bbox.height / h1)

2025-10-09 02:09:17,250:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\patches.py:739: RuntimeWarning: invalid value encountered in scalar add
  y1 = self.convert_yunits(self._y0 + self._height)

2025-10-09 02:09:17,251:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\transforms.py:2050: RuntimeWarning: invalid value encountered in scalar add
  self._mtx[1, 2] += ty

2025-10-09 02:09:17,282:INFO:Visual Rendered Successfully
2025-10-09 02:09:17,377:INFO:plot_model() successfully completed......................................
2025-10-09 02:09:18,055:INFO:Initializing plot_model()
2025-10-09 02:09:18,055:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B253D45090>, estimator=LinearRegression(n_jobs=-1), plot=tree, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 02:09:18,055:INFO:Checking exceptions
2025-10-09 02:09:19,570:INFO:Initializing plot_model()
2025-10-09 02:09:19,570:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B253D45090>, estimator=LinearRegression(n_jobs=-1), plot=residuals_interactive, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 02:09:19,570:INFO:Checking exceptions
2025-10-09 02:09:19,572:INFO:Preloading libraries
2025-10-09 02:09:19,573:INFO:Copying training dataset
2025-10-09 02:09:19,573:INFO:Plot type: residuals_interactive
2025-10-09 02:09:21,140:INFO:Initializing plot_model()
2025-10-09 02:09:21,140:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B253D45090>, estimator=LinearRegression(n_jobs=-1), plot=tree, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 02:09:21,140:INFO:Checking exceptions
2025-10-09 02:09:22,103:INFO:Initializing plot_model()
2025-10-09 02:09:22,103:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B253D45090>, estimator=LinearRegression(n_jobs=-1), plot=feature_all, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 02:09:22,103:INFO:Checking exceptions
2025-10-09 02:09:22,105:INFO:Preloading libraries
2025-10-09 02:09:22,106:INFO:Copying training dataset
2025-10-09 02:09:22,106:INFO:Plot type: feature_all
2025-10-09 02:09:22,266:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\_tight_bbox.py:67: RuntimeWarning:

divide by zero encountered in scalar divide


2025-10-09 02:09:22,266:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\_tight_bbox.py:68: RuntimeWarning:

divide by zero encountered in scalar divide


2025-10-09 02:09:22,266:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\patches.py:739: RuntimeWarning:

invalid value encountered in scalar add


2025-10-09 02:09:22,266:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\transforms.py:2050: RuntimeWarning:

invalid value encountered in scalar add


2025-10-09 02:09:22,297:INFO:Visual Rendered Successfully
2025-10-09 02:09:22,379:INFO:plot_model() successfully completed......................................
2025-10-09 02:09:23,492:INFO:Initializing plot_model()
2025-10-09 02:09:23,492:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B253D45090>, estimator=LinearRegression(n_jobs=-1), plot=pipeline, scale=1, save=False, fold=KFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 02:09:23,492:INFO:Checking exceptions
2025-10-09 02:09:23,494:INFO:Preloading libraries
2025-10-09 02:09:23,494:INFO:Copying training dataset
2025-10-09 02:09:23,495:INFO:Plot type: pipeline
2025-10-09 02:09:23,593:INFO:Visual Rendered Successfully
2025-10-09 02:09:23,698:INFO:plot_model() successfully completed......................................
2025-10-09 02:12:53,461:INFO:Initializing predict_model()
2025-10-09 02:12:53,462:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001B253D45090>, estimator=LinearRegression(n_jobs=-1), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001B259FB7B00>)
2025-10-09 02:12:53,462:INFO:Checking exceptions
2025-10-09 02:12:53,462:INFO:Preloading libraries
2025-10-09 02:12:53,550:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_regression.py:483: FutureWarning:

'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.


2025-10-09 02:14:41,141:INFO:Initializing save_model()
2025-10-09 02:14:41,141:INFO:save_model(model=LinearRegression(n_jobs=-1), model_name=modelo_precio_final, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\jjqs_\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['area_m2', 'num_habitaciones',
                                             'num_banos', 'antiguedad_anos',
                                             'vista_mar'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['distrito'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['distrito'],
                                    transformer=OneHotEncoder(cols=['distrito'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-10-09 02:14:41,141:INFO:Adding model into prep_pipe
2025-10-09 02:14:41,490:INFO:modelo_precio_final.pkl saved in current working directory
2025-10-09 02:14:41,500:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['area_m2', 'num_habitaciones',
                                             'num_banos', 'antiguedad_anos',
                                             'vista_mar'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['distrito'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['distrito'],
                                    transformer=OneHotEncoder(cols=['distrito'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('trained_model', LinearRegression(n_jobs=-1))])
2025-10-09 02:14:41,500:INFO:save_model() successfully completed......................................
2025-10-09 02:23:28,744:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-09 02:23:28,744:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-09 02:23:28,744:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-09 02:23:28,744:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-09 02:24:07,042:INFO:PyCaret RegressionExperiment
2025-10-09 02:24:07,042:INFO:Logging name: reg-default-name
2025-10-09 02:24:07,042:INFO:ML Usecase: MLUsecase.REGRESSION
2025-10-09 02:24:07,042:INFO:version 3.3.2
2025-10-09 02:24:07,042:INFO:Initializing setup()
2025-10-09 02:24:07,042:INFO:self.USI: 457e
2025-10-09 02:24:07,042:INFO:self._variable_keys: {'y', 'idx', 'seed', 'memory', 'logging_param', 'y_test', '_ml_usecase', 'transform_target_param', 'fold_generator', 'X_train', 'fold_groups_param', 'log_plots_param', 'data', 'html_param', 'n_jobs_param', 'USI', 'X', 'y_train', 'pipeline', '_available_plots', 'fold_shuffle_param', 'X_test', 'target_param', 'gpu_param', 'exp_id', 'exp_name_log', 'gpu_n_jobs_param'}
2025-10-09 02:24:07,042:INFO:Checking environment
2025-10-09 02:24:07,042:INFO:python_version: 3.11.0
2025-10-09 02:24:07,042:INFO:python_build: ('main', 'Oct 24 2022 18:26:48')
2025-10-09 02:24:07,043:INFO:machine: AMD64
2025-10-09 02:24:07,043:INFO:platform: Windows-10-10.0.19045-SP0
2025-10-09 02:24:07,049:INFO:Memory: svmem(total=12713988096, available=1571393536, percent=87.6, used=11142594560, free=1571393536)
2025-10-09 02:24:07,049:INFO:Physical Core: 4
2025-10-09 02:24:07,049:INFO:Logical Core: 8
2025-10-09 02:24:07,049:INFO:Checking libraries
2025-10-09 02:24:07,049:INFO:System:
2025-10-09 02:24:07,049:INFO:    python: 3.11.0 (main, Oct 24 2022, 18:26:48) [MSC v.1933 64 bit (AMD64)]
2025-10-09 02:24:07,049:INFO:executable: c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\python.exe
2025-10-09 02:24:07,049:INFO:   machine: Windows-10-10.0.19045-SP0
2025-10-09 02:24:07,049:INFO:PyCaret required dependencies:
2025-10-09 02:24:07,077:INFO:                 pip: 25.2
2025-10-09 02:24:07,077:INFO:          setuptools: 65.5.0
2025-10-09 02:24:07,077:INFO:             pycaret: 3.3.2
2025-10-09 02:24:07,077:INFO:             IPython: 9.6.0
2025-10-09 02:24:07,077:INFO:          ipywidgets: 8.1.7
2025-10-09 02:24:07,077:INFO:                tqdm: 4.67.1
2025-10-09 02:24:07,077:INFO:               numpy: 1.26.4
2025-10-09 02:24:07,077:INFO:              pandas: 2.1.4
2025-10-09 02:24:07,077:INFO:              jinja2: 3.1.6
2025-10-09 02:24:07,077:INFO:               scipy: 1.11.4
2025-10-09 02:24:07,077:INFO:              joblib: 1.3.2
2025-10-09 02:24:07,078:INFO:             sklearn: 1.4.2
2025-10-09 02:24:07,078:INFO:                pyod: 2.0.5
2025-10-09 02:24:07,078:INFO:            imblearn: 0.14.0
2025-10-09 02:24:07,078:INFO:   category_encoders: 2.7.0
2025-10-09 02:24:07,078:INFO:            lightgbm: 4.6.0
2025-10-09 02:24:07,078:INFO:               numba: 0.62.1
2025-10-09 02:24:07,078:INFO:            requests: 2.32.5
2025-10-09 02:24:07,078:INFO:          matplotlib: 3.7.5
2025-10-09 02:24:07,078:INFO:          scikitplot: 0.3.7
2025-10-09 02:24:07,078:INFO:         yellowbrick: 1.5
2025-10-09 02:24:07,078:INFO:              plotly: 6.3.1
2025-10-09 02:24:07,078:INFO:    plotly-resampler: Not installed
2025-10-09 02:24:07,078:INFO:             kaleido: 1.1.0
2025-10-09 02:24:07,078:INFO:           schemdraw: 0.15
2025-10-09 02:24:07,078:INFO:         statsmodels: 0.14.5
2025-10-09 02:24:07,078:INFO:              sktime: 0.26.0
2025-10-09 02:24:07,078:INFO:               tbats: 1.1.3
2025-10-09 02:24:07,078:INFO:            pmdarima: 2.0.4
2025-10-09 02:24:07,078:INFO:              psutil: 7.1.0
2025-10-09 02:24:07,078:INFO:          markupsafe: 3.0.3
2025-10-09 02:24:07,078:INFO:             pickle5: Not installed
2025-10-09 02:24:07,078:INFO:         cloudpickle: 3.1.1
2025-10-09 02:24:07,078:INFO:         deprecation: 2.1.0
2025-10-09 02:24:07,078:INFO:              xxhash: 3.6.0
2025-10-09 02:24:07,078:INFO:           wurlitzer: Not installed
2025-10-09 02:24:07,078:INFO:PyCaret optional dependencies:
2025-10-09 02:24:07,095:INFO:                shap: Not installed
2025-10-09 02:24:07,095:INFO:           interpret: Not installed
2025-10-09 02:24:07,095:INFO:                umap: Not installed
2025-10-09 02:24:07,095:INFO:     ydata_profiling: Not installed
2025-10-09 02:24:07,095:INFO:  explainerdashboard: Not installed
2025-10-09 02:24:07,095:INFO:             autoviz: Not installed
2025-10-09 02:24:07,095:INFO:           fairlearn: Not installed
2025-10-09 02:24:07,095:INFO:          deepchecks: Not installed
2025-10-09 02:24:07,095:INFO:             xgboost: Not installed
2025-10-09 02:24:07,095:INFO:            catboost: Not installed
2025-10-09 02:24:07,096:INFO:              kmodes: Not installed
2025-10-09 02:24:07,096:INFO:             mlxtend: Not installed
2025-10-09 02:24:07,096:INFO:       statsforecast: Not installed
2025-10-09 02:24:07,096:INFO:        tune_sklearn: Not installed
2025-10-09 02:24:07,096:INFO:                 ray: Not installed
2025-10-09 02:24:07,096:INFO:            hyperopt: Not installed
2025-10-09 02:24:07,096:INFO:              optuna: Not installed
2025-10-09 02:24:07,096:INFO:               skopt: Not installed
2025-10-09 02:24:07,096:INFO:              mlflow: Not installed
2025-10-09 02:24:07,096:INFO:              gradio: Not installed
2025-10-09 02:24:07,096:INFO:             fastapi: Not installed
2025-10-09 02:24:07,096:INFO:             uvicorn: Not installed
2025-10-09 02:24:07,096:INFO:              m2cgen: Not installed
2025-10-09 02:24:07,096:INFO:           evidently: Not installed
2025-10-09 02:24:07,096:INFO:               fugue: Not installed
2025-10-09 02:24:07,096:INFO:           streamlit: Not installed
2025-10-09 02:24:07,096:INFO:             prophet: Not installed
2025-10-09 02:24:07,096:INFO:None
2025-10-09 02:24:07,096:INFO:Set up data.
2025-10-09 02:25:23,322:INFO:PyCaret RegressionExperiment
2025-10-09 02:25:23,322:INFO:Logging name: reg-default-name
2025-10-09 02:25:23,322:INFO:ML Usecase: MLUsecase.REGRESSION
2025-10-09 02:25:23,322:INFO:version 3.3.2
2025-10-09 02:25:23,322:INFO:Initializing setup()
2025-10-09 02:25:23,322:INFO:self.USI: 42f3
2025-10-09 02:25:23,322:INFO:self._variable_keys: {'y', 'idx', 'seed', 'memory', 'logging_param', 'y_test', '_ml_usecase', 'transform_target_param', 'fold_generator', 'X_train', 'fold_groups_param', 'log_plots_param', 'data', 'html_param', 'n_jobs_param', 'USI', 'X', 'y_train', 'pipeline', '_available_plots', 'fold_shuffle_param', 'X_test', 'target_param', 'gpu_param', 'exp_id', 'exp_name_log', 'gpu_n_jobs_param'}
2025-10-09 02:25:23,322:INFO:Checking environment
2025-10-09 02:25:23,322:INFO:python_version: 3.11.0
2025-10-09 02:25:23,322:INFO:python_build: ('main', 'Oct 24 2022 18:26:48')
2025-10-09 02:25:23,322:INFO:machine: AMD64
2025-10-09 02:25:23,323:INFO:platform: Windows-10-10.0.19045-SP0
2025-10-09 02:25:23,328:INFO:Memory: svmem(total=12713988096, available=1647243264, percent=87.0, used=11066744832, free=1647243264)
2025-10-09 02:25:23,329:INFO:Physical Core: 4
2025-10-09 02:25:23,329:INFO:Logical Core: 8
2025-10-09 02:25:23,329:INFO:Checking libraries
2025-10-09 02:25:23,329:INFO:System:
2025-10-09 02:25:23,329:INFO:    python: 3.11.0 (main, Oct 24 2022, 18:26:48) [MSC v.1933 64 bit (AMD64)]
2025-10-09 02:25:23,329:INFO:executable: c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\python.exe
2025-10-09 02:25:23,329:INFO:   machine: Windows-10-10.0.19045-SP0
2025-10-09 02:25:23,329:INFO:PyCaret required dependencies:
2025-10-09 02:25:23,329:INFO:                 pip: 25.2
2025-10-09 02:25:23,329:INFO:          setuptools: 65.5.0
2025-10-09 02:25:23,329:INFO:             pycaret: 3.3.2
2025-10-09 02:25:23,329:INFO:             IPython: 9.6.0
2025-10-09 02:25:23,329:INFO:          ipywidgets: 8.1.7
2025-10-09 02:25:23,330:INFO:                tqdm: 4.67.1
2025-10-09 02:25:23,330:INFO:               numpy: 1.26.4
2025-10-09 02:25:23,330:INFO:              pandas: 2.1.4
2025-10-09 02:25:23,330:INFO:              jinja2: 3.1.6
2025-10-09 02:25:23,330:INFO:               scipy: 1.11.4
2025-10-09 02:25:23,330:INFO:              joblib: 1.3.2
2025-10-09 02:25:23,330:INFO:             sklearn: 1.4.2
2025-10-09 02:25:23,330:INFO:                pyod: 2.0.5
2025-10-09 02:25:23,330:INFO:            imblearn: 0.14.0
2025-10-09 02:25:23,330:INFO:   category_encoders: 2.7.0
2025-10-09 02:25:23,330:INFO:            lightgbm: 4.6.0
2025-10-09 02:25:23,330:INFO:               numba: 0.62.1
2025-10-09 02:25:23,330:INFO:            requests: 2.32.5
2025-10-09 02:25:23,330:INFO:          matplotlib: 3.7.5
2025-10-09 02:25:23,330:INFO:          scikitplot: 0.3.7
2025-10-09 02:25:23,330:INFO:         yellowbrick: 1.5
2025-10-09 02:25:23,331:INFO:              plotly: 6.3.1
2025-10-09 02:25:23,331:INFO:    plotly-resampler: Not installed
2025-10-09 02:25:23,331:INFO:             kaleido: 1.1.0
2025-10-09 02:25:23,331:INFO:           schemdraw: 0.15
2025-10-09 02:25:23,331:INFO:         statsmodels: 0.14.5
2025-10-09 02:25:23,331:INFO:              sktime: 0.26.0
2025-10-09 02:25:23,331:INFO:               tbats: 1.1.3
2025-10-09 02:25:23,331:INFO:            pmdarima: 2.0.4
2025-10-09 02:25:23,331:INFO:              psutil: 7.1.0
2025-10-09 02:25:23,331:INFO:          markupsafe: 3.0.3
2025-10-09 02:25:23,331:INFO:             pickle5: Not installed
2025-10-09 02:25:23,331:INFO:         cloudpickle: 3.1.1
2025-10-09 02:25:23,331:INFO:         deprecation: 2.1.0
2025-10-09 02:25:23,331:INFO:              xxhash: 3.6.0
2025-10-09 02:25:23,332:INFO:           wurlitzer: Not installed
2025-10-09 02:25:23,332:INFO:PyCaret optional dependencies:
2025-10-09 02:25:23,332:INFO:                shap: Not installed
2025-10-09 02:25:23,332:INFO:           interpret: Not installed
2025-10-09 02:25:23,332:INFO:                umap: Not installed
2025-10-09 02:25:23,332:INFO:     ydata_profiling: Not installed
2025-10-09 02:25:23,332:INFO:  explainerdashboard: Not installed
2025-10-09 02:25:23,332:INFO:             autoviz: Not installed
2025-10-09 02:25:23,332:INFO:           fairlearn: Not installed
2025-10-09 02:25:23,332:INFO:          deepchecks: Not installed
2025-10-09 02:25:23,332:INFO:             xgboost: Not installed
2025-10-09 02:25:23,332:INFO:            catboost: Not installed
2025-10-09 02:25:23,332:INFO:              kmodes: Not installed
2025-10-09 02:25:23,332:INFO:             mlxtend: Not installed
2025-10-09 02:25:23,332:INFO:       statsforecast: Not installed
2025-10-09 02:25:23,332:INFO:        tune_sklearn: Not installed
2025-10-09 02:25:23,332:INFO:                 ray: Not installed
2025-10-09 02:25:23,332:INFO:            hyperopt: Not installed
2025-10-09 02:25:23,332:INFO:              optuna: Not installed
2025-10-09 02:25:23,332:INFO:               skopt: Not installed
2025-10-09 02:25:23,332:INFO:              mlflow: Not installed
2025-10-09 02:25:23,332:INFO:              gradio: Not installed
2025-10-09 02:25:23,332:INFO:             fastapi: Not installed
2025-10-09 02:25:23,332:INFO:             uvicorn: Not installed
2025-10-09 02:25:23,332:INFO:              m2cgen: Not installed
2025-10-09 02:25:23,332:INFO:           evidently: Not installed
2025-10-09 02:25:23,332:INFO:               fugue: Not installed
2025-10-09 02:25:23,332:INFO:           streamlit: Not installed
2025-10-09 02:25:23,333:INFO:             prophet: Not installed
2025-10-09 02:25:23,333:INFO:None
2025-10-09 02:25:23,333:INFO:Set up data.
2025-10-09 02:25:23,338:INFO:Set up folding strategy.
2025-10-09 02:25:23,338:INFO:Set up train/test split.
2025-10-09 02:25:23,347:INFO:Set up index.
2025-10-09 02:25:23,347:INFO:Assigning column types.
2025-10-09 02:25:23,350:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-09 02:25:23,350:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-10-09 02:25:23,354:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-09 02:25:23,358:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-09 02:25:23,409:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-09 02:25:23,446:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-09 02:25:23,446:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 02:25:23,447:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 02:25:23,447:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-10-09 02:25:23,452:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-09 02:25:23,456:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-09 02:25:23,508:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-09 02:25:23,564:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-09 02:25:23,565:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 02:25:23,565:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 02:25:23,565:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-10-09 02:25:23,569:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-09 02:25:23,573:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-09 02:25:23,636:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-09 02:25:23,677:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-09 02:25:23,678:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 02:25:23,678:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 02:25:23,683:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-09 02:25:23,688:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-09 02:25:23,738:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-09 02:25:23,777:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-09 02:25:23,777:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 02:25:23,777:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 02:25:23,777:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-10-09 02:25:23,786:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-09 02:25:23,834:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-09 02:25:23,875:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-09 02:25:23,876:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 02:25:23,876:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 02:25:23,885:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-09 02:25:23,933:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-09 02:25:23,972:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-09 02:25:23,972:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 02:25:23,972:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 02:25:23,972:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-10-09 02:25:24,032:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-09 02:25:24,077:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-09 02:25:24,078:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 02:25:24,078:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 02:25:24,161:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-09 02:25:24,211:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-09 02:25:24,213:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 02:25:24,213:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 02:25:24,214:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-09 02:25:24,308:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-09 02:25:24,523:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 02:25:24,524:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 02:25:24,587:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-09 02:25:24,629:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 02:25:24,629:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 02:25:24,630:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-10-09 02:25:24,732:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 02:25:24,732:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 02:25:24,832:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 02:25:24,832:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 02:25:24,835:INFO:Preparing preprocessing pipeline...
2025-10-09 02:25:24,835:INFO:Set up simple imputation.
2025-10-09 02:25:24,837:INFO:Set up encoding of ordinal features.
2025-10-09 02:25:24,838:INFO:Set up encoding of categorical features.
2025-10-09 02:25:24,838:INFO:Set up feature normalization.
2025-10-09 02:25:24,946:INFO:Finished creating preprocessing pipeline.
2025-10-09 02:25:24,973:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\jjqs_\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['edad', 'ingresos_mensuales',
                                             'nro_creditos_previos',
                                             'cuota_vs_ingreso'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['estado_civil', 'historia_credito',
                                             'vehiculo_propio'],
                                    transformer...
                                                               mapping=[{'col': 'vehiculo_propio',
                                                                         'data_type': dtype('float64'),
                                                                         'mapping': 0.0    0
1.0    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['estado_civil',
                                             'historia_credito'],
                                    transformer=OneHotEncoder(cols=['estado_civil',
                                                                    'historia_credito'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2025-10-09 02:25:24,973:INFO:Creating final display dataframe.
2025-10-09 02:25:25,177:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target           default
2                   Target type        Regression
3           Original data shape          (150, 8)
4        Transformed data shape         (150, 12)
5   Transformed train set shape         (105, 12)
6    Transformed test set shape          (45, 12)
7              Numeric features                 4
8          Categorical features                 3
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                    Normalize              True
16             Normalize method            zscore
17               Fold Generator             KFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  reg-default-name
23                          USI              42f3
2025-10-09 02:25:25,301:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 02:25:25,301:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 02:25:25,401:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 02:25:25,402:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 02:25:25,402:INFO:setup() successfully completed in 2.08s...............
2025-10-09 02:25:37,330:INFO:Initializing compare_models()
2025-10-09 02:25:37,330:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000159B0BC9710>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000159B0BC9710>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2025-10-09 02:25:37,330:INFO:Checking exceptions
2025-10-09 02:25:37,332:INFO:Preparing display monitor
2025-10-09 02:25:37,358:INFO:Initializing Linear Regression
2025-10-09 02:25:37,358:INFO:Total runtime is 0.0 minutes
2025-10-09 02:25:37,362:INFO:SubProcess create_model() called ==================================
2025-10-09 02:25:37,363:INFO:Initializing create_model()
2025-10-09 02:25:37,363:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000159B0BC9710>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000159B14E5210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:25:37,363:INFO:Checking exceptions
2025-10-09 02:25:37,363:INFO:Importing libraries
2025-10-09 02:25:37,363:INFO:Copying training dataset
2025-10-09 02:25:37,369:INFO:Defining folds
2025-10-09 02:25:37,369:INFO:Declaring metric variables
2025-10-09 02:25:37,374:INFO:Importing untrained model
2025-10-09 02:25:37,379:INFO:Linear Regression Imported successfully
2025-10-09 02:25:37,388:INFO:Starting cross validation
2025-10-09 02:25:37,398:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:25:46,553:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-10-09 02:25:46,602:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-10-09 02:25:47,017:INFO:Calculating mean and std
2025-10-09 02:25:47,019:INFO:Creating metrics dataframe
2025-10-09 02:25:47,022:INFO:Uploading results into container
2025-10-09 02:25:47,023:INFO:Uploading model into container now
2025-10-09 02:25:47,023:INFO:_master_model_container: 1
2025-10-09 02:25:47,024:INFO:_display_container: 2
2025-10-09 02:25:47,025:INFO:LinearRegression(n_jobs=-1)
2025-10-09 02:25:47,026:INFO:create_model() successfully completed......................................
2025-10-09 02:25:47,140:INFO:SubProcess create_model() end ==================================
2025-10-09 02:25:47,140:INFO:Creating metrics dataframe
2025-10-09 02:25:47,151:INFO:Initializing Lasso Regression
2025-10-09 02:25:47,151:INFO:Total runtime is 0.16322638988494872 minutes
2025-10-09 02:25:47,156:INFO:SubProcess create_model() called ==================================
2025-10-09 02:25:47,157:INFO:Initializing create_model()
2025-10-09 02:25:47,157:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000159B0BC9710>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000159B14E5210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:25:47,157:INFO:Checking exceptions
2025-10-09 02:25:47,157:INFO:Importing libraries
2025-10-09 02:25:47,157:INFO:Copying training dataset
2025-10-09 02:25:47,164:INFO:Defining folds
2025-10-09 02:25:47,165:INFO:Declaring metric variables
2025-10-09 02:25:47,170:INFO:Importing untrained model
2025-10-09 02:25:47,176:INFO:Lasso Regression Imported successfully
2025-10-09 02:25:47,186:INFO:Starting cross validation
2025-10-09 02:25:47,188:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:25:47,530:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-10-09 02:25:47,530:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-10-09 02:25:47,534:INFO:Calculating mean and std
2025-10-09 02:25:47,535:INFO:Creating metrics dataframe
2025-10-09 02:25:47,537:INFO:Uploading results into container
2025-10-09 02:25:47,537:INFO:Uploading model into container now
2025-10-09 02:25:47,538:INFO:_master_model_container: 2
2025-10-09 02:25:47,538:INFO:_display_container: 2
2025-10-09 02:25:47,538:INFO:Lasso(random_state=123)
2025-10-09 02:25:47,539:INFO:create_model() successfully completed......................................
2025-10-09 02:25:47,636:INFO:SubProcess create_model() end ==================================
2025-10-09 02:25:47,636:INFO:Creating metrics dataframe
2025-10-09 02:25:47,648:INFO:Initializing Ridge Regression
2025-10-09 02:25:47,648:INFO:Total runtime is 0.1715024948120117 minutes
2025-10-09 02:25:47,653:INFO:SubProcess create_model() called ==================================
2025-10-09 02:25:47,655:INFO:Initializing create_model()
2025-10-09 02:25:47,655:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000159B0BC9710>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000159B14E5210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:25:47,656:INFO:Checking exceptions
2025-10-09 02:25:47,656:INFO:Importing libraries
2025-10-09 02:25:47,657:INFO:Copying training dataset
2025-10-09 02:25:47,668:INFO:Defining folds
2025-10-09 02:25:47,668:INFO:Declaring metric variables
2025-10-09 02:25:47,685:INFO:Importing untrained model
2025-10-09 02:25:47,698:INFO:Ridge Regression Imported successfully
2025-10-09 02:25:47,713:INFO:Starting cross validation
2025-10-09 02:25:47,718:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:25:48,132:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-10-09 02:25:48,133:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-10-09 02:25:48,135:INFO:Calculating mean and std
2025-10-09 02:25:48,137:INFO:Creating metrics dataframe
2025-10-09 02:25:48,139:INFO:Uploading results into container
2025-10-09 02:25:48,140:INFO:Uploading model into container now
2025-10-09 02:25:48,141:INFO:_master_model_container: 3
2025-10-09 02:25:48,141:INFO:_display_container: 2
2025-10-09 02:25:48,142:INFO:Ridge(random_state=123)
2025-10-09 02:25:48,142:INFO:create_model() successfully completed......................................
2025-10-09 02:25:48,278:INFO:SubProcess create_model() end ==================================
2025-10-09 02:25:48,278:INFO:Creating metrics dataframe
2025-10-09 02:25:48,293:INFO:Initializing Elastic Net
2025-10-09 02:25:48,293:INFO:Total runtime is 0.18224948644638062 minutes
2025-10-09 02:25:48,298:INFO:SubProcess create_model() called ==================================
2025-10-09 02:25:48,298:INFO:Initializing create_model()
2025-10-09 02:25:48,298:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000159B0BC9710>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000159B14E5210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:25:48,299:INFO:Checking exceptions
2025-10-09 02:25:48,299:INFO:Importing libraries
2025-10-09 02:25:48,299:INFO:Copying training dataset
2025-10-09 02:25:48,308:INFO:Defining folds
2025-10-09 02:25:48,308:INFO:Declaring metric variables
2025-10-09 02:25:48,315:INFO:Importing untrained model
2025-10-09 02:25:48,320:INFO:Elastic Net Imported successfully
2025-10-09 02:25:48,334:INFO:Starting cross validation
2025-10-09 02:25:48,337:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:25:48,888:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-10-09 02:25:48,889:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-10-09 02:25:48,899:INFO:Calculating mean and std
2025-10-09 02:25:48,901:INFO:Creating metrics dataframe
2025-10-09 02:25:48,905:INFO:Uploading results into container
2025-10-09 02:25:48,907:INFO:Uploading model into container now
2025-10-09 02:25:48,908:INFO:_master_model_container: 4
2025-10-09 02:25:48,909:INFO:_display_container: 2
2025-10-09 02:25:48,909:INFO:ElasticNet(random_state=123)
2025-10-09 02:25:48,909:INFO:create_model() successfully completed......................................
2025-10-09 02:25:49,021:INFO:SubProcess create_model() end ==================================
2025-10-09 02:25:49,021:INFO:Creating metrics dataframe
2025-10-09 02:25:49,028:INFO:Initializing Least Angle Regression
2025-10-09 02:25:49,028:INFO:Total runtime is 0.19451029698053995 minutes
2025-10-09 02:25:49,031:INFO:SubProcess create_model() called ==================================
2025-10-09 02:25:49,032:INFO:Initializing create_model()
2025-10-09 02:25:49,032:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000159B0BC9710>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000159B14E5210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:25:49,032:INFO:Checking exceptions
2025-10-09 02:25:49,032:INFO:Importing libraries
2025-10-09 02:25:49,032:INFO:Copying training dataset
2025-10-09 02:25:49,036:INFO:Defining folds
2025-10-09 02:25:49,036:INFO:Declaring metric variables
2025-10-09 02:25:49,039:INFO:Importing untrained model
2025-10-09 02:25:49,043:INFO:Least Angle Regression Imported successfully
2025-10-09 02:25:49,052:INFO:Starting cross validation
2025-10-09 02:25:49,054:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:25:49,440:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-10-09 02:25:49,440:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-10-09 02:25:49,445:INFO:Calculating mean and std
2025-10-09 02:25:49,446:INFO:Creating metrics dataframe
2025-10-09 02:25:49,448:INFO:Uploading results into container
2025-10-09 02:25:49,449:INFO:Uploading model into container now
2025-10-09 02:25:49,449:INFO:_master_model_container: 5
2025-10-09 02:25:49,449:INFO:_display_container: 2
2025-10-09 02:25:49,450:INFO:Lars(random_state=123)
2025-10-09 02:25:49,450:INFO:create_model() successfully completed......................................
2025-10-09 02:25:49,548:INFO:SubProcess create_model() end ==================================
2025-10-09 02:25:49,548:INFO:Creating metrics dataframe
2025-10-09 02:25:49,558:INFO:Initializing Lasso Least Angle Regression
2025-10-09 02:25:49,558:INFO:Total runtime is 0.20334682861963907 minutes
2025-10-09 02:25:49,562:INFO:SubProcess create_model() called ==================================
2025-10-09 02:25:49,563:INFO:Initializing create_model()
2025-10-09 02:25:49,563:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000159B0BC9710>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000159B14E5210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:25:49,563:INFO:Checking exceptions
2025-10-09 02:25:49,563:INFO:Importing libraries
2025-10-09 02:25:49,563:INFO:Copying training dataset
2025-10-09 02:25:49,569:INFO:Defining folds
2025-10-09 02:25:49,569:INFO:Declaring metric variables
2025-10-09 02:25:49,576:INFO:Importing untrained model
2025-10-09 02:25:49,582:INFO:Lasso Least Angle Regression Imported successfully
2025-10-09 02:25:49,594:INFO:Starting cross validation
2025-10-09 02:25:49,597:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:25:49,895:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-10-09 02:25:49,896:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-10-09 02:25:49,901:INFO:Calculating mean and std
2025-10-09 02:25:49,902:INFO:Creating metrics dataframe
2025-10-09 02:25:49,905:INFO:Uploading results into container
2025-10-09 02:25:49,905:INFO:Uploading model into container now
2025-10-09 02:25:49,906:INFO:_master_model_container: 6
2025-10-09 02:25:49,906:INFO:_display_container: 2
2025-10-09 02:25:49,906:INFO:LassoLars(random_state=123)
2025-10-09 02:25:49,907:INFO:create_model() successfully completed......................................
2025-10-09 02:25:50,016:INFO:SubProcess create_model() end ==================================
2025-10-09 02:25:50,016:INFO:Creating metrics dataframe
2025-10-09 02:25:50,026:INFO:Initializing Orthogonal Matching Pursuit
2025-10-09 02:25:50,026:INFO:Total runtime is 0.2111393610636393 minutes
2025-10-09 02:25:50,030:INFO:SubProcess create_model() called ==================================
2025-10-09 02:25:50,031:INFO:Initializing create_model()
2025-10-09 02:25:50,031:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000159B0BC9710>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000159B14E5210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:25:50,031:INFO:Checking exceptions
2025-10-09 02:25:50,031:INFO:Importing libraries
2025-10-09 02:25:50,031:INFO:Copying training dataset
2025-10-09 02:25:50,037:INFO:Defining folds
2025-10-09 02:25:50,037:INFO:Declaring metric variables
2025-10-09 02:25:50,042:INFO:Importing untrained model
2025-10-09 02:25:50,047:INFO:Orthogonal Matching Pursuit Imported successfully
2025-10-09 02:25:50,060:INFO:Starting cross validation
2025-10-09 02:25:50,062:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:25:50,334:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-10-09 02:25:50,335:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-10-09 02:25:50,343:INFO:Calculating mean and std
2025-10-09 02:25:50,344:INFO:Creating metrics dataframe
2025-10-09 02:25:50,346:INFO:Uploading results into container
2025-10-09 02:25:50,346:INFO:Uploading model into container now
2025-10-09 02:25:50,347:INFO:_master_model_container: 7
2025-10-09 02:25:50,347:INFO:_display_container: 2
2025-10-09 02:25:50,347:INFO:OrthogonalMatchingPursuit()
2025-10-09 02:25:50,347:INFO:create_model() successfully completed......................................
2025-10-09 02:25:50,428:INFO:SubProcess create_model() end ==================================
2025-10-09 02:25:50,428:INFO:Creating metrics dataframe
2025-10-09 02:25:50,436:INFO:Initializing Bayesian Ridge
2025-10-09 02:25:50,436:INFO:Total runtime is 0.2179654836654663 minutes
2025-10-09 02:25:50,438:INFO:SubProcess create_model() called ==================================
2025-10-09 02:25:50,439:INFO:Initializing create_model()
2025-10-09 02:25:50,439:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000159B0BC9710>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000159B14E5210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:25:50,439:INFO:Checking exceptions
2025-10-09 02:25:50,439:INFO:Importing libraries
2025-10-09 02:25:50,439:INFO:Copying training dataset
2025-10-09 02:25:50,444:INFO:Defining folds
2025-10-09 02:25:50,444:INFO:Declaring metric variables
2025-10-09 02:25:50,447:INFO:Importing untrained model
2025-10-09 02:25:50,451:INFO:Bayesian Ridge Imported successfully
2025-10-09 02:25:50,459:INFO:Starting cross validation
2025-10-09 02:25:50,462:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:25:50,845:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-10-09 02:25:50,845:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-10-09 02:25:50,854:INFO:Calculating mean and std
2025-10-09 02:25:50,856:INFO:Creating metrics dataframe
2025-10-09 02:25:50,858:INFO:Uploading results into container
2025-10-09 02:25:50,859:INFO:Uploading model into container now
2025-10-09 02:25:50,859:INFO:_master_model_container: 8
2025-10-09 02:25:50,859:INFO:_display_container: 2
2025-10-09 02:25:50,860:INFO:BayesianRidge()
2025-10-09 02:25:50,860:INFO:create_model() successfully completed......................................
2025-10-09 02:25:50,955:INFO:SubProcess create_model() end ==================================
2025-10-09 02:25:50,955:INFO:Creating metrics dataframe
2025-10-09 02:25:50,962:INFO:Initializing Passive Aggressive Regressor
2025-10-09 02:25:50,963:INFO:Total runtime is 0.2267593463261922 minutes
2025-10-09 02:25:50,966:INFO:SubProcess create_model() called ==================================
2025-10-09 02:25:50,966:INFO:Initializing create_model()
2025-10-09 02:25:50,966:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000159B0BC9710>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000159B14E5210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:25:50,966:INFO:Checking exceptions
2025-10-09 02:25:50,966:INFO:Importing libraries
2025-10-09 02:25:50,966:INFO:Copying training dataset
2025-10-09 02:25:50,971:INFO:Defining folds
2025-10-09 02:25:50,971:INFO:Declaring metric variables
2025-10-09 02:25:50,975:INFO:Importing untrained model
2025-10-09 02:25:50,979:INFO:Passive Aggressive Regressor Imported successfully
2025-10-09 02:25:50,988:INFO:Starting cross validation
2025-10-09 02:25:50,991:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:25:51,272:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-10-09 02:25:51,273:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-10-09 02:25:51,275:INFO:Calculating mean and std
2025-10-09 02:25:51,276:INFO:Creating metrics dataframe
2025-10-09 02:25:51,278:INFO:Uploading results into container
2025-10-09 02:25:51,279:INFO:Uploading model into container now
2025-10-09 02:25:51,279:INFO:_master_model_container: 9
2025-10-09 02:25:51,279:INFO:_display_container: 2
2025-10-09 02:25:51,280:INFO:PassiveAggressiveRegressor(random_state=123)
2025-10-09 02:25:51,280:INFO:create_model() successfully completed......................................
2025-10-09 02:25:51,374:INFO:SubProcess create_model() end ==================================
2025-10-09 02:25:51,374:INFO:Creating metrics dataframe
2025-10-09 02:25:51,384:INFO:Initializing Huber Regressor
2025-10-09 02:25:51,384:INFO:Total runtime is 0.2337706963221232 minutes
2025-10-09 02:25:51,388:INFO:SubProcess create_model() called ==================================
2025-10-09 02:25:51,388:INFO:Initializing create_model()
2025-10-09 02:25:51,388:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000159B0BC9710>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000159B14E5210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:25:51,388:INFO:Checking exceptions
2025-10-09 02:25:51,389:INFO:Importing libraries
2025-10-09 02:25:51,389:INFO:Copying training dataset
2025-10-09 02:25:51,394:INFO:Defining folds
2025-10-09 02:25:51,395:INFO:Declaring metric variables
2025-10-09 02:25:51,400:INFO:Importing untrained model
2025-10-09 02:25:51,406:INFO:Huber Regressor Imported successfully
2025-10-09 02:25:51,417:INFO:Starting cross validation
2025-10-09 02:25:51,420:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:25:51,803:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-10-09 02:25:51,803:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-10-09 02:25:51,809:INFO:Calculating mean and std
2025-10-09 02:25:51,810:INFO:Creating metrics dataframe
2025-10-09 02:25:51,812:INFO:Uploading results into container
2025-10-09 02:25:51,813:INFO:Uploading model into container now
2025-10-09 02:25:51,813:INFO:_master_model_container: 10
2025-10-09 02:25:51,813:INFO:_display_container: 2
2025-10-09 02:25:51,814:INFO:HuberRegressor()
2025-10-09 02:25:51,814:INFO:create_model() successfully completed......................................
2025-10-09 02:25:51,897:INFO:SubProcess create_model() end ==================================
2025-10-09 02:25:51,897:INFO:Creating metrics dataframe
2025-10-09 02:25:51,905:INFO:Initializing K Neighbors Regressor
2025-10-09 02:25:51,905:INFO:Total runtime is 0.24245805342992144 minutes
2025-10-09 02:25:51,908:INFO:SubProcess create_model() called ==================================
2025-10-09 02:25:51,908:INFO:Initializing create_model()
2025-10-09 02:25:51,908:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000159B0BC9710>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000159B14E5210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:25:51,908:INFO:Checking exceptions
2025-10-09 02:25:51,908:INFO:Importing libraries
2025-10-09 02:25:51,908:INFO:Copying training dataset
2025-10-09 02:25:51,912:INFO:Defining folds
2025-10-09 02:25:51,913:INFO:Declaring metric variables
2025-10-09 02:25:51,916:INFO:Importing untrained model
2025-10-09 02:25:51,920:INFO:K Neighbors Regressor Imported successfully
2025-10-09 02:25:51,928:INFO:Starting cross validation
2025-10-09 02:25:51,930:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:25:52,248:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-10-09 02:25:52,248:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-10-09 02:25:52,252:INFO:Calculating mean and std
2025-10-09 02:25:52,253:INFO:Creating metrics dataframe
2025-10-09 02:25:52,255:INFO:Uploading results into container
2025-10-09 02:25:52,255:INFO:Uploading model into container now
2025-10-09 02:25:52,256:INFO:_master_model_container: 11
2025-10-09 02:25:52,256:INFO:_display_container: 2
2025-10-09 02:25:52,256:INFO:KNeighborsRegressor(n_jobs=-1)
2025-10-09 02:25:52,256:INFO:create_model() successfully completed......................................
2025-10-09 02:25:52,339:INFO:SubProcess create_model() end ==================================
2025-10-09 02:25:52,339:INFO:Creating metrics dataframe
2025-10-09 02:25:52,348:INFO:Initializing Decision Tree Regressor
2025-10-09 02:25:52,348:INFO:Total runtime is 0.24983564217885332 minutes
2025-10-09 02:25:52,352:INFO:SubProcess create_model() called ==================================
2025-10-09 02:25:52,352:INFO:Initializing create_model()
2025-10-09 02:25:52,352:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000159B0BC9710>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000159B14E5210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:25:52,352:INFO:Checking exceptions
2025-10-09 02:25:52,352:INFO:Importing libraries
2025-10-09 02:25:52,352:INFO:Copying training dataset
2025-10-09 02:25:52,357:INFO:Defining folds
2025-10-09 02:25:52,357:INFO:Declaring metric variables
2025-10-09 02:25:52,361:INFO:Importing untrained model
2025-10-09 02:25:52,367:INFO:Decision Tree Regressor Imported successfully
2025-10-09 02:25:52,376:INFO:Starting cross validation
2025-10-09 02:25:52,379:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:25:52,682:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-10-09 02:25:52,682:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-10-09 02:25:52,687:INFO:Calculating mean and std
2025-10-09 02:25:52,688:INFO:Creating metrics dataframe
2025-10-09 02:25:52,690:INFO:Uploading results into container
2025-10-09 02:25:52,690:INFO:Uploading model into container now
2025-10-09 02:25:52,691:INFO:_master_model_container: 12
2025-10-09 02:25:52,691:INFO:_display_container: 2
2025-10-09 02:25:52,691:INFO:DecisionTreeRegressor(random_state=123)
2025-10-09 02:25:52,691:INFO:create_model() successfully completed......................................
2025-10-09 02:25:52,778:INFO:SubProcess create_model() end ==================================
2025-10-09 02:25:52,779:INFO:Creating metrics dataframe
2025-10-09 02:25:52,788:INFO:Initializing Random Forest Regressor
2025-10-09 02:25:52,788:INFO:Total runtime is 0.2571728666623433 minutes
2025-10-09 02:25:52,791:INFO:SubProcess create_model() called ==================================
2025-10-09 02:25:52,792:INFO:Initializing create_model()
2025-10-09 02:25:52,792:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000159B0BC9710>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000159B14E5210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:25:52,792:INFO:Checking exceptions
2025-10-09 02:25:52,792:INFO:Importing libraries
2025-10-09 02:25:52,792:INFO:Copying training dataset
2025-10-09 02:25:52,797:INFO:Defining folds
2025-10-09 02:25:52,797:INFO:Declaring metric variables
2025-10-09 02:25:52,803:INFO:Importing untrained model
2025-10-09 02:25:52,809:INFO:Random Forest Regressor Imported successfully
2025-10-09 02:25:52,819:INFO:Starting cross validation
2025-10-09 02:25:52,820:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:25:53,577:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-10-09 02:25:53,577:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-10-09 02:25:53,580:INFO:Calculating mean and std
2025-10-09 02:25:53,581:INFO:Creating metrics dataframe
2025-10-09 02:25:53,583:INFO:Uploading results into container
2025-10-09 02:25:53,584:INFO:Uploading model into container now
2025-10-09 02:25:53,584:INFO:_master_model_container: 13
2025-10-09 02:25:53,584:INFO:_display_container: 2
2025-10-09 02:25:53,585:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-10-09 02:25:53,585:INFO:create_model() successfully completed......................................
2025-10-09 02:25:53,676:INFO:SubProcess create_model() end ==================================
2025-10-09 02:25:53,676:INFO:Creating metrics dataframe
2025-10-09 02:25:53,686:INFO:Initializing Extra Trees Regressor
2025-10-09 02:25:53,686:INFO:Total runtime is 0.27214088439941403 minutes
2025-10-09 02:25:53,689:INFO:SubProcess create_model() called ==================================
2025-10-09 02:25:53,690:INFO:Initializing create_model()
2025-10-09 02:25:53,690:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000159B0BC9710>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000159B14E5210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:25:53,690:INFO:Checking exceptions
2025-10-09 02:25:53,690:INFO:Importing libraries
2025-10-09 02:25:53,690:INFO:Copying training dataset
2025-10-09 02:25:53,694:INFO:Defining folds
2025-10-09 02:25:53,694:INFO:Declaring metric variables
2025-10-09 02:25:53,698:INFO:Importing untrained model
2025-10-09 02:25:53,702:INFO:Extra Trees Regressor Imported successfully
2025-10-09 02:25:53,710:INFO:Starting cross validation
2025-10-09 02:25:53,712:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:25:54,320:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-10-09 02:25:54,320:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-10-09 02:25:54,331:INFO:Calculating mean and std
2025-10-09 02:25:54,332:INFO:Creating metrics dataframe
2025-10-09 02:25:54,334:INFO:Uploading results into container
2025-10-09 02:25:54,335:INFO:Uploading model into container now
2025-10-09 02:25:54,335:INFO:_master_model_container: 14
2025-10-09 02:25:54,336:INFO:_display_container: 2
2025-10-09 02:25:54,336:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-10-09 02:25:54,336:INFO:create_model() successfully completed......................................
2025-10-09 02:25:54,417:INFO:SubProcess create_model() end ==================================
2025-10-09 02:25:54,418:INFO:Creating metrics dataframe
2025-10-09 02:25:54,426:INFO:Initializing AdaBoost Regressor
2025-10-09 02:25:54,426:INFO:Total runtime is 0.2844714800516764 minutes
2025-10-09 02:25:54,429:INFO:SubProcess create_model() called ==================================
2025-10-09 02:25:54,429:INFO:Initializing create_model()
2025-10-09 02:25:54,429:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000159B0BC9710>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000159B14E5210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:25:54,429:INFO:Checking exceptions
2025-10-09 02:25:54,430:INFO:Importing libraries
2025-10-09 02:25:54,430:INFO:Copying training dataset
2025-10-09 02:25:54,434:INFO:Defining folds
2025-10-09 02:25:54,434:INFO:Declaring metric variables
2025-10-09 02:25:54,437:INFO:Importing untrained model
2025-10-09 02:25:54,442:INFO:AdaBoost Regressor Imported successfully
2025-10-09 02:25:54,451:INFO:Starting cross validation
2025-10-09 02:25:54,453:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:25:54,974:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-10-09 02:25:54,974:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-10-09 02:25:54,977:INFO:Calculating mean and std
2025-10-09 02:25:54,978:INFO:Creating metrics dataframe
2025-10-09 02:25:54,979:INFO:Uploading results into container
2025-10-09 02:25:54,980:INFO:Uploading model into container now
2025-10-09 02:25:54,981:INFO:_master_model_container: 15
2025-10-09 02:25:54,981:INFO:_display_container: 2
2025-10-09 02:25:54,981:INFO:AdaBoostRegressor(random_state=123)
2025-10-09 02:25:54,982:INFO:create_model() successfully completed......................................
2025-10-09 02:25:55,064:INFO:SubProcess create_model() end ==================================
2025-10-09 02:25:55,065:INFO:Creating metrics dataframe
2025-10-09 02:25:55,074:INFO:Initializing Gradient Boosting Regressor
2025-10-09 02:25:55,075:INFO:Total runtime is 0.2952954729398091 minutes
2025-10-09 02:25:55,078:INFO:SubProcess create_model() called ==================================
2025-10-09 02:25:55,079:INFO:Initializing create_model()
2025-10-09 02:25:55,079:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000159B0BC9710>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000159B14E5210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:25:55,079:INFO:Checking exceptions
2025-10-09 02:25:55,079:INFO:Importing libraries
2025-10-09 02:25:55,079:INFO:Copying training dataset
2025-10-09 02:25:55,084:INFO:Defining folds
2025-10-09 02:25:55,084:INFO:Declaring metric variables
2025-10-09 02:25:55,087:INFO:Importing untrained model
2025-10-09 02:25:55,091:INFO:Gradient Boosting Regressor Imported successfully
2025-10-09 02:25:55,100:INFO:Starting cross validation
2025-10-09 02:25:55,102:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:25:55,548:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-10-09 02:25:55,548:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-10-09 02:25:55,568:INFO:Calculating mean and std
2025-10-09 02:25:55,569:INFO:Creating metrics dataframe
2025-10-09 02:25:55,571:INFO:Uploading results into container
2025-10-09 02:25:55,572:INFO:Uploading model into container now
2025-10-09 02:25:55,572:INFO:_master_model_container: 16
2025-10-09 02:25:55,572:INFO:_display_container: 2
2025-10-09 02:25:55,573:INFO:GradientBoostingRegressor(random_state=123)
2025-10-09 02:25:55,573:INFO:create_model() successfully completed......................................
2025-10-09 02:25:55,674:INFO:SubProcess create_model() end ==================================
2025-10-09 02:25:55,675:INFO:Creating metrics dataframe
2025-10-09 02:25:55,686:INFO:Initializing Light Gradient Boosting Machine
2025-10-09 02:25:55,686:INFO:Total runtime is 0.3054672479629516 minutes
2025-10-09 02:25:55,690:INFO:SubProcess create_model() called ==================================
2025-10-09 02:25:55,690:INFO:Initializing create_model()
2025-10-09 02:25:55,690:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000159B0BC9710>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000159B14E5210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:25:55,690:INFO:Checking exceptions
2025-10-09 02:25:55,691:INFO:Importing libraries
2025-10-09 02:25:55,691:INFO:Copying training dataset
2025-10-09 02:25:55,695:INFO:Defining folds
2025-10-09 02:25:55,696:INFO:Declaring metric variables
2025-10-09 02:25:55,700:INFO:Importing untrained model
2025-10-09 02:25:55,705:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-09 02:25:55,715:INFO:Starting cross validation
2025-10-09 02:25:55,718:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:25:56,363:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-10-09 02:25:56,364:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-10-09 02:25:56,380:INFO:Calculating mean and std
2025-10-09 02:25:56,381:INFO:Creating metrics dataframe
2025-10-09 02:25:56,385:INFO:Uploading results into container
2025-10-09 02:25:56,386:INFO:Uploading model into container now
2025-10-09 02:25:56,387:INFO:_master_model_container: 17
2025-10-09 02:25:56,387:INFO:_display_container: 2
2025-10-09 02:25:56,388:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-10-09 02:25:56,388:INFO:create_model() successfully completed......................................
2025-10-09 02:25:56,498:INFO:SubProcess create_model() end ==================================
2025-10-09 02:25:56,498:INFO:Creating metrics dataframe
2025-10-09 02:25:56,508:INFO:Initializing Dummy Regressor
2025-10-09 02:25:56,508:INFO:Total runtime is 0.3191703081130981 minutes
2025-10-09 02:25:56,512:INFO:SubProcess create_model() called ==================================
2025-10-09 02:25:56,512:INFO:Initializing create_model()
2025-10-09 02:25:56,512:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000159B0BC9710>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000159B14E5210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:25:56,512:INFO:Checking exceptions
2025-10-09 02:25:56,512:INFO:Importing libraries
2025-10-09 02:25:56,512:INFO:Copying training dataset
2025-10-09 02:25:56,517:INFO:Defining folds
2025-10-09 02:25:56,517:INFO:Declaring metric variables
2025-10-09 02:25:56,523:INFO:Importing untrained model
2025-10-09 02:25:56,527:INFO:Dummy Regressor Imported successfully
2025-10-09 02:25:56,536:INFO:Starting cross validation
2025-10-09 02:25:56,538:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:25:56,828:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\function_base.py:520: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)

2025-10-09 02:25:56,828:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\core\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)

2025-10-09 02:25:56,839:INFO:Calculating mean and std
2025-10-09 02:25:56,840:INFO:Creating metrics dataframe
2025-10-09 02:25:56,842:INFO:Uploading results into container
2025-10-09 02:25:56,843:INFO:Uploading model into container now
2025-10-09 02:25:56,843:INFO:_master_model_container: 18
2025-10-09 02:25:56,844:INFO:_display_container: 2
2025-10-09 02:25:56,844:INFO:DummyRegressor()
2025-10-09 02:25:56,844:INFO:create_model() successfully completed......................................
2025-10-09 02:25:56,928:INFO:SubProcess create_model() end ==================================
2025-10-09 02:25:56,928:INFO:Creating metrics dataframe
2025-10-09 02:25:56,940:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-10-09 02:25:56,948:INFO:Initializing create_model()
2025-10-09 02:25:56,948:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000159B0BC9710>, estimator=Lasso(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:25:56,948:INFO:Checking exceptions
2025-10-09 02:25:56,951:INFO:Importing libraries
2025-10-09 02:25:56,951:INFO:Copying training dataset
2025-10-09 02:25:56,955:INFO:Defining folds
2025-10-09 02:25:56,955:INFO:Declaring metric variables
2025-10-09 02:25:56,955:INFO:Importing untrained model
2025-10-09 02:25:56,955:INFO:Declaring custom model
2025-10-09 02:25:56,956:INFO:Lasso Regression Imported successfully
2025-10-09 02:25:56,957:INFO:Cross validation set to False
2025-10-09 02:25:56,957:INFO:Fitting Model
2025-10-09 02:25:57,012:INFO:Lasso(random_state=123)
2025-10-09 02:25:57,012:INFO:create_model() successfully completed......................................
2025-10-09 02:25:57,137:INFO:_master_model_container: 18
2025-10-09 02:25:57,137:INFO:_display_container: 2
2025-10-09 02:25:57,137:INFO:Lasso(random_state=123)
2025-10-09 02:25:57,137:INFO:compare_models() successfully completed......................................
2025-10-09 02:26:50,658:INFO:PyCaret ClassificationExperiment
2025-10-09 02:26:50,658:INFO:Logging name: clf-default-name
2025-10-09 02:26:50,658:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-10-09 02:26:50,658:INFO:version 3.3.2
2025-10-09 02:26:50,658:INFO:Initializing setup()
2025-10-09 02:26:50,658:INFO:self.USI: 4155
2025-10-09 02:26:50,658:INFO:self._variable_keys: {'y', 'idx', 'seed', 'memory', 'is_multiclass', 'logging_param', 'y_test', '_ml_usecase', 'fix_imbalance', 'fold_generator', 'X_train', 'fold_groups_param', 'log_plots_param', 'data', 'html_param', 'n_jobs_param', 'USI', 'X', 'y_train', 'pipeline', '_available_plots', 'fold_shuffle_param', 'X_test', 'target_param', 'gpu_param', 'exp_id', 'exp_name_log', 'gpu_n_jobs_param'}
2025-10-09 02:26:50,658:INFO:Checking environment
2025-10-09 02:26:50,659:INFO:python_version: 3.11.0
2025-10-09 02:26:50,659:INFO:python_build: ('main', 'Oct 24 2022 18:26:48')
2025-10-09 02:26:50,659:INFO:machine: AMD64
2025-10-09 02:26:50,659:INFO:platform: Windows-10-10.0.19045-SP0
2025-10-09 02:26:50,666:INFO:Memory: svmem(total=12713988096, available=505196544, percent=96.0, used=12208791552, free=505196544)
2025-10-09 02:26:50,666:INFO:Physical Core: 4
2025-10-09 02:26:50,666:INFO:Logical Core: 8
2025-10-09 02:26:50,666:INFO:Checking libraries
2025-10-09 02:26:50,666:INFO:System:
2025-10-09 02:26:50,667:INFO:    python: 3.11.0 (main, Oct 24 2022, 18:26:48) [MSC v.1933 64 bit (AMD64)]
2025-10-09 02:26:50,667:INFO:executable: c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\python.exe
2025-10-09 02:26:50,667:INFO:   machine: Windows-10-10.0.19045-SP0
2025-10-09 02:26:50,667:INFO:PyCaret required dependencies:
2025-10-09 02:26:50,667:INFO:                 pip: 25.2
2025-10-09 02:26:50,667:INFO:          setuptools: 65.5.0
2025-10-09 02:26:50,667:INFO:             pycaret: 3.3.2
2025-10-09 02:26:50,667:INFO:             IPython: 9.6.0
2025-10-09 02:26:50,667:INFO:          ipywidgets: 8.1.7
2025-10-09 02:26:50,667:INFO:                tqdm: 4.67.1
2025-10-09 02:26:50,667:INFO:               numpy: 1.26.4
2025-10-09 02:26:50,667:INFO:              pandas: 2.1.4
2025-10-09 02:26:50,668:INFO:              jinja2: 3.1.6
2025-10-09 02:26:50,668:INFO:               scipy: 1.11.4
2025-10-09 02:26:50,668:INFO:              joblib: 1.3.2
2025-10-09 02:26:50,668:INFO:             sklearn: 1.4.2
2025-10-09 02:26:50,668:INFO:                pyod: 2.0.5
2025-10-09 02:26:50,668:INFO:            imblearn: 0.14.0
2025-10-09 02:26:50,668:INFO:   category_encoders: 2.7.0
2025-10-09 02:26:50,668:INFO:            lightgbm: 4.6.0
2025-10-09 02:26:50,668:INFO:               numba: 0.62.1
2025-10-09 02:26:50,668:INFO:            requests: 2.32.5
2025-10-09 02:26:50,668:INFO:          matplotlib: 3.7.5
2025-10-09 02:26:50,668:INFO:          scikitplot: 0.3.7
2025-10-09 02:26:50,668:INFO:         yellowbrick: 1.5
2025-10-09 02:26:50,668:INFO:              plotly: 6.3.1
2025-10-09 02:26:50,668:INFO:    plotly-resampler: Not installed
2025-10-09 02:26:50,669:INFO:             kaleido: 1.1.0
2025-10-09 02:26:50,669:INFO:           schemdraw: 0.15
2025-10-09 02:26:50,669:INFO:         statsmodels: 0.14.5
2025-10-09 02:26:50,669:INFO:              sktime: 0.26.0
2025-10-09 02:26:50,669:INFO:               tbats: 1.1.3
2025-10-09 02:26:50,669:INFO:            pmdarima: 2.0.4
2025-10-09 02:26:50,669:INFO:              psutil: 7.1.0
2025-10-09 02:26:50,669:INFO:          markupsafe: 3.0.3
2025-10-09 02:26:50,669:INFO:             pickle5: Not installed
2025-10-09 02:26:50,669:INFO:         cloudpickle: 3.1.1
2025-10-09 02:26:50,669:INFO:         deprecation: 2.1.0
2025-10-09 02:26:50,669:INFO:              xxhash: 3.6.0
2025-10-09 02:26:50,669:INFO:           wurlitzer: Not installed
2025-10-09 02:26:50,669:INFO:PyCaret optional dependencies:
2025-10-09 02:26:50,669:INFO:                shap: Not installed
2025-10-09 02:26:50,669:INFO:           interpret: Not installed
2025-10-09 02:26:50,670:INFO:                umap: Not installed
2025-10-09 02:26:50,670:INFO:     ydata_profiling: Not installed
2025-10-09 02:26:50,670:INFO:  explainerdashboard: Not installed
2025-10-09 02:26:50,670:INFO:             autoviz: Not installed
2025-10-09 02:26:50,670:INFO:           fairlearn: Not installed
2025-10-09 02:26:50,670:INFO:          deepchecks: Not installed
2025-10-09 02:26:50,670:INFO:             xgboost: Not installed
2025-10-09 02:26:50,670:INFO:            catboost: Not installed
2025-10-09 02:26:50,670:INFO:              kmodes: Not installed
2025-10-09 02:26:50,670:INFO:             mlxtend: Not installed
2025-10-09 02:26:50,670:INFO:       statsforecast: Not installed
2025-10-09 02:26:50,670:INFO:        tune_sklearn: Not installed
2025-10-09 02:26:50,670:INFO:                 ray: Not installed
2025-10-09 02:26:50,670:INFO:            hyperopt: Not installed
2025-10-09 02:26:50,670:INFO:              optuna: Not installed
2025-10-09 02:26:50,670:INFO:               skopt: Not installed
2025-10-09 02:26:50,671:INFO:              mlflow: Not installed
2025-10-09 02:26:50,671:INFO:              gradio: Not installed
2025-10-09 02:26:50,671:INFO:             fastapi: Not installed
2025-10-09 02:26:50,671:INFO:             uvicorn: Not installed
2025-10-09 02:26:50,671:INFO:              m2cgen: Not installed
2025-10-09 02:26:50,671:INFO:           evidently: Not installed
2025-10-09 02:26:50,671:INFO:               fugue: Not installed
2025-10-09 02:26:50,671:INFO:           streamlit: Not installed
2025-10-09 02:26:50,671:INFO:             prophet: Not installed
2025-10-09 02:26:50,671:INFO:None
2025-10-09 02:26:50,671:INFO:Set up data.
2025-10-09 02:26:50,678:INFO:Set up folding strategy.
2025-10-09 02:26:50,678:INFO:Set up train/test split.
2025-10-09 02:26:50,685:INFO:Set up index.
2025-10-09 02:26:50,686:INFO:Assigning column types.
2025-10-09 02:26:50,691:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-09 02:26:50,758:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-09 02:26:50,765:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-09 02:26:50,810:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 02:26:50,810:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 02:26:50,864:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-09 02:26:50,865:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-09 02:26:50,894:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 02:26:50,895:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 02:26:50,895:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-09 02:26:50,938:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-09 02:26:50,963:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 02:26:50,964:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 02:26:51,014:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-09 02:26:51,050:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 02:26:51,050:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 02:26:51,051:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-10-09 02:26:51,123:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 02:26:51,123:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 02:26:51,200:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 02:26:51,200:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 02:26:51,202:INFO:Preparing preprocessing pipeline...
2025-10-09 02:26:51,203:INFO:Set up simple imputation.
2025-10-09 02:26:51,205:INFO:Set up encoding of ordinal features.
2025-10-09 02:26:51,206:INFO:Set up encoding of categorical features.
2025-10-09 02:26:51,206:INFO:Set up feature normalization.
2025-10-09 02:26:51,291:INFO:Finished creating preprocessing pipeline.
2025-10-09 02:26:51,318:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\jjqs_\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'ingresos_mensuales',
                                             'nro_creditos_previos',
                                             'cuota_vs_ingreso'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'...
                                    include=['estado_civil',
                                             'historia_credito'],
                                    transformer=OneHotEncoder(cols=['estado_civil',
                                                                    'historia_credito'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-10-09 02:26:51,318:INFO:Creating final display dataframe.
2025-10-09 02:26:51,568:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target           default
2                   Target type            Binary
3           Original data shape          (150, 8)
4        Transformed data shape         (150, 12)
5   Transformed train set shape         (105, 12)
6    Transformed test set shape          (45, 12)
7              Numeric features                 4
8          Categorical features                 3
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                    Normalize              True
16             Normalize method            zscore
17               Fold Generator   StratifiedKFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  clf-default-name
23                          USI              4155
2025-10-09 02:26:51,677:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 02:26:51,677:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 02:26:51,756:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 02:26:51,756:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 02:26:51,758:INFO:setup() successfully completed in 1.1s...............
2025-10-09 02:26:54,505:INFO:Initializing compare_models()
2025-10-09 02:26:54,506:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000159B1726090>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000159B1726090>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-10-09 02:26:54,506:INFO:Checking exceptions
2025-10-09 02:26:54,517:INFO:Preparing display monitor
2025-10-09 02:26:54,542:INFO:Initializing Logistic Regression
2025-10-09 02:26:54,543:INFO:Total runtime is 1.6705195109049478e-05 minutes
2025-10-09 02:26:54,547:INFO:SubProcess create_model() called ==================================
2025-10-09 02:26:54,547:INFO:Initializing create_model()
2025-10-09 02:26:54,548:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000159B1726090>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000159B1153190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:26:54,548:INFO:Checking exceptions
2025-10-09 02:26:54,548:INFO:Importing libraries
2025-10-09 02:26:54,548:INFO:Copying training dataset
2025-10-09 02:26:54,556:INFO:Defining folds
2025-10-09 02:26:54,556:INFO:Declaring metric variables
2025-10-09 02:26:54,561:INFO:Importing untrained model
2025-10-09 02:26:54,566:INFO:Logistic Regression Imported successfully
2025-10-09 02:26:54,576:INFO:Starting cross validation
2025-10-09 02:26:54,579:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:26:54,888:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:26:54,958:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:26:54,983:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:26:54,984:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:26:54,985:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:26:54,994:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:26:55,005:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:26:55,123:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:26:55,135:INFO:Calculating mean and std
2025-10-09 02:26:55,135:INFO:Creating metrics dataframe
2025-10-09 02:26:55,137:INFO:Uploading results into container
2025-10-09 02:26:55,137:INFO:Uploading model into container now
2025-10-09 02:26:55,138:INFO:_master_model_container: 1
2025-10-09 02:26:55,138:INFO:_display_container: 2
2025-10-09 02:26:55,138:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-09 02:26:55,139:INFO:create_model() successfully completed......................................
2025-10-09 02:26:55,231:INFO:SubProcess create_model() end ==================================
2025-10-09 02:26:55,231:INFO:Creating metrics dataframe
2025-10-09 02:26:55,237:INFO:Initializing K Neighbors Classifier
2025-10-09 02:26:55,237:INFO:Total runtime is 0.011581393082936604 minutes
2025-10-09 02:26:55,240:INFO:SubProcess create_model() called ==================================
2025-10-09 02:26:55,241:INFO:Initializing create_model()
2025-10-09 02:26:55,241:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000159B1726090>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000159B1153190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:26:55,241:INFO:Checking exceptions
2025-10-09 02:26:55,241:INFO:Importing libraries
2025-10-09 02:26:55,241:INFO:Copying training dataset
2025-10-09 02:26:55,246:INFO:Defining folds
2025-10-09 02:26:55,247:INFO:Declaring metric variables
2025-10-09 02:26:55,252:INFO:Importing untrained model
2025-10-09 02:26:55,257:INFO:K Neighbors Classifier Imported successfully
2025-10-09 02:26:55,268:INFO:Starting cross validation
2025-10-09 02:26:55,270:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:26:55,563:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:26:55,565:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:26:55,580:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:26:55,589:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:26:55,590:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:26:55,724:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:26:55,743:INFO:Calculating mean and std
2025-10-09 02:26:55,744:INFO:Creating metrics dataframe
2025-10-09 02:26:55,746:INFO:Uploading results into container
2025-10-09 02:26:55,746:INFO:Uploading model into container now
2025-10-09 02:26:55,747:INFO:_master_model_container: 2
2025-10-09 02:26:55,747:INFO:_display_container: 2
2025-10-09 02:26:55,747:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-10-09 02:26:55,747:INFO:create_model() successfully completed......................................
2025-10-09 02:26:55,831:INFO:SubProcess create_model() end ==================================
2025-10-09 02:26:55,831:INFO:Creating metrics dataframe
2025-10-09 02:26:55,839:INFO:Initializing Naive Bayes
2025-10-09 02:26:55,839:INFO:Total runtime is 0.021607895692189533 minutes
2025-10-09 02:26:55,845:INFO:SubProcess create_model() called ==================================
2025-10-09 02:26:55,845:INFO:Initializing create_model()
2025-10-09 02:26:55,845:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000159B1726090>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000159B1153190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:26:55,845:INFO:Checking exceptions
2025-10-09 02:26:55,845:INFO:Importing libraries
2025-10-09 02:26:55,845:INFO:Copying training dataset
2025-10-09 02:26:55,850:INFO:Defining folds
2025-10-09 02:26:55,850:INFO:Declaring metric variables
2025-10-09 02:26:55,853:INFO:Importing untrained model
2025-10-09 02:26:55,857:INFO:Naive Bayes Imported successfully
2025-10-09 02:26:55,866:INFO:Starting cross validation
2025-10-09 02:26:55,867:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:26:56,056:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:26:56,065:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:26:56,067:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:26:56,217:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:26:56,228:INFO:Calculating mean and std
2025-10-09 02:26:56,229:INFO:Creating metrics dataframe
2025-10-09 02:26:56,233:INFO:Uploading results into container
2025-10-09 02:26:56,233:INFO:Uploading model into container now
2025-10-09 02:26:56,234:INFO:_master_model_container: 3
2025-10-09 02:26:56,234:INFO:_display_container: 2
2025-10-09 02:26:56,234:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-10-09 02:26:56,234:INFO:create_model() successfully completed......................................
2025-10-09 02:26:56,328:INFO:SubProcess create_model() end ==================================
2025-10-09 02:26:56,328:INFO:Creating metrics dataframe
2025-10-09 02:26:56,335:INFO:Initializing Decision Tree Classifier
2025-10-09 02:26:56,335:INFO:Total runtime is 0.029876224199930825 minutes
2025-10-09 02:26:56,339:INFO:SubProcess create_model() called ==================================
2025-10-09 02:26:56,339:INFO:Initializing create_model()
2025-10-09 02:26:56,339:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000159B1726090>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000159B1153190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:26:56,339:INFO:Checking exceptions
2025-10-09 02:26:56,339:INFO:Importing libraries
2025-10-09 02:26:56,339:INFO:Copying training dataset
2025-10-09 02:26:56,345:INFO:Defining folds
2025-10-09 02:26:56,345:INFO:Declaring metric variables
2025-10-09 02:26:56,349:INFO:Importing untrained model
2025-10-09 02:26:56,354:INFO:Decision Tree Classifier Imported successfully
2025-10-09 02:26:56,363:INFO:Starting cross validation
2025-10-09 02:26:56,364:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:26:56,671:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:26:56,783:INFO:Calculating mean and std
2025-10-09 02:26:56,785:INFO:Creating metrics dataframe
2025-10-09 02:26:56,789:INFO:Uploading results into container
2025-10-09 02:26:56,790:INFO:Uploading model into container now
2025-10-09 02:26:56,790:INFO:_master_model_container: 4
2025-10-09 02:26:56,791:INFO:_display_container: 2
2025-10-09 02:26:56,791:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-10-09 02:26:56,792:INFO:create_model() successfully completed......................................
2025-10-09 02:26:56,912:INFO:SubProcess create_model() end ==================================
2025-10-09 02:26:56,912:INFO:Creating metrics dataframe
2025-10-09 02:26:56,925:INFO:Initializing SVM - Linear Kernel
2025-10-09 02:26:56,925:INFO:Total runtime is 0.03970530827840169 minutes
2025-10-09 02:26:56,931:INFO:SubProcess create_model() called ==================================
2025-10-09 02:26:56,932:INFO:Initializing create_model()
2025-10-09 02:26:56,932:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000159B1726090>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000159B1153190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:26:56,932:INFO:Checking exceptions
2025-10-09 02:26:56,932:INFO:Importing libraries
2025-10-09 02:26:56,932:INFO:Copying training dataset
2025-10-09 02:26:56,940:INFO:Defining folds
2025-10-09 02:26:56,940:INFO:Declaring metric variables
2025-10-09 02:26:56,946:INFO:Importing untrained model
2025-10-09 02:26:56,952:INFO:SVM - Linear Kernel Imported successfully
2025-10-09 02:26:56,965:INFO:Starting cross validation
2025-10-09 02:26:56,968:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:26:57,210:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:26:57,250:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:26:57,324:INFO:Calculating mean and std
2025-10-09 02:26:57,325:INFO:Creating metrics dataframe
2025-10-09 02:26:57,327:INFO:Uploading results into container
2025-10-09 02:26:57,328:INFO:Uploading model into container now
2025-10-09 02:26:57,328:INFO:_master_model_container: 5
2025-10-09 02:26:57,329:INFO:_display_container: 2
2025-10-09 02:26:57,329:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-10-09 02:26:57,329:INFO:create_model() successfully completed......................................
2025-10-09 02:26:57,417:INFO:SubProcess create_model() end ==================================
2025-10-09 02:26:57,417:INFO:Creating metrics dataframe
2025-10-09 02:26:57,425:INFO:Initializing Ridge Classifier
2025-10-09 02:26:57,425:INFO:Total runtime is 0.04804227352142334 minutes
2025-10-09 02:26:57,429:INFO:SubProcess create_model() called ==================================
2025-10-09 02:26:57,429:INFO:Initializing create_model()
2025-10-09 02:26:57,429:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000159B1726090>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000159B1153190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:26:57,429:INFO:Checking exceptions
2025-10-09 02:26:57,429:INFO:Importing libraries
2025-10-09 02:26:57,430:INFO:Copying training dataset
2025-10-09 02:26:57,435:INFO:Defining folds
2025-10-09 02:26:57,435:INFO:Declaring metric variables
2025-10-09 02:26:57,440:INFO:Importing untrained model
2025-10-09 02:26:57,445:INFO:Ridge Classifier Imported successfully
2025-10-09 02:26:57,456:INFO:Starting cross validation
2025-10-09 02:26:57,458:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:26:57,648:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:26:57,651:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:26:57,664:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:26:57,665:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:26:57,690:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:26:57,693:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:26:57,706:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:26:57,786:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:26:57,787:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:26:57,802:INFO:Calculating mean and std
2025-10-09 02:26:57,803:INFO:Creating metrics dataframe
2025-10-09 02:26:57,805:INFO:Uploading results into container
2025-10-09 02:26:57,806:INFO:Uploading model into container now
2025-10-09 02:26:57,806:INFO:_master_model_container: 6
2025-10-09 02:26:57,806:INFO:_display_container: 2
2025-10-09 02:26:57,807:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-10-09 02:26:57,807:INFO:create_model() successfully completed......................................
2025-10-09 02:26:57,892:INFO:SubProcess create_model() end ==================================
2025-10-09 02:26:57,892:INFO:Creating metrics dataframe
2025-10-09 02:26:57,900:INFO:Initializing Random Forest Classifier
2025-10-09 02:26:57,900:INFO:Total runtime is 0.055970760186513265 minutes
2025-10-09 02:26:57,903:INFO:SubProcess create_model() called ==================================
2025-10-09 02:26:57,904:INFO:Initializing create_model()
2025-10-09 02:26:57,904:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000159B1726090>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000159B1153190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:26:57,904:INFO:Checking exceptions
2025-10-09 02:26:57,904:INFO:Importing libraries
2025-10-09 02:26:57,904:INFO:Copying training dataset
2025-10-09 02:26:57,909:INFO:Defining folds
2025-10-09 02:26:57,909:INFO:Declaring metric variables
2025-10-09 02:26:57,913:INFO:Importing untrained model
2025-10-09 02:26:57,919:INFO:Random Forest Classifier Imported successfully
2025-10-09 02:26:57,928:INFO:Starting cross validation
2025-10-09 02:26:57,930:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:26:58,441:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:26:58,442:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:26:58,448:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:26:58,463:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:26:58,541:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:26:58,664:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:26:58,683:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:26:58,867:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:26:58,884:INFO:Calculating mean and std
2025-10-09 02:26:58,886:INFO:Creating metrics dataframe
2025-10-09 02:26:58,888:INFO:Uploading results into container
2025-10-09 02:26:58,889:INFO:Uploading model into container now
2025-10-09 02:26:58,890:INFO:_master_model_container: 7
2025-10-09 02:26:58,891:INFO:_display_container: 2
2025-10-09 02:26:58,892:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-10-09 02:26:58,892:INFO:create_model() successfully completed......................................
2025-10-09 02:26:59,074:INFO:SubProcess create_model() end ==================================
2025-10-09 02:26:59,074:INFO:Creating metrics dataframe
2025-10-09 02:26:59,084:INFO:Initializing Quadratic Discriminant Analysis
2025-10-09 02:26:59,084:INFO:Total runtime is 0.07569867769877116 minutes
2025-10-09 02:26:59,088:INFO:SubProcess create_model() called ==================================
2025-10-09 02:26:59,088:INFO:Initializing create_model()
2025-10-09 02:26:59,088:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000159B1726090>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000159B1153190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:26:59,088:INFO:Checking exceptions
2025-10-09 02:26:59,089:INFO:Importing libraries
2025-10-09 02:26:59,089:INFO:Copying training dataset
2025-10-09 02:26:59,094:INFO:Defining folds
2025-10-09 02:26:59,094:INFO:Declaring metric variables
2025-10-09 02:26:59,100:INFO:Importing untrained model
2025-10-09 02:26:59,105:INFO:Quadratic Discriminant Analysis Imported successfully
2025-10-09 02:26:59,116:INFO:Starting cross validation
2025-10-09 02:26:59,118:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:26:59,249:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 02:26:59,249:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 02:26:59,249:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 02:26:59,252:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 02:26:59,266:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 02:26:59,268:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 02:26:59,284:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 02:26:59,296:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 02:26:59,336:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:26:59,404:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 02:26:59,419:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 02:26:59,455:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:26:59,465:INFO:Calculating mean and std
2025-10-09 02:26:59,467:INFO:Creating metrics dataframe
2025-10-09 02:26:59,469:INFO:Uploading results into container
2025-10-09 02:26:59,469:INFO:Uploading model into container now
2025-10-09 02:26:59,470:INFO:_master_model_container: 8
2025-10-09 02:26:59,470:INFO:_display_container: 2
2025-10-09 02:26:59,470:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-10-09 02:26:59,470:INFO:create_model() successfully completed......................................
2025-10-09 02:26:59,561:INFO:SubProcess create_model() end ==================================
2025-10-09 02:26:59,561:INFO:Creating metrics dataframe
2025-10-09 02:26:59,568:INFO:Initializing Ada Boost Classifier
2025-10-09 02:26:59,569:INFO:Total runtime is 0.08377452691396077 minutes
2025-10-09 02:26:59,572:INFO:SubProcess create_model() called ==================================
2025-10-09 02:26:59,572:INFO:Initializing create_model()
2025-10-09 02:26:59,572:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000159B1726090>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000159B1153190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:26:59,572:INFO:Checking exceptions
2025-10-09 02:26:59,573:INFO:Importing libraries
2025-10-09 02:26:59,573:INFO:Copying training dataset
2025-10-09 02:26:59,577:INFO:Defining folds
2025-10-09 02:26:59,577:INFO:Declaring metric variables
2025-10-09 02:26:59,581:INFO:Importing untrained model
2025-10-09 02:26:59,586:INFO:Ada Boost Classifier Imported successfully
2025-10-09 02:26:59,594:INFO:Starting cross validation
2025-10-09 02:26:59,597:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:26:59,728:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 02:26:59,728:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 02:26:59,729:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 02:26:59,734:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 02:26:59,745:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 02:26:59,750:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 02:26:59,761:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 02:26:59,765:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 02:26:59,988:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:27:00,007:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:27:00,112:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 02:27:00,126:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 02:27:00,316:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:27:00,316:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:27:00,334:INFO:Calculating mean and std
2025-10-09 02:27:00,335:INFO:Creating metrics dataframe
2025-10-09 02:27:00,338:INFO:Uploading results into container
2025-10-09 02:27:00,339:INFO:Uploading model into container now
2025-10-09 02:27:00,341:INFO:_master_model_container: 9
2025-10-09 02:27:00,341:INFO:_display_container: 2
2025-10-09 02:27:00,342:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-10-09 02:27:00,342:INFO:create_model() successfully completed......................................
2025-10-09 02:27:00,443:INFO:SubProcess create_model() end ==================================
2025-10-09 02:27:00,443:INFO:Creating metrics dataframe
2025-10-09 02:27:00,453:INFO:Initializing Gradient Boosting Classifier
2025-10-09 02:27:00,453:INFO:Total runtime is 0.09850833813349405 minutes
2025-10-09 02:27:00,456:INFO:SubProcess create_model() called ==================================
2025-10-09 02:27:00,457:INFO:Initializing create_model()
2025-10-09 02:27:00,457:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000159B1726090>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000159B1153190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:27:00,457:INFO:Checking exceptions
2025-10-09 02:27:00,457:INFO:Importing libraries
2025-10-09 02:27:00,457:INFO:Copying training dataset
2025-10-09 02:27:00,462:INFO:Defining folds
2025-10-09 02:27:00,462:INFO:Declaring metric variables
2025-10-09 02:27:00,466:INFO:Importing untrained model
2025-10-09 02:27:00,470:INFO:Gradient Boosting Classifier Imported successfully
2025-10-09 02:27:00,479:INFO:Starting cross validation
2025-10-09 02:27:00,481:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:27:01,020:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:27:01,169:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:27:01,185:INFO:Calculating mean and std
2025-10-09 02:27:01,186:INFO:Creating metrics dataframe
2025-10-09 02:27:01,188:INFO:Uploading results into container
2025-10-09 02:27:01,189:INFO:Uploading model into container now
2025-10-09 02:27:01,189:INFO:_master_model_container: 10
2025-10-09 02:27:01,189:INFO:_display_container: 2
2025-10-09 02:27:01,190:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-09 02:27:01,190:INFO:create_model() successfully completed......................................
2025-10-09 02:27:01,280:INFO:SubProcess create_model() end ==================================
2025-10-09 02:27:01,281:INFO:Creating metrics dataframe
2025-10-09 02:27:01,290:INFO:Initializing Linear Discriminant Analysis
2025-10-09 02:27:01,290:INFO:Total runtime is 0.11246996720631916 minutes
2025-10-09 02:27:01,295:INFO:SubProcess create_model() called ==================================
2025-10-09 02:27:01,295:INFO:Initializing create_model()
2025-10-09 02:27:01,295:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000159B1726090>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000159B1153190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:27:01,295:INFO:Checking exceptions
2025-10-09 02:27:01,295:INFO:Importing libraries
2025-10-09 02:27:01,295:INFO:Copying training dataset
2025-10-09 02:27:01,300:INFO:Defining folds
2025-10-09 02:27:01,300:INFO:Declaring metric variables
2025-10-09 02:27:01,305:INFO:Importing untrained model
2025-10-09 02:27:01,309:INFO:Linear Discriminant Analysis Imported successfully
2025-10-09 02:27:01,319:INFO:Starting cross validation
2025-10-09 02:27:01,321:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:27:01,471:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:27:01,481:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:27:01,522:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:27:01,523:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:27:01,540:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:27:01,613:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:27:01,628:INFO:Calculating mean and std
2025-10-09 02:27:01,629:INFO:Creating metrics dataframe
2025-10-09 02:27:01,633:INFO:Uploading results into container
2025-10-09 02:27:01,634:INFO:Uploading model into container now
2025-10-09 02:27:01,635:INFO:_master_model_container: 11
2025-10-09 02:27:01,635:INFO:_display_container: 2
2025-10-09 02:27:01,636:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-09 02:27:01,636:INFO:create_model() successfully completed......................................
2025-10-09 02:27:01,734:INFO:SubProcess create_model() end ==================================
2025-10-09 02:27:01,735:INFO:Creating metrics dataframe
2025-10-09 02:27:01,745:INFO:Initializing Extra Trees Classifier
2025-10-09 02:27:01,745:INFO:Total runtime is 0.12005210320154824 minutes
2025-10-09 02:27:01,750:INFO:SubProcess create_model() called ==================================
2025-10-09 02:27:01,750:INFO:Initializing create_model()
2025-10-09 02:27:01,750:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000159B1726090>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000159B1153190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:27:01,751:INFO:Checking exceptions
2025-10-09 02:27:01,751:INFO:Importing libraries
2025-10-09 02:27:01,751:INFO:Copying training dataset
2025-10-09 02:27:01,757:INFO:Defining folds
2025-10-09 02:27:01,757:INFO:Declaring metric variables
2025-10-09 02:27:01,761:INFO:Importing untrained model
2025-10-09 02:27:01,766:INFO:Extra Trees Classifier Imported successfully
2025-10-09 02:27:01,777:INFO:Starting cross validation
2025-10-09 02:27:01,780:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:27:02,230:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:27:02,250:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:27:02,282:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:27:02,491:INFO:Calculating mean and std
2025-10-09 02:27:02,492:INFO:Creating metrics dataframe
2025-10-09 02:27:02,494:INFO:Uploading results into container
2025-10-09 02:27:02,495:INFO:Uploading model into container now
2025-10-09 02:27:02,495:INFO:_master_model_container: 12
2025-10-09 02:27:02,495:INFO:_display_container: 2
2025-10-09 02:27:02,496:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-10-09 02:27:02,496:INFO:create_model() successfully completed......................................
2025-10-09 02:27:02,607:INFO:SubProcess create_model() end ==================================
2025-10-09 02:27:02,607:INFO:Creating metrics dataframe
2025-10-09 02:27:02,620:INFO:Initializing Light Gradient Boosting Machine
2025-10-09 02:27:02,621:INFO:Total runtime is 0.1346464236577352 minutes
2025-10-09 02:27:02,624:INFO:SubProcess create_model() called ==================================
2025-10-09 02:27:02,625:INFO:Initializing create_model()
2025-10-09 02:27:02,625:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000159B1726090>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000159B1153190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:27:02,625:INFO:Checking exceptions
2025-10-09 02:27:02,625:INFO:Importing libraries
2025-10-09 02:27:02,626:INFO:Copying training dataset
2025-10-09 02:27:02,631:INFO:Defining folds
2025-10-09 02:27:02,632:INFO:Declaring metric variables
2025-10-09 02:27:02,636:INFO:Importing untrained model
2025-10-09 02:27:02,642:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-09 02:27:02,663:INFO:Starting cross validation
2025-10-09 02:27:02,669:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:27:02,935:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:27:02,935:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:27:02,987:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:27:03,052:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:27:03,107:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:27:03,204:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:27:03,220:INFO:Calculating mean and std
2025-10-09 02:27:03,222:INFO:Creating metrics dataframe
2025-10-09 02:27:03,224:INFO:Uploading results into container
2025-10-09 02:27:03,225:INFO:Uploading model into container now
2025-10-09 02:27:03,226:INFO:_master_model_container: 13
2025-10-09 02:27:03,226:INFO:_display_container: 2
2025-10-09 02:27:03,227:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-09 02:27:03,227:INFO:create_model() successfully completed......................................
2025-10-09 02:27:03,336:INFO:SubProcess create_model() end ==================================
2025-10-09 02:27:03,337:INFO:Creating metrics dataframe
2025-10-09 02:27:03,348:INFO:Initializing Dummy Classifier
2025-10-09 02:27:03,349:INFO:Total runtime is 0.14678446451822916 minutes
2025-10-09 02:27:03,352:INFO:SubProcess create_model() called ==================================
2025-10-09 02:27:03,352:INFO:Initializing create_model()
2025-10-09 02:27:03,352:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000159B1726090>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000159B1153190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:27:03,353:INFO:Checking exceptions
2025-10-09 02:27:03,353:INFO:Importing libraries
2025-10-09 02:27:03,353:INFO:Copying training dataset
2025-10-09 02:27:03,358:INFO:Defining folds
2025-10-09 02:27:03,358:INFO:Declaring metric variables
2025-10-09 02:27:03,363:INFO:Importing untrained model
2025-10-09 02:27:03,367:INFO:Dummy Classifier Imported successfully
2025-10-09 02:27:03,376:INFO:Starting cross validation
2025-10-09 02:27:03,378:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:27:03,527:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:27:03,543:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:27:03,543:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:27:03,545:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:27:03,547:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:27:03,557:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:27:03,575:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:27:03,597:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:27:03,649:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:27:03,668:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:27:03,685:INFO:Calculating mean and std
2025-10-09 02:27:03,686:INFO:Creating metrics dataframe
2025-10-09 02:27:03,689:INFO:Uploading results into container
2025-10-09 02:27:03,689:INFO:Uploading model into container now
2025-10-09 02:27:03,690:INFO:_master_model_container: 14
2025-10-09 02:27:03,690:INFO:_display_container: 2
2025-10-09 02:27:03,690:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-10-09 02:27:03,690:INFO:create_model() successfully completed......................................
2025-10-09 02:27:03,793:INFO:SubProcess create_model() end ==================================
2025-10-09 02:27:03,794:INFO:Creating metrics dataframe
2025-10-09 02:27:03,805:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-10-09 02:27:03,814:INFO:Initializing create_model()
2025-10-09 02:27:03,814:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000159B1726090>, estimator=DummyClassifier(constant=None, random_state=123, strategy='prior'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:27:03,814:INFO:Checking exceptions
2025-10-09 02:27:03,816:INFO:Importing libraries
2025-10-09 02:27:03,816:INFO:Copying training dataset
2025-10-09 02:27:03,821:INFO:Defining folds
2025-10-09 02:27:03,821:INFO:Declaring metric variables
2025-10-09 02:27:03,821:INFO:Importing untrained model
2025-10-09 02:27:03,822:INFO:Declaring custom model
2025-10-09 02:27:03,822:INFO:Dummy Classifier Imported successfully
2025-10-09 02:27:03,824:INFO:Cross validation set to False
2025-10-09 02:27:03,824:INFO:Fitting Model
2025-10-09 02:27:03,874:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-10-09 02:27:03,874:INFO:create_model() successfully completed......................................
2025-10-09 02:27:04,050:INFO:_master_model_container: 14
2025-10-09 02:27:04,050:INFO:_display_container: 2
2025-10-09 02:27:04,050:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-10-09 02:27:04,050:INFO:compare_models() successfully completed......................................
2025-10-09 02:27:35,024:INFO:Initializing create_model()
2025-10-09 02:27:35,025:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000159B1726090>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:27:35,025:INFO:Checking exceptions
2025-10-09 02:27:35,046:INFO:Importing libraries
2025-10-09 02:27:35,046:INFO:Copying training dataset
2025-10-09 02:27:35,053:INFO:Defining folds
2025-10-09 02:27:35,054:INFO:Declaring metric variables
2025-10-09 02:27:35,059:INFO:Importing untrained model
2025-10-09 02:27:35,066:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-09 02:27:35,078:INFO:Starting cross validation
2025-10-09 02:27:35,083:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:27:35,790:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:27:35,854:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:27:36,126:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:27:36,244:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:27:36,250:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:27:36,348:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:27:36,365:INFO:Calculating mean and std
2025-10-09 02:27:36,367:INFO:Creating metrics dataframe
2025-10-09 02:27:36,374:INFO:Finalizing model
2025-10-09 02:27:36,459:INFO:[LightGBM] [Info] Number of positive: 18, number of negative: 87
2025-10-09 02:27:36,459:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000039 seconds.
2025-10-09 02:27:36,459:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-09 02:27:36,459:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-09 02:27:36,460:INFO:[LightGBM] [Info] Total Bins 117
2025-10-09 02:27:36,460:INFO:[LightGBM] [Info] Number of data points in the train set: 105, number of used features: 10
2025-10-09 02:27:36,460:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.171429 -> initscore=-1.575536
2025-10-09 02:27:36,460:INFO:[LightGBM] [Info] Start training from score -1.575536
2025-10-09 02:27:36,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:27:36,500:INFO:Uploading results into container
2025-10-09 02:27:36,501:INFO:Uploading model into container now
2025-10-09 02:27:36,517:INFO:_master_model_container: 15
2025-10-09 02:27:36,517:INFO:_display_container: 3
2025-10-09 02:27:36,518:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-09 02:27:36,518:INFO:create_model() successfully completed......................................
2025-10-09 02:27:53,797:INFO:Initializing tune_model()
2025-10-09 02:27:53,797:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000159B1726090>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-10-09 02:27:53,797:INFO:Checking exceptions
2025-10-09 02:27:53,814:INFO:Copying training dataset
2025-10-09 02:27:53,819:INFO:Checking base model
2025-10-09 02:27:53,819:INFO:Base model : Light Gradient Boosting Machine
2025-10-09 02:27:53,825:INFO:Declaring metric variables
2025-10-09 02:27:53,829:INFO:Defining Hyperparameters
2025-10-09 02:27:53,948:INFO:Tuning with n_jobs=-1
2025-10-09 02:27:53,948:INFO:Initializing RandomizedSearchCV
2025-10-09 02:28:02,737:INFO:best_params: {'actual_estimator__reg_lambda': 1e-06, 'actual_estimator__reg_alpha': 4, 'actual_estimator__num_leaves': 80, 'actual_estimator__n_estimators': 130, 'actual_estimator__min_split_gain': 0.5, 'actual_estimator__min_child_samples': 91, 'actual_estimator__learning_rate': 1e-07, 'actual_estimator__feature_fraction': 0.9, 'actual_estimator__bagging_freq': 0, 'actual_estimator__bagging_fraction': 0.5}
2025-10-09 02:28:02,738:INFO:Hyperparameter search completed
2025-10-09 02:28:02,738:INFO:SubProcess create_model() called ==================================
2025-10-09 02:28:02,739:INFO:Initializing create_model()
2025-10-09 02:28:02,739:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000159B1726090>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000159B1199E50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 1e-06, 'reg_alpha': 4, 'num_leaves': 80, 'n_estimators': 130, 'min_split_gain': 0.5, 'min_child_samples': 91, 'learning_rate': 1e-07, 'feature_fraction': 0.9, 'bagging_freq': 0, 'bagging_fraction': 0.5})
2025-10-09 02:28:02,740:INFO:Checking exceptions
2025-10-09 02:28:02,740:INFO:Importing libraries
2025-10-09 02:28:02,740:INFO:Copying training dataset
2025-10-09 02:28:02,746:INFO:Defining folds
2025-10-09 02:28:02,746:INFO:Declaring metric variables
2025-10-09 02:28:02,751:INFO:Importing untrained model
2025-10-09 02:28:02,751:INFO:Declaring custom model
2025-10-09 02:28:02,757:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-09 02:28:02,768:INFO:Starting cross validation
2025-10-09 02:28:02,770:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:28:03,095:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:28:03,107:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:28:03,134:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:28:03,242:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:28:03,246:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:28:03,271:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:28:03,273:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:28:03,356:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:28:03,368:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:28:03,374:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:28:03,389:INFO:Calculating mean and std
2025-10-09 02:28:03,391:INFO:Creating metrics dataframe
2025-10-09 02:28:03,403:INFO:Finalizing model
2025-10-09 02:28:03,516:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2025-10-09 02:28:03,516:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2025-10-09 02:28:03,516:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-10-09 02:28:03,516:INFO:[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.
2025-10-09 02:28:03,517:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2025-10-09 02:28:03,517:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2025-10-09 02:28:03,517:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-10-09 02:28:03,517:INFO:[LightGBM] [Info] Number of positive: 18, number of negative: 87
2025-10-09 02:28:03,517:INFO:[LightGBM] [Info] Total Bins 0
2025-10-09 02:28:03,517:INFO:[LightGBM] [Info] Number of data points in the train set: 105, number of used features: 0
2025-10-09 02:28:03,517:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.171429 -> initscore=-1.575536
2025-10-09 02:28:03,518:INFO:[LightGBM] [Info] Start training from score -1.575536
2025-10-09 02:28:03,518:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,518:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,519:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,519:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,519:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,519:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,519:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,519:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,520:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,520:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,520:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,520:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,520:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,520:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,520:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,520:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,520:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,520:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,520:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,521:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,521:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,521:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,521:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,521:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,521:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,521:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,521:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,521:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,521:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,522:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,522:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,522:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,522:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,522:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,522:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,522:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,522:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,522:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,523:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,523:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,523:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,523:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,523:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,523:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,523:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,523:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,523:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,524:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,524:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,524:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,524:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,524:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,524:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,524:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,524:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,524:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,524:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,525:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,526:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,527:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,527:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,527:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,528:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,528:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,528:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,529:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,529:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,529:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,529:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,529:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,529:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,529:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,529:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,529:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,529:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,530:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,530:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,530:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,530:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,530:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,530:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,530:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,530:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,530:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,530:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,531:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,532:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,533:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,533:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,533:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,533:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,533:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,533:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,533:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,534:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,534:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,534:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,534:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,534:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,534:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,534:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,534:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,534:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,535:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,535:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,535:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,535:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,535:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,535:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,535:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,535:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,535:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,536:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,536:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,536:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,536:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,536:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,536:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,536:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,537:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,537:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,537:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,537:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,537:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,537:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,537:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,537:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,537:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,537:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,538:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:28:03,545:INFO:Uploading results into container
2025-10-09 02:28:03,546:INFO:Uploading model into container now
2025-10-09 02:28:03,548:INFO:_master_model_container: 16
2025-10-09 02:28:03,548:INFO:_display_container: 4
2025-10-09 02:28:03,549:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-09 02:28:03,549:INFO:create_model() successfully completed......................................
2025-10-09 02:28:03,668:INFO:SubProcess create_model() end ==================================
2025-10-09 02:28:03,668:INFO:choose_better activated
2025-10-09 02:28:03,673:INFO:SubProcess create_model() called ==================================
2025-10-09 02:28:03,674:INFO:Initializing create_model()
2025-10-09 02:28:03,674:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000159B1726090>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:28:03,674:INFO:Checking exceptions
2025-10-09 02:28:03,676:INFO:Importing libraries
2025-10-09 02:28:03,676:INFO:Copying training dataset
2025-10-09 02:28:03,682:INFO:Defining folds
2025-10-09 02:28:03,682:INFO:Declaring metric variables
2025-10-09 02:28:03,683:INFO:Importing untrained model
2025-10-09 02:28:03,683:INFO:Declaring custom model
2025-10-09 02:28:03,684:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-09 02:28:03,684:INFO:Starting cross validation
2025-10-09 02:28:03,686:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:28:04,050:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:28:04,051:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:28:04,161:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:28:04,284:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:28:04,335:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:28:04,382:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:28:04,399:INFO:Calculating mean and std
2025-10-09 02:28:04,399:INFO:Creating metrics dataframe
2025-10-09 02:28:04,401:INFO:Finalizing model
2025-10-09 02:28:04,474:INFO:[LightGBM] [Info] Number of positive: 18, number of negative: 87
2025-10-09 02:28:04,474:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000141 seconds.
2025-10-09 02:28:04,474:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-10-09 02:28:04,474:INFO:[LightGBM] [Info] Total Bins 117
2025-10-09 02:28:04,474:INFO:[LightGBM] [Info] Number of data points in the train set: 105, number of used features: 10
2025-10-09 02:28:04,475:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.171429 -> initscore=-1.575536
2025-10-09 02:28:04,475:INFO:[LightGBM] [Info] Start training from score -1.575536
2025-10-09 02:28:04,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:28:04,535:INFO:Uploading results into container
2025-10-09 02:28:04,536:INFO:Uploading model into container now
2025-10-09 02:28:04,536:INFO:_master_model_container: 17
2025-10-09 02:28:04,536:INFO:_display_container: 5
2025-10-09 02:28:04,537:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-09 02:28:04,537:INFO:create_model() successfully completed......................................
2025-10-09 02:28:04,694:INFO:SubProcess create_model() end ==================================
2025-10-09 02:28:04,696:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.7891
2025-10-09 02:28:04,699:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.8291
2025-10-09 02:28:04,703:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-10-09 02:28:04,703:INFO:choose_better completed
2025-10-09 02:28:04,724:INFO:_master_model_container: 17
2025-10-09 02:28:04,725:INFO:_display_container: 4
2025-10-09 02:28:04,726:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-09 02:28:04,726:INFO:tune_model() successfully completed......................................
2025-10-09 02:28:14,869:INFO:Initializing evaluate_model()
2025-10-09 02:28:14,869:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000159B1726090>, estimator=LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-10-09 02:28:14,879:INFO:Initializing plot_model()
2025-10-09 02:28:14,879:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000159B1726090>, estimator=LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 02:28:14,879:INFO:Checking exceptions
2025-10-09 02:28:14,881:INFO:Preloading libraries
2025-10-09 02:28:14,883:INFO:Copying training dataset
2025-10-09 02:28:14,883:INFO:Plot type: pipeline
2025-10-09 02:28:15,109:INFO:Visual Rendered Successfully
2025-10-09 02:28:15,197:INFO:plot_model() successfully completed......................................
2025-10-09 02:28:19,021:INFO:Initializing plot_model()
2025-10-09 02:28:19,021:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000159B1726090>, estimator=LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=parameter, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 02:28:19,021:INFO:Checking exceptions
2025-10-09 02:28:19,023:INFO:Preloading libraries
2025-10-09 02:28:19,024:INFO:Copying training dataset
2025-10-09 02:28:19,024:INFO:Plot type: parameter
2025-10-09 02:28:19,029:INFO:Visual Rendered Successfully
2025-10-09 02:28:19,168:INFO:plot_model() successfully completed......................................
2025-10-09 02:28:19,976:INFO:Initializing plot_model()
2025-10-09 02:28:19,976:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000159B1726090>, estimator=LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 02:28:19,976:INFO:Checking exceptions
2025-10-09 02:28:19,978:INFO:Preloading libraries
2025-10-09 02:28:19,979:INFO:Copying training dataset
2025-10-09 02:28:19,979:INFO:Plot type: pipeline
2025-10-09 02:28:20,131:INFO:Visual Rendered Successfully
2025-10-09 02:28:20,265:INFO:plot_model() successfully completed......................................
2025-10-09 02:28:21,245:INFO:Initializing plot_model()
2025-10-09 02:28:21,245:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000159B1726090>, estimator=LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=tree, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 02:28:21,245:INFO:Checking exceptions
2025-10-09 02:28:22,421:INFO:Initializing plot_model()
2025-10-09 02:28:22,422:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000159B1726090>, estimator=LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 02:28:22,422:INFO:Checking exceptions
2025-10-09 02:28:22,424:INFO:Preloading libraries
2025-10-09 02:28:22,425:INFO:Copying training dataset
2025-10-09 02:28:22,425:INFO:Plot type: pipeline
2025-10-09 02:28:22,589:INFO:Visual Rendered Successfully
2025-10-09 02:28:22,718:INFO:plot_model() successfully completed......................................
2025-10-09 02:28:39,102:INFO:Initializing predict_model()
2025-10-09 02:28:39,102:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000159B1726090>, estimator=LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000159B1648180>)
2025-10-09 02:28:39,102:INFO:Checking exceptions
2025-10-09 02:28:39,102:INFO:Preloading libraries
2025-10-09 02:28:39,222:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:31:38,945:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-09 02:31:38,945:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-09 02:31:38,945:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-09 02:31:38,945:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-09 02:31:46,083:INFO:PyCaret ClassificationExperiment
2025-10-09 02:31:46,083:INFO:Logging name: clf-default-name
2025-10-09 02:31:46,083:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-10-09 02:31:46,084:INFO:version 3.3.2
2025-10-09 02:31:46,084:INFO:Initializing setup()
2025-10-09 02:31:46,084:INFO:self.USI: 445f
2025-10-09 02:31:46,084:INFO:self._variable_keys: {'y_test', 'fold_shuffle_param', 'y', 'exp_name_log', 'n_jobs_param', 'exp_id', 'target_param', 'X_test', 'fold_groups_param', 'fix_imbalance', 'is_multiclass', 'pipeline', '_available_plots', 'gpu_param', 'memory', 'X', 'seed', 'data', 'idx', 'USI', 'X_train', '_ml_usecase', 'y_train', 'log_plots_param', 'logging_param', 'html_param', 'fold_generator', 'gpu_n_jobs_param'}
2025-10-09 02:31:46,084:INFO:Checking environment
2025-10-09 02:31:46,084:INFO:python_version: 3.11.0
2025-10-09 02:31:46,084:INFO:python_build: ('main', 'Oct 24 2022 18:26:48')
2025-10-09 02:31:46,084:INFO:machine: AMD64
2025-10-09 02:31:46,084:INFO:platform: Windows-10-10.0.19045-SP0
2025-10-09 02:31:46,090:INFO:Memory: svmem(total=12713988096, available=1832325120, percent=85.6, used=10881662976, free=1832325120)
2025-10-09 02:31:46,090:INFO:Physical Core: 4
2025-10-09 02:31:46,090:INFO:Logical Core: 8
2025-10-09 02:31:46,090:INFO:Checking libraries
2025-10-09 02:31:46,090:INFO:System:
2025-10-09 02:31:46,090:INFO:    python: 3.11.0 (main, Oct 24 2022, 18:26:48) [MSC v.1933 64 bit (AMD64)]
2025-10-09 02:31:46,090:INFO:executable: c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\python.exe
2025-10-09 02:31:46,090:INFO:   machine: Windows-10-10.0.19045-SP0
2025-10-09 02:31:46,090:INFO:PyCaret required dependencies:
2025-10-09 02:31:46,123:INFO:                 pip: 25.2
2025-10-09 02:31:46,123:INFO:          setuptools: 65.5.0
2025-10-09 02:31:46,124:INFO:             pycaret: 3.3.2
2025-10-09 02:31:46,124:INFO:             IPython: 9.6.0
2025-10-09 02:31:46,124:INFO:          ipywidgets: 8.1.7
2025-10-09 02:31:46,124:INFO:                tqdm: 4.67.1
2025-10-09 02:31:46,124:INFO:               numpy: 1.26.4
2025-10-09 02:31:46,124:INFO:              pandas: 2.1.4
2025-10-09 02:31:46,124:INFO:              jinja2: 3.1.6
2025-10-09 02:31:46,124:INFO:               scipy: 1.11.4
2025-10-09 02:31:46,124:INFO:              joblib: 1.3.2
2025-10-09 02:31:46,124:INFO:             sklearn: 1.4.2
2025-10-09 02:31:46,124:INFO:                pyod: 2.0.5
2025-10-09 02:31:46,124:INFO:            imblearn: 0.14.0
2025-10-09 02:31:46,124:INFO:   category_encoders: 2.7.0
2025-10-09 02:31:46,124:INFO:            lightgbm: 4.6.0
2025-10-09 02:31:46,124:INFO:               numba: 0.62.1
2025-10-09 02:31:46,124:INFO:            requests: 2.32.5
2025-10-09 02:31:46,124:INFO:          matplotlib: 3.7.5
2025-10-09 02:31:46,124:INFO:          scikitplot: 0.3.7
2025-10-09 02:31:46,124:INFO:         yellowbrick: 1.5
2025-10-09 02:31:46,124:INFO:              plotly: 6.3.1
2025-10-09 02:31:46,124:INFO:    plotly-resampler: Not installed
2025-10-09 02:31:46,124:INFO:             kaleido: 1.1.0
2025-10-09 02:31:46,125:INFO:           schemdraw: 0.15
2025-10-09 02:31:46,125:INFO:         statsmodels: 0.14.5
2025-10-09 02:31:46,125:INFO:              sktime: 0.26.0
2025-10-09 02:31:46,125:INFO:               tbats: 1.1.3
2025-10-09 02:31:46,125:INFO:            pmdarima: 2.0.4
2025-10-09 02:31:46,125:INFO:              psutil: 7.1.0
2025-10-09 02:31:46,125:INFO:          markupsafe: 3.0.3
2025-10-09 02:31:46,125:INFO:             pickle5: Not installed
2025-10-09 02:31:46,125:INFO:         cloudpickle: 3.1.1
2025-10-09 02:31:46,125:INFO:         deprecation: 2.1.0
2025-10-09 02:31:46,125:INFO:              xxhash: 3.6.0
2025-10-09 02:31:46,125:INFO:           wurlitzer: Not installed
2025-10-09 02:31:46,125:INFO:PyCaret optional dependencies:
2025-10-09 02:31:46,140:INFO:                shap: Not installed
2025-10-09 02:31:46,140:INFO:           interpret: Not installed
2025-10-09 02:31:46,141:INFO:                umap: Not installed
2025-10-09 02:31:46,141:INFO:     ydata_profiling: Not installed
2025-10-09 02:31:46,141:INFO:  explainerdashboard: Not installed
2025-10-09 02:31:46,141:INFO:             autoviz: Not installed
2025-10-09 02:31:46,141:INFO:           fairlearn: Not installed
2025-10-09 02:31:46,141:INFO:          deepchecks: Not installed
2025-10-09 02:31:46,141:INFO:             xgboost: Not installed
2025-10-09 02:31:46,141:INFO:            catboost: Not installed
2025-10-09 02:31:46,141:INFO:              kmodes: Not installed
2025-10-09 02:31:46,141:INFO:             mlxtend: Not installed
2025-10-09 02:31:46,141:INFO:       statsforecast: Not installed
2025-10-09 02:31:46,141:INFO:        tune_sklearn: Not installed
2025-10-09 02:31:46,141:INFO:                 ray: Not installed
2025-10-09 02:31:46,141:INFO:            hyperopt: Not installed
2025-10-09 02:31:46,141:INFO:              optuna: Not installed
2025-10-09 02:31:46,141:INFO:               skopt: Not installed
2025-10-09 02:31:46,141:INFO:              mlflow: Not installed
2025-10-09 02:31:46,141:INFO:              gradio: Not installed
2025-10-09 02:31:46,141:INFO:             fastapi: Not installed
2025-10-09 02:31:46,141:INFO:             uvicorn: Not installed
2025-10-09 02:31:46,141:INFO:              m2cgen: Not installed
2025-10-09 02:31:46,141:INFO:           evidently: Not installed
2025-10-09 02:31:46,141:INFO:               fugue: Not installed
2025-10-09 02:31:46,142:INFO:           streamlit: Not installed
2025-10-09 02:31:46,142:INFO:             prophet: Not installed
2025-10-09 02:31:46,142:INFO:None
2025-10-09 02:31:46,142:INFO:Set up data.
2025-10-09 02:31:46,147:INFO:Set up folding strategy.
2025-10-09 02:31:46,147:INFO:Set up train/test split.
2025-10-09 02:31:46,152:INFO:Set up index.
2025-10-09 02:31:46,153:INFO:Assigning column types.
2025-10-09 02:31:46,155:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-09 02:31:46,202:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-09 02:31:46,206:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-09 02:31:46,246:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 02:31:46,246:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 02:31:46,298:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-09 02:31:46,299:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-09 02:31:46,331:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 02:31:46,332:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 02:31:46,332:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-09 02:31:46,374:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-09 02:31:46,400:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 02:31:46,401:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 02:31:46,446:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-09 02:31:46,476:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 02:31:46,477:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 02:31:46,477:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-10-09 02:31:46,544:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 02:31:46,544:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 02:31:46,606:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 02:31:46,607:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 02:31:46,608:INFO:Preparing preprocessing pipeline...
2025-10-09 02:31:46,609:INFO:Set up simple imputation.
2025-10-09 02:31:46,611:INFO:Set up encoding of ordinal features.
2025-10-09 02:31:46,612:INFO:Set up encoding of categorical features.
2025-10-09 02:31:46,612:INFO:Set up feature normalization.
2025-10-09 02:31:46,696:INFO:Finished creating preprocessing pipeline.
2025-10-09 02:31:46,719:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\jjqs_\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'ingresos_mensuales',
                                             'nro_creditos_previos',
                                             'cuota_vs_ingreso'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'...
                                    include=['estado_civil',
                                             'historia_credito'],
                                    transformer=OneHotEncoder(cols=['estado_civil',
                                                                    'historia_credito'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-10-09 02:31:46,719:INFO:Creating final display dataframe.
2025-10-09 02:31:46,912:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target           default
2                   Target type            Binary
3           Original data shape          (150, 8)
4        Transformed data shape         (150, 12)
5   Transformed train set shape         (105, 12)
6    Transformed test set shape          (45, 12)
7              Numeric features                 4
8          Categorical features                 3
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                    Normalize              True
16             Normalize method            zscore
17               Fold Generator   StratifiedKFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  clf-default-name
23                          USI              445f
2025-10-09 02:31:46,999:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 02:31:46,999:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 02:31:47,068:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 02:31:47,068:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 02:31:47,070:INFO:setup() successfully completed in 0.99s...............
2025-10-09 02:31:56,133:INFO:PyCaret ClassificationExperiment
2025-10-09 02:31:56,133:INFO:Logging name: clf-default-name
2025-10-09 02:31:56,133:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-10-09 02:31:56,133:INFO:version 3.3.2
2025-10-09 02:31:56,133:INFO:Initializing setup()
2025-10-09 02:31:56,133:INFO:self.USI: 2986
2025-10-09 02:31:56,133:INFO:self._variable_keys: {'y_test', 'fold_shuffle_param', 'y', 'exp_name_log', 'n_jobs_param', 'exp_id', 'target_param', 'X_test', 'fold_groups_param', 'fix_imbalance', 'is_multiclass', 'pipeline', '_available_plots', 'gpu_param', 'memory', 'X', 'seed', 'data', 'idx', 'USI', 'X_train', '_ml_usecase', 'y_train', 'log_plots_param', 'logging_param', 'html_param', 'fold_generator', 'gpu_n_jobs_param'}
2025-10-09 02:31:56,133:INFO:Checking environment
2025-10-09 02:31:56,133:INFO:python_version: 3.11.0
2025-10-09 02:31:56,133:INFO:python_build: ('main', 'Oct 24 2022 18:26:48')
2025-10-09 02:31:56,133:INFO:machine: AMD64
2025-10-09 02:31:56,133:INFO:platform: Windows-10-10.0.19045-SP0
2025-10-09 02:31:56,138:INFO:Memory: svmem(total=12713988096, available=1800830976, percent=85.8, used=10913157120, free=1800830976)
2025-10-09 02:31:56,138:INFO:Physical Core: 4
2025-10-09 02:31:56,138:INFO:Logical Core: 8
2025-10-09 02:31:56,138:INFO:Checking libraries
2025-10-09 02:31:56,138:INFO:System:
2025-10-09 02:31:56,139:INFO:    python: 3.11.0 (main, Oct 24 2022, 18:26:48) [MSC v.1933 64 bit (AMD64)]
2025-10-09 02:31:56,139:INFO:executable: c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\python.exe
2025-10-09 02:31:56,139:INFO:   machine: Windows-10-10.0.19045-SP0
2025-10-09 02:31:56,139:INFO:PyCaret required dependencies:
2025-10-09 02:31:56,139:INFO:                 pip: 25.2
2025-10-09 02:31:56,139:INFO:          setuptools: 65.5.0
2025-10-09 02:31:56,139:INFO:             pycaret: 3.3.2
2025-10-09 02:31:56,139:INFO:             IPython: 9.6.0
2025-10-09 02:31:56,139:INFO:          ipywidgets: 8.1.7
2025-10-09 02:31:56,139:INFO:                tqdm: 4.67.1
2025-10-09 02:31:56,139:INFO:               numpy: 1.26.4
2025-10-09 02:31:56,139:INFO:              pandas: 2.1.4
2025-10-09 02:31:56,139:INFO:              jinja2: 3.1.6
2025-10-09 02:31:56,139:INFO:               scipy: 1.11.4
2025-10-09 02:31:56,139:INFO:              joblib: 1.3.2
2025-10-09 02:31:56,139:INFO:             sklearn: 1.4.2
2025-10-09 02:31:56,139:INFO:                pyod: 2.0.5
2025-10-09 02:31:56,139:INFO:            imblearn: 0.14.0
2025-10-09 02:31:56,139:INFO:   category_encoders: 2.7.0
2025-10-09 02:31:56,139:INFO:            lightgbm: 4.6.0
2025-10-09 02:31:56,139:INFO:               numba: 0.62.1
2025-10-09 02:31:56,139:INFO:            requests: 2.32.5
2025-10-09 02:31:56,139:INFO:          matplotlib: 3.7.5
2025-10-09 02:31:56,139:INFO:          scikitplot: 0.3.7
2025-10-09 02:31:56,139:INFO:         yellowbrick: 1.5
2025-10-09 02:31:56,139:INFO:              plotly: 6.3.1
2025-10-09 02:31:56,140:INFO:    plotly-resampler: Not installed
2025-10-09 02:31:56,140:INFO:             kaleido: 1.1.0
2025-10-09 02:31:56,140:INFO:           schemdraw: 0.15
2025-10-09 02:31:56,140:INFO:         statsmodels: 0.14.5
2025-10-09 02:31:56,140:INFO:              sktime: 0.26.0
2025-10-09 02:31:56,140:INFO:               tbats: 1.1.3
2025-10-09 02:31:56,140:INFO:            pmdarima: 2.0.4
2025-10-09 02:31:56,140:INFO:              psutil: 7.1.0
2025-10-09 02:31:56,140:INFO:          markupsafe: 3.0.3
2025-10-09 02:31:56,140:INFO:             pickle5: Not installed
2025-10-09 02:31:56,140:INFO:         cloudpickle: 3.1.1
2025-10-09 02:31:56,140:INFO:         deprecation: 2.1.0
2025-10-09 02:31:56,140:INFO:              xxhash: 3.6.0
2025-10-09 02:31:56,140:INFO:           wurlitzer: Not installed
2025-10-09 02:31:56,140:INFO:PyCaret optional dependencies:
2025-10-09 02:31:56,140:INFO:                shap: Not installed
2025-10-09 02:31:56,140:INFO:           interpret: Not installed
2025-10-09 02:31:56,140:INFO:                umap: Not installed
2025-10-09 02:31:56,140:INFO:     ydata_profiling: Not installed
2025-10-09 02:31:56,140:INFO:  explainerdashboard: Not installed
2025-10-09 02:31:56,140:INFO:             autoviz: Not installed
2025-10-09 02:31:56,140:INFO:           fairlearn: Not installed
2025-10-09 02:31:56,140:INFO:          deepchecks: Not installed
2025-10-09 02:31:56,140:INFO:             xgboost: Not installed
2025-10-09 02:31:56,140:INFO:            catboost: Not installed
2025-10-09 02:31:56,140:INFO:              kmodes: Not installed
2025-10-09 02:31:56,140:INFO:             mlxtend: Not installed
2025-10-09 02:31:56,141:INFO:       statsforecast: Not installed
2025-10-09 02:31:56,141:INFO:        tune_sklearn: Not installed
2025-10-09 02:31:56,141:INFO:                 ray: Not installed
2025-10-09 02:31:56,141:INFO:            hyperopt: Not installed
2025-10-09 02:31:56,141:INFO:              optuna: Not installed
2025-10-09 02:31:56,141:INFO:               skopt: Not installed
2025-10-09 02:31:56,141:INFO:              mlflow: Not installed
2025-10-09 02:31:56,141:INFO:              gradio: Not installed
2025-10-09 02:31:56,141:INFO:             fastapi: Not installed
2025-10-09 02:31:56,141:INFO:             uvicorn: Not installed
2025-10-09 02:31:56,141:INFO:              m2cgen: Not installed
2025-10-09 02:31:56,141:INFO:           evidently: Not installed
2025-10-09 02:31:56,141:INFO:               fugue: Not installed
2025-10-09 02:31:56,141:INFO:           streamlit: Not installed
2025-10-09 02:31:56,141:INFO:             prophet: Not installed
2025-10-09 02:31:56,141:INFO:None
2025-10-09 02:31:56,141:INFO:Set up data.
2025-10-09 02:31:56,147:INFO:Set up folding strategy.
2025-10-09 02:31:56,147:INFO:Set up train/test split.
2025-10-09 02:31:56,152:INFO:Set up index.
2025-10-09 02:31:56,152:INFO:Assigning column types.
2025-10-09 02:31:56,156:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-09 02:31:56,193:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-09 02:31:56,194:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-09 02:31:56,218:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 02:31:56,218:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 02:31:56,259:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-09 02:31:56,260:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-09 02:31:56,282:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 02:31:56,282:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 02:31:56,283:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-09 02:31:56,319:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-09 02:31:56,341:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 02:31:56,342:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 02:31:56,382:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-09 02:31:56,411:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 02:31:56,412:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 02:31:56,412:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-10-09 02:31:56,490:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 02:31:56,490:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 02:31:56,573:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 02:31:56,573:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 02:31:56,575:INFO:Preparing preprocessing pipeline...
2025-10-09 02:31:56,576:INFO:Set up simple imputation.
2025-10-09 02:31:56,578:INFO:Set up encoding of categorical features.
2025-10-09 02:31:56,578:INFO:Set up feature normalization.
2025-10-09 02:31:56,663:INFO:Finished creating preprocessing pipeline.
2025-10-09 02:31:56,684:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\jjqs_\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'ingresos_mensuales',
                                             'nro_creditos_previos',
                                             'cuota_vs_ingreso',
                                             'vehiculo_propio'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=n...
                                    include=['estado_civil',
                                             'historia_credito'],
                                    transformer=OneHotEncoder(cols=['estado_civil',
                                                                    'historia_credito'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-10-09 02:31:56,684:INFO:Creating final display dataframe.
2025-10-09 02:31:56,857:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target           default
2                   Target type            Binary
3           Original data shape          (150, 8)
4        Transformed data shape         (150, 12)
5   Transformed train set shape         (105, 12)
6    Transformed test set shape          (45, 12)
7              Numeric features                 5
8          Categorical features                 2
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                    Normalize              True
16             Normalize method            zscore
17               Fold Generator   StratifiedKFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  clf-default-name
23                          USI              2986
2025-10-09 02:31:56,934:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 02:31:56,934:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 02:31:57,009:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 02:31:57,009:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 02:31:57,010:INFO:setup() successfully completed in 0.88s...............
2025-10-09 02:32:00,117:INFO:Initializing compare_models()
2025-10-09 02:32:00,117:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A66406FD0>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000025A66406FD0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-10-09 02:32:00,117:INFO:Checking exceptions
2025-10-09 02:32:00,121:INFO:Preparing display monitor
2025-10-09 02:32:00,146:INFO:Initializing Logistic Regression
2025-10-09 02:32:00,147:INFO:Total runtime is 1.6681353251139323e-05 minutes
2025-10-09 02:32:00,152:INFO:SubProcess create_model() called ==================================
2025-10-09 02:32:00,152:INFO:Initializing create_model()
2025-10-09 02:32:00,153:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A66406FD0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025A0AEB4950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:32:00,153:INFO:Checking exceptions
2025-10-09 02:32:00,153:INFO:Importing libraries
2025-10-09 02:32:00,153:INFO:Copying training dataset
2025-10-09 02:32:00,158:INFO:Defining folds
2025-10-09 02:32:00,158:INFO:Declaring metric variables
2025-10-09 02:32:00,162:INFO:Importing untrained model
2025-10-09 02:32:00,167:INFO:Logistic Regression Imported successfully
2025-10-09 02:32:00,175:INFO:Starting cross validation
2025-10-09 02:32:00,178:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:32:07,142:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:07,255:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:07,268:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:07,279:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:07,532:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:07,539:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:07,590:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:07,791:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:08,019:INFO:Calculating mean and std
2025-10-09 02:32:08,021:INFO:Creating metrics dataframe
2025-10-09 02:32:08,023:INFO:Uploading results into container
2025-10-09 02:32:08,023:INFO:Uploading model into container now
2025-10-09 02:32:08,023:INFO:_master_model_container: 1
2025-10-09 02:32:08,024:INFO:_display_container: 2
2025-10-09 02:32:08,024:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-09 02:32:08,024:INFO:create_model() successfully completed......................................
2025-10-09 02:32:08,115:INFO:SubProcess create_model() end ==================================
2025-10-09 02:32:08,115:INFO:Creating metrics dataframe
2025-10-09 02:32:08,120:INFO:Initializing K Neighbors Classifier
2025-10-09 02:32:08,121:INFO:Total runtime is 0.13291711409886678 minutes
2025-10-09 02:32:08,124:INFO:SubProcess create_model() called ==================================
2025-10-09 02:32:08,124:INFO:Initializing create_model()
2025-10-09 02:32:08,124:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A66406FD0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025A0AEB4950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:32:08,124:INFO:Checking exceptions
2025-10-09 02:32:08,124:INFO:Importing libraries
2025-10-09 02:32:08,124:INFO:Copying training dataset
2025-10-09 02:32:08,128:INFO:Defining folds
2025-10-09 02:32:08,128:INFO:Declaring metric variables
2025-10-09 02:32:08,132:INFO:Importing untrained model
2025-10-09 02:32:08,135:INFO:K Neighbors Classifier Imported successfully
2025-10-09 02:32:08,143:INFO:Starting cross validation
2025-10-09 02:32:08,145:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:32:08,343:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:08,343:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:08,346:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:08,348:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:08,386:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:08,480:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:08,488:INFO:Calculating mean and std
2025-10-09 02:32:08,489:INFO:Creating metrics dataframe
2025-10-09 02:32:08,491:INFO:Uploading results into container
2025-10-09 02:32:08,491:INFO:Uploading model into container now
2025-10-09 02:32:08,492:INFO:_master_model_container: 2
2025-10-09 02:32:08,492:INFO:_display_container: 2
2025-10-09 02:32:08,493:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-10-09 02:32:08,493:INFO:create_model() successfully completed......................................
2025-10-09 02:32:08,572:INFO:SubProcess create_model() end ==================================
2025-10-09 02:32:08,572:INFO:Creating metrics dataframe
2025-10-09 02:32:08,579:INFO:Initializing Naive Bayes
2025-10-09 02:32:08,579:INFO:Total runtime is 0.1405529578526815 minutes
2025-10-09 02:32:08,582:INFO:SubProcess create_model() called ==================================
2025-10-09 02:32:08,583:INFO:Initializing create_model()
2025-10-09 02:32:08,583:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A66406FD0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025A0AEB4950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:32:08,583:INFO:Checking exceptions
2025-10-09 02:32:08,583:INFO:Importing libraries
2025-10-09 02:32:08,583:INFO:Copying training dataset
2025-10-09 02:32:08,587:INFO:Defining folds
2025-10-09 02:32:08,587:INFO:Declaring metric variables
2025-10-09 02:32:08,590:INFO:Importing untrained model
2025-10-09 02:32:08,593:INFO:Naive Bayes Imported successfully
2025-10-09 02:32:08,602:INFO:Starting cross validation
2025-10-09 02:32:08,603:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:32:08,749:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:08,750:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:08,758:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:08,851:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:08,862:INFO:Calculating mean and std
2025-10-09 02:32:08,862:INFO:Creating metrics dataframe
2025-10-09 02:32:08,865:INFO:Uploading results into container
2025-10-09 02:32:08,865:INFO:Uploading model into container now
2025-10-09 02:32:08,866:INFO:_master_model_container: 3
2025-10-09 02:32:08,866:INFO:_display_container: 2
2025-10-09 02:32:08,866:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-10-09 02:32:08,866:INFO:create_model() successfully completed......................................
2025-10-09 02:32:08,948:INFO:SubProcess create_model() end ==================================
2025-10-09 02:32:08,949:INFO:Creating metrics dataframe
2025-10-09 02:32:08,957:INFO:Initializing Decision Tree Classifier
2025-10-09 02:32:08,957:INFO:Total runtime is 0.14684659639994305 minutes
2025-10-09 02:32:08,962:INFO:SubProcess create_model() called ==================================
2025-10-09 02:32:08,962:INFO:Initializing create_model()
2025-10-09 02:32:08,962:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A66406FD0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025A0AEB4950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:32:08,962:INFO:Checking exceptions
2025-10-09 02:32:08,962:INFO:Importing libraries
2025-10-09 02:32:08,962:INFO:Copying training dataset
2025-10-09 02:32:08,967:INFO:Defining folds
2025-10-09 02:32:08,967:INFO:Declaring metric variables
2025-10-09 02:32:08,970:INFO:Importing untrained model
2025-10-09 02:32:08,975:INFO:Decision Tree Classifier Imported successfully
2025-10-09 02:32:08,983:INFO:Starting cross validation
2025-10-09 02:32:08,985:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:32:09,153:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:09,256:INFO:Calculating mean and std
2025-10-09 02:32:09,256:INFO:Creating metrics dataframe
2025-10-09 02:32:09,259:INFO:Uploading results into container
2025-10-09 02:32:09,259:INFO:Uploading model into container now
2025-10-09 02:32:09,260:INFO:_master_model_container: 4
2025-10-09 02:32:09,260:INFO:_display_container: 2
2025-10-09 02:32:09,260:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-10-09 02:32:09,260:INFO:create_model() successfully completed......................................
2025-10-09 02:32:09,337:INFO:SubProcess create_model() end ==================================
2025-10-09 02:32:09,337:INFO:Creating metrics dataframe
2025-10-09 02:32:09,345:INFO:Initializing SVM - Linear Kernel
2025-10-09 02:32:09,345:INFO:Total runtime is 0.15331515471140544 minutes
2025-10-09 02:32:09,350:INFO:SubProcess create_model() called ==================================
2025-10-09 02:32:09,350:INFO:Initializing create_model()
2025-10-09 02:32:09,350:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A66406FD0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025A0AEB4950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:32:09,350:INFO:Checking exceptions
2025-10-09 02:32:09,350:INFO:Importing libraries
2025-10-09 02:32:09,351:INFO:Copying training dataset
2025-10-09 02:32:09,355:INFO:Defining folds
2025-10-09 02:32:09,356:INFO:Declaring metric variables
2025-10-09 02:32:09,360:INFO:Importing untrained model
2025-10-09 02:32:09,365:INFO:SVM - Linear Kernel Imported successfully
2025-10-09 02:32:09,375:INFO:Starting cross validation
2025-10-09 02:32:09,377:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:32:09,551:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:09,584:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:09,624:INFO:Calculating mean and std
2025-10-09 02:32:09,625:INFO:Creating metrics dataframe
2025-10-09 02:32:09,627:INFO:Uploading results into container
2025-10-09 02:32:09,628:INFO:Uploading model into container now
2025-10-09 02:32:09,628:INFO:_master_model_container: 5
2025-10-09 02:32:09,628:INFO:_display_container: 2
2025-10-09 02:32:09,629:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-10-09 02:32:09,629:INFO:create_model() successfully completed......................................
2025-10-09 02:32:09,704:INFO:SubProcess create_model() end ==================================
2025-10-09 02:32:09,705:INFO:Creating metrics dataframe
2025-10-09 02:32:09,711:INFO:Initializing Ridge Classifier
2025-10-09 02:32:09,711:INFO:Total runtime is 0.15941747426986694 minutes
2025-10-09 02:32:09,715:INFO:SubProcess create_model() called ==================================
2025-10-09 02:32:09,715:INFO:Initializing create_model()
2025-10-09 02:32:09,715:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A66406FD0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025A0AEB4950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:32:09,715:INFO:Checking exceptions
2025-10-09 02:32:09,715:INFO:Importing libraries
2025-10-09 02:32:09,715:INFO:Copying training dataset
2025-10-09 02:32:09,719:INFO:Defining folds
2025-10-09 02:32:09,719:INFO:Declaring metric variables
2025-10-09 02:32:09,722:INFO:Importing untrained model
2025-10-09 02:32:09,725:INFO:Ridge Classifier Imported successfully
2025-10-09 02:32:09,731:INFO:Starting cross validation
2025-10-09 02:32:09,733:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:32:09,875:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:09,887:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:09,907:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:09,920:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:09,922:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:09,941:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:09,960:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:09,986:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:09,996:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:10,011:INFO:Calculating mean and std
2025-10-09 02:32:10,012:INFO:Creating metrics dataframe
2025-10-09 02:32:10,015:INFO:Uploading results into container
2025-10-09 02:32:10,016:INFO:Uploading model into container now
2025-10-09 02:32:10,016:INFO:_master_model_container: 6
2025-10-09 02:32:10,016:INFO:_display_container: 2
2025-10-09 02:32:10,017:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-10-09 02:32:10,017:INFO:create_model() successfully completed......................................
2025-10-09 02:32:10,103:INFO:SubProcess create_model() end ==================================
2025-10-09 02:32:10,103:INFO:Creating metrics dataframe
2025-10-09 02:32:10,113:INFO:Initializing Random Forest Classifier
2025-10-09 02:32:10,113:INFO:Total runtime is 0.16612775723139445 minutes
2025-10-09 02:32:10,117:INFO:SubProcess create_model() called ==================================
2025-10-09 02:32:10,117:INFO:Initializing create_model()
2025-10-09 02:32:10,117:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A66406FD0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025A0AEB4950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:32:10,118:INFO:Checking exceptions
2025-10-09 02:32:10,118:INFO:Importing libraries
2025-10-09 02:32:10,118:INFO:Copying training dataset
2025-10-09 02:32:10,123:INFO:Defining folds
2025-10-09 02:32:10,123:INFO:Declaring metric variables
2025-10-09 02:32:10,127:INFO:Importing untrained model
2025-10-09 02:32:10,131:INFO:Random Forest Classifier Imported successfully
2025-10-09 02:32:10,140:INFO:Starting cross validation
2025-10-09 02:32:10,141:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:32:10,807:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:10,820:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:10,825:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:10,832:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:10,834:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:10,881:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:10,906:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:11,181:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:11,201:INFO:Calculating mean and std
2025-10-09 02:32:11,204:INFO:Creating metrics dataframe
2025-10-09 02:32:11,206:INFO:Uploading results into container
2025-10-09 02:32:11,207:INFO:Uploading model into container now
2025-10-09 02:32:11,208:INFO:_master_model_container: 7
2025-10-09 02:32:11,209:INFO:_display_container: 2
2025-10-09 02:32:11,209:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-10-09 02:32:11,210:INFO:create_model() successfully completed......................................
2025-10-09 02:32:11,302:INFO:SubProcess create_model() end ==================================
2025-10-09 02:32:11,302:INFO:Creating metrics dataframe
2025-10-09 02:32:11,310:INFO:Initializing Quadratic Discriminant Analysis
2025-10-09 02:32:11,310:INFO:Total runtime is 0.1860670248667399 minutes
2025-10-09 02:32:11,315:INFO:SubProcess create_model() called ==================================
2025-10-09 02:32:11,315:INFO:Initializing create_model()
2025-10-09 02:32:11,315:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A66406FD0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025A0AEB4950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:32:11,315:INFO:Checking exceptions
2025-10-09 02:32:11,315:INFO:Importing libraries
2025-10-09 02:32:11,316:INFO:Copying training dataset
2025-10-09 02:32:11,320:INFO:Defining folds
2025-10-09 02:32:11,320:INFO:Declaring metric variables
2025-10-09 02:32:11,324:INFO:Importing untrained model
2025-10-09 02:32:11,329:INFO:Quadratic Discriminant Analysis Imported successfully
2025-10-09 02:32:11,339:INFO:Starting cross validation
2025-10-09 02:32:11,341:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:32:11,432:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 02:32:11,437:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 02:32:11,447:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 02:32:11,449:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 02:32:11,452:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 02:32:11,457:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 02:32:11,459:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 02:32:11,477:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 02:32:11,540:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:11,555:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 02:32:11,560:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 02:32:11,585:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:11,594:INFO:Calculating mean and std
2025-10-09 02:32:11,595:INFO:Creating metrics dataframe
2025-10-09 02:32:11,597:INFO:Uploading results into container
2025-10-09 02:32:11,598:INFO:Uploading model into container now
2025-10-09 02:32:11,599:INFO:_master_model_container: 8
2025-10-09 02:32:11,599:INFO:_display_container: 2
2025-10-09 02:32:11,599:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-10-09 02:32:11,599:INFO:create_model() successfully completed......................................
2025-10-09 02:32:11,674:INFO:SubProcess create_model() end ==================================
2025-10-09 02:32:11,674:INFO:Creating metrics dataframe
2025-10-09 02:32:11,681:INFO:Initializing Ada Boost Classifier
2025-10-09 02:32:11,681:INFO:Total runtime is 0.19226015806198118 minutes
2025-10-09 02:32:11,684:INFO:SubProcess create_model() called ==================================
2025-10-09 02:32:11,684:INFO:Initializing create_model()
2025-10-09 02:32:11,684:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A66406FD0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025A0AEB4950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:32:11,684:INFO:Checking exceptions
2025-10-09 02:32:11,684:INFO:Importing libraries
2025-10-09 02:32:11,684:INFO:Copying training dataset
2025-10-09 02:32:11,688:INFO:Defining folds
2025-10-09 02:32:11,688:INFO:Declaring metric variables
2025-10-09 02:32:11,691:INFO:Importing untrained model
2025-10-09 02:32:11,694:INFO:Ada Boost Classifier Imported successfully
2025-10-09 02:32:11,701:INFO:Starting cross validation
2025-10-09 02:32:11,703:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:32:11,780:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 02:32:11,780:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 02:32:11,780:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 02:32:11,786:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 02:32:11,789:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 02:32:11,791:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 02:32:11,807:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 02:32:11,825:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 02:32:12,069:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:12,077:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 02:32:12,078:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:12,085:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 02:32:12,190:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:12,196:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:12,205:INFO:Calculating mean and std
2025-10-09 02:32:12,206:INFO:Creating metrics dataframe
2025-10-09 02:32:12,208:INFO:Uploading results into container
2025-10-09 02:32:12,209:INFO:Uploading model into container now
2025-10-09 02:32:12,210:INFO:_master_model_container: 9
2025-10-09 02:32:12,210:INFO:_display_container: 2
2025-10-09 02:32:12,210:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-10-09 02:32:12,210:INFO:create_model() successfully completed......................................
2025-10-09 02:32:12,285:INFO:SubProcess create_model() end ==================================
2025-10-09 02:32:12,285:INFO:Creating metrics dataframe
2025-10-09 02:32:12,293:INFO:Initializing Gradient Boosting Classifier
2025-10-09 02:32:12,293:INFO:Total runtime is 0.2024499456087748 minutes
2025-10-09 02:32:12,296:INFO:SubProcess create_model() called ==================================
2025-10-09 02:32:12,296:INFO:Initializing create_model()
2025-10-09 02:32:12,296:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A66406FD0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025A0AEB4950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:32:12,297:INFO:Checking exceptions
2025-10-09 02:32:12,297:INFO:Importing libraries
2025-10-09 02:32:12,297:INFO:Copying training dataset
2025-10-09 02:32:12,301:INFO:Defining folds
2025-10-09 02:32:12,301:INFO:Declaring metric variables
2025-10-09 02:32:12,304:INFO:Importing untrained model
2025-10-09 02:32:12,307:INFO:Gradient Boosting Classifier Imported successfully
2025-10-09 02:32:12,315:INFO:Starting cross validation
2025-10-09 02:32:12,317:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:32:12,658:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:12,918:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:12,933:INFO:Calculating mean and std
2025-10-09 02:32:12,933:INFO:Creating metrics dataframe
2025-10-09 02:32:12,936:INFO:Uploading results into container
2025-10-09 02:32:12,937:INFO:Uploading model into container now
2025-10-09 02:32:12,938:INFO:_master_model_container: 10
2025-10-09 02:32:12,938:INFO:_display_container: 2
2025-10-09 02:32:12,938:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-09 02:32:12,938:INFO:create_model() successfully completed......................................
2025-10-09 02:32:13,016:INFO:SubProcess create_model() end ==================================
2025-10-09 02:32:13,017:INFO:Creating metrics dataframe
2025-10-09 02:32:13,025:INFO:Initializing Linear Discriminant Analysis
2025-10-09 02:32:13,025:INFO:Total runtime is 0.21464753548304238 minutes
2025-10-09 02:32:13,029:INFO:SubProcess create_model() called ==================================
2025-10-09 02:32:13,029:INFO:Initializing create_model()
2025-10-09 02:32:13,029:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A66406FD0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025A0AEB4950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:32:13,029:INFO:Checking exceptions
2025-10-09 02:32:13,029:INFO:Importing libraries
2025-10-09 02:32:13,029:INFO:Copying training dataset
2025-10-09 02:32:13,032:INFO:Defining folds
2025-10-09 02:32:13,033:INFO:Declaring metric variables
2025-10-09 02:32:13,036:INFO:Importing untrained model
2025-10-09 02:32:13,038:INFO:Linear Discriminant Analysis Imported successfully
2025-10-09 02:32:13,046:INFO:Starting cross validation
2025-10-09 02:32:13,048:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:32:13,184:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:13,186:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:13,187:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:13,210:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:13,229:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:13,273:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:13,280:INFO:Calculating mean and std
2025-10-09 02:32:13,280:INFO:Creating metrics dataframe
2025-10-09 02:32:13,282:INFO:Uploading results into container
2025-10-09 02:32:13,283:INFO:Uploading model into container now
2025-10-09 02:32:13,284:INFO:_master_model_container: 11
2025-10-09 02:32:13,284:INFO:_display_container: 2
2025-10-09 02:32:13,284:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-09 02:32:13,285:INFO:create_model() successfully completed......................................
2025-10-09 02:32:13,362:INFO:SubProcess create_model() end ==================================
2025-10-09 02:32:13,362:INFO:Creating metrics dataframe
2025-10-09 02:32:13,370:INFO:Initializing Extra Trees Classifier
2025-10-09 02:32:13,370:INFO:Total runtime is 0.22040780782699584 minutes
2025-10-09 02:32:13,374:INFO:SubProcess create_model() called ==================================
2025-10-09 02:32:13,374:INFO:Initializing create_model()
2025-10-09 02:32:13,374:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A66406FD0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025A0AEB4950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:32:13,374:INFO:Checking exceptions
2025-10-09 02:32:13,374:INFO:Importing libraries
2025-10-09 02:32:13,374:INFO:Copying training dataset
2025-10-09 02:32:13,378:INFO:Defining folds
2025-10-09 02:32:13,378:INFO:Declaring metric variables
2025-10-09 02:32:13,381:INFO:Importing untrained model
2025-10-09 02:32:13,384:INFO:Extra Trees Classifier Imported successfully
2025-10-09 02:32:13,392:INFO:Starting cross validation
2025-10-09 02:32:13,393:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:32:13,873:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:13,902:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:14,002:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:14,160:INFO:Calculating mean and std
2025-10-09 02:32:14,161:INFO:Creating metrics dataframe
2025-10-09 02:32:14,163:INFO:Uploading results into container
2025-10-09 02:32:14,164:INFO:Uploading model into container now
2025-10-09 02:32:14,164:INFO:_master_model_container: 12
2025-10-09 02:32:14,165:INFO:_display_container: 2
2025-10-09 02:32:14,166:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-10-09 02:32:14,166:INFO:create_model() successfully completed......................................
2025-10-09 02:32:14,266:INFO:SubProcess create_model() end ==================================
2025-10-09 02:32:14,266:INFO:Creating metrics dataframe
2025-10-09 02:32:14,279:INFO:Initializing Light Gradient Boosting Machine
2025-10-09 02:32:14,279:INFO:Total runtime is 0.2355525533358256 minutes
2025-10-09 02:32:14,283:INFO:SubProcess create_model() called ==================================
2025-10-09 02:32:14,283:INFO:Initializing create_model()
2025-10-09 02:32:14,283:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A66406FD0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025A0AEB4950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:32:14,283:INFO:Checking exceptions
2025-10-09 02:32:14,283:INFO:Importing libraries
2025-10-09 02:32:14,284:INFO:Copying training dataset
2025-10-09 02:32:14,287:INFO:Defining folds
2025-10-09 02:32:14,288:INFO:Declaring metric variables
2025-10-09 02:32:14,291:INFO:Importing untrained model
2025-10-09 02:32:14,295:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-09 02:32:14,305:INFO:Starting cross validation
2025-10-09 02:32:14,307:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:32:14,527:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:14,567:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:14,669:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:14,698:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:14,763:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:14,886:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:14,904:INFO:Calculating mean and std
2025-10-09 02:32:14,905:INFO:Creating metrics dataframe
2025-10-09 02:32:14,909:INFO:Uploading results into container
2025-10-09 02:32:14,909:INFO:Uploading model into container now
2025-10-09 02:32:14,910:INFO:_master_model_container: 13
2025-10-09 02:32:14,910:INFO:_display_container: 2
2025-10-09 02:32:14,911:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-09 02:32:14,911:INFO:create_model() successfully completed......................................
2025-10-09 02:32:15,012:INFO:SubProcess create_model() end ==================================
2025-10-09 02:32:15,012:INFO:Creating metrics dataframe
2025-10-09 02:32:15,023:INFO:Initializing Dummy Classifier
2025-10-09 02:32:15,024:INFO:Total runtime is 0.2479773243268331 minutes
2025-10-09 02:32:15,028:INFO:SubProcess create_model() called ==================================
2025-10-09 02:32:15,029:INFO:Initializing create_model()
2025-10-09 02:32:15,029:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A66406FD0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025A0AEB4950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:32:15,029:INFO:Checking exceptions
2025-10-09 02:32:15,029:INFO:Importing libraries
2025-10-09 02:32:15,029:INFO:Copying training dataset
2025-10-09 02:32:15,035:INFO:Defining folds
2025-10-09 02:32:15,035:INFO:Declaring metric variables
2025-10-09 02:32:15,040:INFO:Importing untrained model
2025-10-09 02:32:15,045:INFO:Dummy Classifier Imported successfully
2025-10-09 02:32:15,054:INFO:Starting cross validation
2025-10-09 02:32:15,057:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:32:15,183:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:15,183:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:15,184:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:15,202:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:15,216:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:15,220:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:15,242:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:15,245:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:15,281:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:15,282:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:15,298:INFO:Calculating mean and std
2025-10-09 02:32:15,299:INFO:Creating metrics dataframe
2025-10-09 02:32:15,301:INFO:Uploading results into container
2025-10-09 02:32:15,301:INFO:Uploading model into container now
2025-10-09 02:32:15,302:INFO:_master_model_container: 14
2025-10-09 02:32:15,302:INFO:_display_container: 2
2025-10-09 02:32:15,302:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-10-09 02:32:15,302:INFO:create_model() successfully completed......................................
2025-10-09 02:32:15,441:INFO:SubProcess create_model() end ==================================
2025-10-09 02:32:15,441:INFO:Creating metrics dataframe
2025-10-09 02:32:15,453:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-10-09 02:32:15,461:INFO:Initializing create_model()
2025-10-09 02:32:15,461:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A66406FD0>, estimator=DummyClassifier(constant=None, random_state=123, strategy='prior'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:32:15,461:INFO:Checking exceptions
2025-10-09 02:32:15,463:INFO:Importing libraries
2025-10-09 02:32:15,463:INFO:Copying training dataset
2025-10-09 02:32:15,467:INFO:Defining folds
2025-10-09 02:32:15,467:INFO:Declaring metric variables
2025-10-09 02:32:15,467:INFO:Importing untrained model
2025-10-09 02:32:15,467:INFO:Declaring custom model
2025-10-09 02:32:15,467:INFO:Dummy Classifier Imported successfully
2025-10-09 02:32:15,468:INFO:Cross validation set to False
2025-10-09 02:32:15,468:INFO:Fitting Model
2025-10-09 02:32:15,507:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-10-09 02:32:15,507:INFO:create_model() successfully completed......................................
2025-10-09 02:32:15,612:INFO:_master_model_container: 14
2025-10-09 02:32:15,612:INFO:_display_container: 2
2025-10-09 02:32:15,612:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-10-09 02:32:15,612:INFO:compare_models() successfully completed......................................
2025-10-09 02:32:26,691:INFO:Initializing compare_models()
2025-10-09 02:32:26,691:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A66406FD0>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000025A66406FD0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-10-09 02:32:26,691:INFO:Checking exceptions
2025-10-09 02:32:26,693:INFO:Preparing display monitor
2025-10-09 02:32:26,717:INFO:Initializing Logistic Regression
2025-10-09 02:32:26,717:INFO:Total runtime is 0.0 minutes
2025-10-09 02:32:26,720:INFO:SubProcess create_model() called ==================================
2025-10-09 02:32:26,721:INFO:Initializing create_model()
2025-10-09 02:32:26,721:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A66406FD0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025A0B3FCF10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:32:26,721:INFO:Checking exceptions
2025-10-09 02:32:26,721:INFO:Importing libraries
2025-10-09 02:32:26,721:INFO:Copying training dataset
2025-10-09 02:32:26,725:INFO:Defining folds
2025-10-09 02:32:26,725:INFO:Declaring metric variables
2025-10-09 02:32:26,729:INFO:Importing untrained model
2025-10-09 02:32:26,735:INFO:Logistic Regression Imported successfully
2025-10-09 02:32:26,743:INFO:Starting cross validation
2025-10-09 02:32:26,746:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:32:26,878:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:26,885:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:26,885:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:26,886:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:26,898:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:26,903:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:26,936:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:26,981:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:26,996:INFO:Calculating mean and std
2025-10-09 02:32:26,996:INFO:Creating metrics dataframe
2025-10-09 02:32:26,998:INFO:Uploading results into container
2025-10-09 02:32:26,998:INFO:Uploading model into container now
2025-10-09 02:32:26,999:INFO:_master_model_container: 15
2025-10-09 02:32:26,999:INFO:_display_container: 3
2025-10-09 02:32:26,999:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-09 02:32:26,999:INFO:create_model() successfully completed......................................
2025-10-09 02:32:27,069:INFO:SubProcess create_model() end ==================================
2025-10-09 02:32:27,069:INFO:Creating metrics dataframe
2025-10-09 02:32:27,074:INFO:Initializing K Neighbors Classifier
2025-10-09 02:32:27,074:INFO:Total runtime is 0.005951201915740967 minutes
2025-10-09 02:32:27,077:INFO:SubProcess create_model() called ==================================
2025-10-09 02:32:27,078:INFO:Initializing create_model()
2025-10-09 02:32:27,078:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A66406FD0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025A0B3FCF10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:32:27,078:INFO:Checking exceptions
2025-10-09 02:32:27,078:INFO:Importing libraries
2025-10-09 02:32:27,078:INFO:Copying training dataset
2025-10-09 02:32:27,081:INFO:Defining folds
2025-10-09 02:32:27,081:INFO:Declaring metric variables
2025-10-09 02:32:27,084:INFO:Importing untrained model
2025-10-09 02:32:27,087:INFO:K Neighbors Classifier Imported successfully
2025-10-09 02:32:27,096:INFO:Starting cross validation
2025-10-09 02:32:27,098:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:32:27,327:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:27,327:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:27,335:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:27,350:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:27,409:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:27,503:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:27,521:INFO:Calculating mean and std
2025-10-09 02:32:27,522:INFO:Creating metrics dataframe
2025-10-09 02:32:27,524:INFO:Uploading results into container
2025-10-09 02:32:27,524:INFO:Uploading model into container now
2025-10-09 02:32:27,525:INFO:_master_model_container: 16
2025-10-09 02:32:27,525:INFO:_display_container: 3
2025-10-09 02:32:27,525:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-10-09 02:32:27,525:INFO:create_model() successfully completed......................................
2025-10-09 02:32:27,726:INFO:SubProcess create_model() end ==================================
2025-10-09 02:32:27,726:INFO:Creating metrics dataframe
2025-10-09 02:32:27,734:INFO:Initializing Naive Bayes
2025-10-09 02:32:27,734:INFO:Total runtime is 0.016938034693400064 minutes
2025-10-09 02:32:27,738:INFO:SubProcess create_model() called ==================================
2025-10-09 02:32:27,739:INFO:Initializing create_model()
2025-10-09 02:32:27,739:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A66406FD0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025A0B3FCF10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:32:27,739:INFO:Checking exceptions
2025-10-09 02:32:27,739:INFO:Importing libraries
2025-10-09 02:32:27,739:INFO:Copying training dataset
2025-10-09 02:32:27,746:INFO:Defining folds
2025-10-09 02:32:27,746:INFO:Declaring metric variables
2025-10-09 02:32:27,755:INFO:Importing untrained model
2025-10-09 02:32:27,761:INFO:Naive Bayes Imported successfully
2025-10-09 02:32:27,773:INFO:Starting cross validation
2025-10-09 02:32:27,776:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:32:27,954:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:27,971:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:28,021:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:28,066:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:28,088:INFO:Calculating mean and std
2025-10-09 02:32:28,090:INFO:Creating metrics dataframe
2025-10-09 02:32:28,092:INFO:Uploading results into container
2025-10-09 02:32:28,093:INFO:Uploading model into container now
2025-10-09 02:32:28,093:INFO:_master_model_container: 17
2025-10-09 02:32:28,093:INFO:_display_container: 3
2025-10-09 02:32:28,093:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-10-09 02:32:28,094:INFO:create_model() successfully completed......................................
2025-10-09 02:32:28,177:INFO:SubProcess create_model() end ==================================
2025-10-09 02:32:28,177:INFO:Creating metrics dataframe
2025-10-09 02:32:28,184:INFO:Initializing Decision Tree Classifier
2025-10-09 02:32:28,184:INFO:Total runtime is 0.02444129784901937 minutes
2025-10-09 02:32:28,188:INFO:SubProcess create_model() called ==================================
2025-10-09 02:32:28,188:INFO:Initializing create_model()
2025-10-09 02:32:28,189:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A66406FD0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025A0B3FCF10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:32:28,189:INFO:Checking exceptions
2025-10-09 02:32:28,189:INFO:Importing libraries
2025-10-09 02:32:28,189:INFO:Copying training dataset
2025-10-09 02:32:28,193:INFO:Defining folds
2025-10-09 02:32:28,193:INFO:Declaring metric variables
2025-10-09 02:32:28,197:INFO:Importing untrained model
2025-10-09 02:32:28,201:INFO:Decision Tree Classifier Imported successfully
2025-10-09 02:32:28,210:INFO:Starting cross validation
2025-10-09 02:32:28,212:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:32:28,386:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:28,486:INFO:Calculating mean and std
2025-10-09 02:32:28,487:INFO:Creating metrics dataframe
2025-10-09 02:32:28,489:INFO:Uploading results into container
2025-10-09 02:32:28,489:INFO:Uploading model into container now
2025-10-09 02:32:28,490:INFO:_master_model_container: 18
2025-10-09 02:32:28,490:INFO:_display_container: 3
2025-10-09 02:32:28,490:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-10-09 02:32:28,490:INFO:create_model() successfully completed......................................
2025-10-09 02:32:28,574:INFO:SubProcess create_model() end ==================================
2025-10-09 02:32:28,574:INFO:Creating metrics dataframe
2025-10-09 02:32:28,581:INFO:Initializing SVM - Linear Kernel
2025-10-09 02:32:28,581:INFO:Total runtime is 0.031052744388580324 minutes
2025-10-09 02:32:28,584:INFO:SubProcess create_model() called ==================================
2025-10-09 02:32:28,585:INFO:Initializing create_model()
2025-10-09 02:32:28,585:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A66406FD0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025A0B3FCF10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:32:28,585:INFO:Checking exceptions
2025-10-09 02:32:28,585:INFO:Importing libraries
2025-10-09 02:32:28,585:INFO:Copying training dataset
2025-10-09 02:32:28,589:INFO:Defining folds
2025-10-09 02:32:28,589:INFO:Declaring metric variables
2025-10-09 02:32:28,593:INFO:Importing untrained model
2025-10-09 02:32:28,596:INFO:SVM - Linear Kernel Imported successfully
2025-10-09 02:32:28,605:INFO:Starting cross validation
2025-10-09 02:32:28,607:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:32:28,778:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:28,780:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:28,874:INFO:Calculating mean and std
2025-10-09 02:32:28,875:INFO:Creating metrics dataframe
2025-10-09 02:32:28,877:INFO:Uploading results into container
2025-10-09 02:32:28,878:INFO:Uploading model into container now
2025-10-09 02:32:28,878:INFO:_master_model_container: 19
2025-10-09 02:32:28,878:INFO:_display_container: 3
2025-10-09 02:32:28,879:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-10-09 02:32:28,879:INFO:create_model() successfully completed......................................
2025-10-09 02:32:28,969:INFO:SubProcess create_model() end ==================================
2025-10-09 02:32:28,969:INFO:Creating metrics dataframe
2025-10-09 02:32:28,976:INFO:Initializing Ridge Classifier
2025-10-09 02:32:28,976:INFO:Total runtime is 0.03764833211898804 minutes
2025-10-09 02:32:28,980:INFO:SubProcess create_model() called ==================================
2025-10-09 02:32:28,980:INFO:Initializing create_model()
2025-10-09 02:32:28,980:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A66406FD0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025A0B3FCF10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:32:28,980:INFO:Checking exceptions
2025-10-09 02:32:28,981:INFO:Importing libraries
2025-10-09 02:32:28,981:INFO:Copying training dataset
2025-10-09 02:32:28,985:INFO:Defining folds
2025-10-09 02:32:28,985:INFO:Declaring metric variables
2025-10-09 02:32:28,990:INFO:Importing untrained model
2025-10-09 02:32:28,995:INFO:Ridge Classifier Imported successfully
2025-10-09 02:32:29,004:INFO:Starting cross validation
2025-10-09 02:32:29,007:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:32:29,139:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:29,146:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:29,152:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:29,156:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:29,167:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:29,175:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:29,205:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:29,250:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:29,257:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:29,271:INFO:Calculating mean and std
2025-10-09 02:32:29,273:INFO:Creating metrics dataframe
2025-10-09 02:32:29,275:INFO:Uploading results into container
2025-10-09 02:32:29,276:INFO:Uploading model into container now
2025-10-09 02:32:29,277:INFO:_master_model_container: 20
2025-10-09 02:32:29,277:INFO:_display_container: 3
2025-10-09 02:32:29,278:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-10-09 02:32:29,278:INFO:create_model() successfully completed......................................
2025-10-09 02:32:29,371:INFO:SubProcess create_model() end ==================================
2025-10-09 02:32:29,371:INFO:Creating metrics dataframe
2025-10-09 02:32:29,379:INFO:Initializing Random Forest Classifier
2025-10-09 02:32:29,379:INFO:Total runtime is 0.04435875813166301 minutes
2025-10-09 02:32:29,383:INFO:SubProcess create_model() called ==================================
2025-10-09 02:32:29,383:INFO:Initializing create_model()
2025-10-09 02:32:29,383:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A66406FD0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025A0B3FCF10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:32:29,383:INFO:Checking exceptions
2025-10-09 02:32:29,383:INFO:Importing libraries
2025-10-09 02:32:29,384:INFO:Copying training dataset
2025-10-09 02:32:29,388:INFO:Defining folds
2025-10-09 02:32:29,388:INFO:Declaring metric variables
2025-10-09 02:32:29,391:INFO:Importing untrained model
2025-10-09 02:32:29,395:INFO:Random Forest Classifier Imported successfully
2025-10-09 02:32:29,414:INFO:Starting cross validation
2025-10-09 02:32:29,419:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:32:29,879:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:29,881:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:29,898:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:29,899:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:29,913:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:30,030:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:30,052:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:30,205:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:30,211:INFO:Calculating mean and std
2025-10-09 02:32:30,212:INFO:Creating metrics dataframe
2025-10-09 02:32:30,215:INFO:Uploading results into container
2025-10-09 02:32:30,216:INFO:Uploading model into container now
2025-10-09 02:32:30,216:INFO:_master_model_container: 21
2025-10-09 02:32:30,216:INFO:_display_container: 3
2025-10-09 02:32:30,217:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-10-09 02:32:30,217:INFO:create_model() successfully completed......................................
2025-10-09 02:32:30,294:INFO:SubProcess create_model() end ==================================
2025-10-09 02:32:30,294:INFO:Creating metrics dataframe
2025-10-09 02:32:30,301:INFO:Initializing Quadratic Discriminant Analysis
2025-10-09 02:32:30,301:INFO:Total runtime is 0.05972311894098918 minutes
2025-10-09 02:32:30,304:INFO:SubProcess create_model() called ==================================
2025-10-09 02:32:30,305:INFO:Initializing create_model()
2025-10-09 02:32:30,305:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A66406FD0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025A0B3FCF10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:32:30,305:INFO:Checking exceptions
2025-10-09 02:32:30,305:INFO:Importing libraries
2025-10-09 02:32:30,305:INFO:Copying training dataset
2025-10-09 02:32:30,308:INFO:Defining folds
2025-10-09 02:32:30,309:INFO:Declaring metric variables
2025-10-09 02:32:30,311:INFO:Importing untrained model
2025-10-09 02:32:30,315:INFO:Quadratic Discriminant Analysis Imported successfully
2025-10-09 02:32:30,324:INFO:Starting cross validation
2025-10-09 02:32:30,325:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:32:30,402:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 02:32:30,404:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 02:32:30,406:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 02:32:30,408:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 02:32:30,409:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 02:32:30,412:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 02:32:30,438:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 02:32:30,450:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 02:32:30,466:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:30,521:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 02:32:30,527:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 02:32:30,560:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:30,570:INFO:Calculating mean and std
2025-10-09 02:32:30,570:INFO:Creating metrics dataframe
2025-10-09 02:32:30,573:INFO:Uploading results into container
2025-10-09 02:32:30,573:INFO:Uploading model into container now
2025-10-09 02:32:30,574:INFO:_master_model_container: 22
2025-10-09 02:32:30,574:INFO:_display_container: 3
2025-10-09 02:32:30,574:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-10-09 02:32:30,574:INFO:create_model() successfully completed......................................
2025-10-09 02:32:30,657:INFO:SubProcess create_model() end ==================================
2025-10-09 02:32:30,657:INFO:Creating metrics dataframe
2025-10-09 02:32:30,665:INFO:Initializing Ada Boost Classifier
2025-10-09 02:32:30,665:INFO:Total runtime is 0.06579845348993937 minutes
2025-10-09 02:32:30,669:INFO:SubProcess create_model() called ==================================
2025-10-09 02:32:30,669:INFO:Initializing create_model()
2025-10-09 02:32:30,669:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A66406FD0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025A0B3FCF10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:32:30,669:INFO:Checking exceptions
2025-10-09 02:32:30,669:INFO:Importing libraries
2025-10-09 02:32:30,669:INFO:Copying training dataset
2025-10-09 02:32:30,673:INFO:Defining folds
2025-10-09 02:32:30,673:INFO:Declaring metric variables
2025-10-09 02:32:30,676:INFO:Importing untrained model
2025-10-09 02:32:30,680:INFO:Ada Boost Classifier Imported successfully
2025-10-09 02:32:30,691:INFO:Starting cross validation
2025-10-09 02:32:30,695:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:32:30,775:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 02:32:30,776:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 02:32:30,779:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 02:32:30,784:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 02:32:30,784:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 02:32:30,790:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 02:32:30,817:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 02:32:30,826:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 02:32:31,024:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:31,061:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 02:32:31,073:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 02:32:31,084:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:31,187:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:31,198:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:31,212:INFO:Calculating mean and std
2025-10-09 02:32:31,212:INFO:Creating metrics dataframe
2025-10-09 02:32:31,215:INFO:Uploading results into container
2025-10-09 02:32:31,216:INFO:Uploading model into container now
2025-10-09 02:32:31,217:INFO:_master_model_container: 23
2025-10-09 02:32:31,217:INFO:_display_container: 3
2025-10-09 02:32:31,217:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-10-09 02:32:31,217:INFO:create_model() successfully completed......................................
2025-10-09 02:32:31,297:INFO:SubProcess create_model() end ==================================
2025-10-09 02:32:31,297:INFO:Creating metrics dataframe
2025-10-09 02:32:31,305:INFO:Initializing Gradient Boosting Classifier
2025-10-09 02:32:31,306:INFO:Total runtime is 0.07647190888722738 minutes
2025-10-09 02:32:31,309:INFO:SubProcess create_model() called ==================================
2025-10-09 02:32:31,309:INFO:Initializing create_model()
2025-10-09 02:32:31,309:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A66406FD0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025A0B3FCF10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:32:31,309:INFO:Checking exceptions
2025-10-09 02:32:31,309:INFO:Importing libraries
2025-10-09 02:32:31,309:INFO:Copying training dataset
2025-10-09 02:32:31,313:INFO:Defining folds
2025-10-09 02:32:31,313:INFO:Declaring metric variables
2025-10-09 02:32:31,316:INFO:Importing untrained model
2025-10-09 02:32:31,320:INFO:Gradient Boosting Classifier Imported successfully
2025-10-09 02:32:31,328:INFO:Starting cross validation
2025-10-09 02:32:31,330:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:32:31,728:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:31,961:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:31,969:INFO:Calculating mean and std
2025-10-09 02:32:31,970:INFO:Creating metrics dataframe
2025-10-09 02:32:31,973:INFO:Uploading results into container
2025-10-09 02:32:31,973:INFO:Uploading model into container now
2025-10-09 02:32:31,974:INFO:_master_model_container: 24
2025-10-09 02:32:31,974:INFO:_display_container: 3
2025-10-09 02:32:31,974:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-09 02:32:31,975:INFO:create_model() successfully completed......................................
2025-10-09 02:32:32,069:INFO:SubProcess create_model() end ==================================
2025-10-09 02:32:32,069:INFO:Creating metrics dataframe
2025-10-09 02:32:32,077:INFO:Initializing Linear Discriminant Analysis
2025-10-09 02:32:32,077:INFO:Total runtime is 0.08933478196461996 minutes
2025-10-09 02:32:32,080:INFO:SubProcess create_model() called ==================================
2025-10-09 02:32:32,080:INFO:Initializing create_model()
2025-10-09 02:32:32,080:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A66406FD0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025A0B3FCF10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:32:32,080:INFO:Checking exceptions
2025-10-09 02:32:32,081:INFO:Importing libraries
2025-10-09 02:32:32,081:INFO:Copying training dataset
2025-10-09 02:32:32,084:INFO:Defining folds
2025-10-09 02:32:32,084:INFO:Declaring metric variables
2025-10-09 02:32:32,086:INFO:Importing untrained model
2025-10-09 02:32:32,090:INFO:Linear Discriminant Analysis Imported successfully
2025-10-09 02:32:32,099:INFO:Starting cross validation
2025-10-09 02:32:32,100:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:32:32,245:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:32,261:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:32,263:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:32,285:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:32,294:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:32,343:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:32,357:INFO:Calculating mean and std
2025-10-09 02:32:32,357:INFO:Creating metrics dataframe
2025-10-09 02:32:32,360:INFO:Uploading results into container
2025-10-09 02:32:32,360:INFO:Uploading model into container now
2025-10-09 02:32:32,361:INFO:_master_model_container: 25
2025-10-09 02:32:32,361:INFO:_display_container: 3
2025-10-09 02:32:32,361:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-09 02:32:32,361:INFO:create_model() successfully completed......................................
2025-10-09 02:32:32,461:INFO:SubProcess create_model() end ==================================
2025-10-09 02:32:32,461:INFO:Creating metrics dataframe
2025-10-09 02:32:32,470:INFO:Initializing Extra Trees Classifier
2025-10-09 02:32:32,470:INFO:Total runtime is 0.09586925109227498 minutes
2025-10-09 02:32:32,473:INFO:SubProcess create_model() called ==================================
2025-10-09 02:32:32,474:INFO:Initializing create_model()
2025-10-09 02:32:32,474:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A66406FD0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025A0B3FCF10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:32:32,474:INFO:Checking exceptions
2025-10-09 02:32:32,474:INFO:Importing libraries
2025-10-09 02:32:32,474:INFO:Copying training dataset
2025-10-09 02:32:32,477:INFO:Defining folds
2025-10-09 02:32:32,477:INFO:Declaring metric variables
2025-10-09 02:32:32,480:INFO:Importing untrained model
2025-10-09 02:32:32,484:INFO:Extra Trees Classifier Imported successfully
2025-10-09 02:32:32,495:INFO:Starting cross validation
2025-10-09 02:32:32,496:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:32:32,900:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:32,902:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:32,986:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:33,154:INFO:Calculating mean and std
2025-10-09 02:32:33,154:INFO:Creating metrics dataframe
2025-10-09 02:32:33,156:INFO:Uploading results into container
2025-10-09 02:32:33,157:INFO:Uploading model into container now
2025-10-09 02:32:33,157:INFO:_master_model_container: 26
2025-10-09 02:32:33,157:INFO:_display_container: 3
2025-10-09 02:32:33,158:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-10-09 02:32:33,158:INFO:create_model() successfully completed......................................
2025-10-09 02:32:33,241:INFO:SubProcess create_model() end ==================================
2025-10-09 02:32:33,241:INFO:Creating metrics dataframe
2025-10-09 02:32:33,253:INFO:Initializing Light Gradient Boosting Machine
2025-10-09 02:32:33,253:INFO:Total runtime is 0.10891854365666707 minutes
2025-10-09 02:32:33,257:INFO:SubProcess create_model() called ==================================
2025-10-09 02:32:33,258:INFO:Initializing create_model()
2025-10-09 02:32:33,258:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A66406FD0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025A0B3FCF10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:32:33,258:INFO:Checking exceptions
2025-10-09 02:32:33,258:INFO:Importing libraries
2025-10-09 02:32:33,259:INFO:Copying training dataset
2025-10-09 02:32:33,263:INFO:Defining folds
2025-10-09 02:32:33,263:INFO:Declaring metric variables
2025-10-09 02:32:33,268:INFO:Importing untrained model
2025-10-09 02:32:33,273:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-09 02:32:33,284:INFO:Starting cross validation
2025-10-09 02:32:33,286:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:32:33,494:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:33,494:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:33,511:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:33,621:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:33,682:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:33,745:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:33,763:INFO:Calculating mean and std
2025-10-09 02:32:33,765:INFO:Creating metrics dataframe
2025-10-09 02:32:33,769:INFO:Uploading results into container
2025-10-09 02:32:33,770:INFO:Uploading model into container now
2025-10-09 02:32:33,771:INFO:_master_model_container: 27
2025-10-09 02:32:33,771:INFO:_display_container: 3
2025-10-09 02:32:33,772:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-09 02:32:33,772:INFO:create_model() successfully completed......................................
2025-10-09 02:32:33,869:INFO:SubProcess create_model() end ==================================
2025-10-09 02:32:33,869:INFO:Creating metrics dataframe
2025-10-09 02:32:33,878:INFO:Initializing Dummy Classifier
2025-10-09 02:32:33,878:INFO:Total runtime is 0.11934954325358073 minutes
2025-10-09 02:32:33,881:INFO:SubProcess create_model() called ==================================
2025-10-09 02:32:33,882:INFO:Initializing create_model()
2025-10-09 02:32:33,882:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A66406FD0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025A0B3FCF10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:32:33,882:INFO:Checking exceptions
2025-10-09 02:32:33,882:INFO:Importing libraries
2025-10-09 02:32:33,882:INFO:Copying training dataset
2025-10-09 02:32:33,886:INFO:Defining folds
2025-10-09 02:32:33,886:INFO:Declaring metric variables
2025-10-09 02:32:33,890:INFO:Importing untrained model
2025-10-09 02:32:33,894:INFO:Dummy Classifier Imported successfully
2025-10-09 02:32:33,902:INFO:Starting cross validation
2025-10-09 02:32:33,903:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:32:34,039:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:34,040:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:34,046:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:34,052:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:34,056:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:34,064:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:34,067:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:34,081:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:34,136:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:34,144:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:34,155:INFO:Calculating mean and std
2025-10-09 02:32:34,156:INFO:Creating metrics dataframe
2025-10-09 02:32:34,159:INFO:Uploading results into container
2025-10-09 02:32:34,159:INFO:Uploading model into container now
2025-10-09 02:32:34,160:INFO:_master_model_container: 28
2025-10-09 02:32:34,160:INFO:_display_container: 3
2025-10-09 02:32:34,160:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-10-09 02:32:34,160:INFO:create_model() successfully completed......................................
2025-10-09 02:32:34,236:INFO:SubProcess create_model() end ==================================
2025-10-09 02:32:34,236:INFO:Creating metrics dataframe
2025-10-09 02:32:34,245:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-10-09 02:32:34,252:INFO:Initializing create_model()
2025-10-09 02:32:34,252:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A66406FD0>, estimator=DummyClassifier(constant=None, random_state=123, strategy='prior'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:32:34,252:INFO:Checking exceptions
2025-10-09 02:32:34,253:INFO:Importing libraries
2025-10-09 02:32:34,254:INFO:Copying training dataset
2025-10-09 02:32:34,257:INFO:Defining folds
2025-10-09 02:32:34,257:INFO:Declaring metric variables
2025-10-09 02:32:34,257:INFO:Importing untrained model
2025-10-09 02:32:34,257:INFO:Declaring custom model
2025-10-09 02:32:34,258:INFO:Dummy Classifier Imported successfully
2025-10-09 02:32:34,259:INFO:Cross validation set to False
2025-10-09 02:32:34,259:INFO:Fitting Model
2025-10-09 02:32:34,313:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-10-09 02:32:34,313:INFO:create_model() successfully completed......................................
2025-10-09 02:32:34,430:INFO:_master_model_container: 28
2025-10-09 02:32:34,430:INFO:_display_container: 3
2025-10-09 02:32:34,431:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-10-09 02:32:34,431:INFO:compare_models() successfully completed......................................
2025-10-09 02:32:41,492:INFO:Initializing create_model()
2025-10-09 02:32:41,492:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A66406FD0>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:32:41,492:INFO:Checking exceptions
2025-10-09 02:32:41,507:INFO:Importing libraries
2025-10-09 02:32:41,507:INFO:Copying training dataset
2025-10-09 02:32:41,516:INFO:Defining folds
2025-10-09 02:32:41,516:INFO:Declaring metric variables
2025-10-09 02:32:41,521:INFO:Importing untrained model
2025-10-09 02:32:41,527:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-09 02:32:41,536:INFO:Starting cross validation
2025-10-09 02:32:41,538:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:32:41,937:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:41,944:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:42,012:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:42,113:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:42,178:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:42,249:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:42,263:INFO:Calculating mean and std
2025-10-09 02:32:42,264:INFO:Creating metrics dataframe
2025-10-09 02:32:42,271:INFO:Finalizing model
2025-10-09 02:32:42,340:INFO:[LightGBM] [Info] Number of positive: 18, number of negative: 87
2025-10-09 02:32:42,341:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000099 seconds.
2025-10-09 02:32:42,341:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-10-09 02:32:42,341:INFO:[LightGBM] [Info] Total Bins 117
2025-10-09 02:32:42,341:INFO:[LightGBM] [Info] Number of data points in the train set: 105, number of used features: 10
2025-10-09 02:32:42,341:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.171429 -> initscore=-1.575536
2025-10-09 02:32:42,342:INFO:[LightGBM] [Info] Start training from score -1.575536
2025-10-09 02:32:42,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:42,372:INFO:Uploading results into container
2025-10-09 02:32:42,374:INFO:Uploading model into container now
2025-10-09 02:32:42,389:INFO:_master_model_container: 29
2025-10-09 02:32:42,390:INFO:_display_container: 4
2025-10-09 02:32:42,391:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-09 02:32:42,391:INFO:create_model() successfully completed......................................
2025-10-09 02:32:46,071:INFO:Initializing tune_model()
2025-10-09 02:32:46,071:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A66406FD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-10-09 02:32:46,071:INFO:Checking exceptions
2025-10-09 02:32:46,092:INFO:Copying training dataset
2025-10-09 02:32:46,097:INFO:Checking base model
2025-10-09 02:32:46,097:INFO:Base model : Light Gradient Boosting Machine
2025-10-09 02:32:46,103:INFO:Declaring metric variables
2025-10-09 02:32:46,107:INFO:Defining Hyperparameters
2025-10-09 02:32:46,214:INFO:Tuning with n_jobs=-1
2025-10-09 02:32:46,215:INFO:Initializing RandomizedSearchCV
2025-10-09 02:32:51,499:INFO:best_params: {'actual_estimator__reg_lambda': 1e-06, 'actual_estimator__reg_alpha': 4, 'actual_estimator__num_leaves': 80, 'actual_estimator__n_estimators': 130, 'actual_estimator__min_split_gain': 0.5, 'actual_estimator__min_child_samples': 91, 'actual_estimator__learning_rate': 1e-07, 'actual_estimator__feature_fraction': 0.9, 'actual_estimator__bagging_freq': 0, 'actual_estimator__bagging_fraction': 0.5}
2025-10-09 02:32:51,500:INFO:Hyperparameter search completed
2025-10-09 02:32:51,500:INFO:SubProcess create_model() called ==================================
2025-10-09 02:32:51,501:INFO:Initializing create_model()
2025-10-09 02:32:51,502:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A66406FD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025A0A0ECD10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 1e-06, 'reg_alpha': 4, 'num_leaves': 80, 'n_estimators': 130, 'min_split_gain': 0.5, 'min_child_samples': 91, 'learning_rate': 1e-07, 'feature_fraction': 0.9, 'bagging_freq': 0, 'bagging_fraction': 0.5})
2025-10-09 02:32:51,502:INFO:Checking exceptions
2025-10-09 02:32:51,502:INFO:Importing libraries
2025-10-09 02:32:51,502:INFO:Copying training dataset
2025-10-09 02:32:51,509:INFO:Defining folds
2025-10-09 02:32:51,509:INFO:Declaring metric variables
2025-10-09 02:32:51,515:INFO:Importing untrained model
2025-10-09 02:32:51,515:INFO:Declaring custom model
2025-10-09 02:32:51,524:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-09 02:32:51,535:INFO:Starting cross validation
2025-10-09 02:32:51,537:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:32:51,832:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:51,840:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:51,851:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:51,870:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:51,895:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:51,954:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:51,971:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:52,001:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:52,069:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:52,080:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:52,098:INFO:Calculating mean and std
2025-10-09 02:32:52,100:INFO:Creating metrics dataframe
2025-10-09 02:32:52,108:INFO:Finalizing model
2025-10-09 02:32:52,180:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2025-10-09 02:32:52,180:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2025-10-09 02:32:52,180:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-10-09 02:32:52,181:INFO:[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.
2025-10-09 02:32:52,181:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2025-10-09 02:32:52,181:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2025-10-09 02:32:52,181:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-10-09 02:32:52,182:INFO:[LightGBM] [Info] Number of positive: 18, number of negative: 87
2025-10-09 02:32:52,182:INFO:[LightGBM] [Info] Total Bins 0
2025-10-09 02:32:52,182:INFO:[LightGBM] [Info] Number of data points in the train set: 105, number of used features: 0
2025-10-09 02:32:52,182:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.171429 -> initscore=-1.575536
2025-10-09 02:32:52,182:INFO:[LightGBM] [Info] Start training from score -1.575536
2025-10-09 02:32:52,182:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,182:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,183:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,183:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,183:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,183:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,183:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,183:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,183:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,183:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,184:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,184:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,184:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,184:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,184:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,184:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,184:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,185:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,185:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,185:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,185:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,185:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,186:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,186:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,186:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,186:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,186:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,186:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,186:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,186:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,186:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,187:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,187:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,187:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,187:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,187:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,187:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,187:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,187:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,187:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,187:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,188:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,188:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,188:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,188:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,188:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,188:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,188:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,188:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,188:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,188:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,189:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,189:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,189:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,189:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,189:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,189:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,190:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,190:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,190:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,190:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,190:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,190:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,190:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,190:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,191:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,191:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,191:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,191:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,191:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,191:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,191:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,191:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,192:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,192:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,192:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,192:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,193:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,193:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,193:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,193:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,193:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,193:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,193:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,193:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,193:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,194:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,194:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,194:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,194:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,194:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,194:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,194:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,194:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,195:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,195:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,195:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,195:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,195:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,195:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,195:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,195:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,196:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,196:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,196:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,196:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,196:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,196:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,196:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,197:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,197:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,197:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,197:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,197:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,197:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,197:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,197:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,197:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,198:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,198:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,198:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,198:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,198:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,198:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,198:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,198:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,199:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,199:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,199:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,199:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:32:52,207:INFO:Uploading results into container
2025-10-09 02:32:52,208:INFO:Uploading model into container now
2025-10-09 02:32:52,209:INFO:_master_model_container: 30
2025-10-09 02:32:52,209:INFO:_display_container: 5
2025-10-09 02:32:52,210:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-09 02:32:52,210:INFO:create_model() successfully completed......................................
2025-10-09 02:32:52,358:INFO:SubProcess create_model() end ==================================
2025-10-09 02:32:52,358:INFO:choose_better activated
2025-10-09 02:32:52,363:INFO:SubProcess create_model() called ==================================
2025-10-09 02:32:52,364:INFO:Initializing create_model()
2025-10-09 02:32:52,365:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A66406FD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:32:52,365:INFO:Checking exceptions
2025-10-09 02:32:52,368:INFO:Importing libraries
2025-10-09 02:32:52,368:INFO:Copying training dataset
2025-10-09 02:32:52,374:INFO:Defining folds
2025-10-09 02:32:52,374:INFO:Declaring metric variables
2025-10-09 02:32:52,374:INFO:Importing untrained model
2025-10-09 02:32:52,374:INFO:Declaring custom model
2025-10-09 02:32:52,377:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-09 02:32:52,377:INFO:Starting cross validation
2025-10-09 02:32:52,380:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:32:52,649:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:52,649:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:52,737:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:52,792:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:52,843:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:52,893:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:32:52,908:INFO:Calculating mean and std
2025-10-09 02:32:52,908:INFO:Creating metrics dataframe
2025-10-09 02:32:52,911:INFO:Finalizing model
2025-10-09 02:32:52,975:INFO:[LightGBM] [Info] Number of positive: 18, number of negative: 87
2025-10-09 02:32:52,975:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000085 seconds.
2025-10-09 02:32:52,975:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-10-09 02:32:52,976:INFO:[LightGBM] [Info] Total Bins 117
2025-10-09 02:32:52,976:INFO:[LightGBM] [Info] Number of data points in the train set: 105, number of used features: 10
2025-10-09 02:32:52,976:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.171429 -> initscore=-1.575536
2025-10-09 02:32:52,976:INFO:[LightGBM] [Info] Start training from score -1.575536
2025-10-09 02:32:52,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:52,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:52,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:52,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:52,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:52,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:52,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:52,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:52,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:52,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:52,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:52,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:52,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:52,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:52,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:52,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:52,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:52,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:52,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:52,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:52,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:52,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:52,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:52,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:52,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:52,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:52,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:52,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:52,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:52,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:52,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:52,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:52,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:52,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:52,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:52,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:52,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:52,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:52,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:52,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:52,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:52,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:52,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:52,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:52,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:52,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:52,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:52,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:52,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:52,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:52,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:52,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:52,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:52,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:52,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:52,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:52,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:52,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:52,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:52,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:52,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:52,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:52,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:52,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:52,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:52,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:52,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:52,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:52,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:52,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:52,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:52,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:52,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:52,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:52,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:52,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:53,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:53,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:53,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:53,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:53,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:53,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:53,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:53,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:53,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:53,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:53,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:53,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:53,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:53,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:53,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:53,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:53,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:53,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:53,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:53,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:53,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:53,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:53,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:53,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:32:53,011:INFO:Uploading results into container
2025-10-09 02:32:53,012:INFO:Uploading model into container now
2025-10-09 02:32:53,013:INFO:_master_model_container: 31
2025-10-09 02:32:53,013:INFO:_display_container: 6
2025-10-09 02:32:53,014:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-09 02:32:53,014:INFO:create_model() successfully completed......................................
2025-10-09 02:32:53,129:INFO:SubProcess create_model() end ==================================
2025-10-09 02:32:53,130:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.7891
2025-10-09 02:32:53,131:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.8291
2025-10-09 02:32:53,132:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-10-09 02:32:53,132:INFO:choose_better completed
2025-10-09 02:32:53,144:INFO:_master_model_container: 31
2025-10-09 02:32:53,144:INFO:_display_container: 5
2025-10-09 02:32:53,145:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-09 02:32:53,145:INFO:tune_model() successfully completed......................................
2025-10-09 02:32:56,690:INFO:Initializing tune_model()
2025-10-09 02:32:56,690:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A66406FD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-10-09 02:32:56,690:INFO:Checking exceptions
2025-10-09 02:32:56,709:INFO:Copying training dataset
2025-10-09 02:32:56,713:INFO:Checking base model
2025-10-09 02:32:56,714:INFO:Base model : Light Gradient Boosting Machine
2025-10-09 02:32:56,719:INFO:Declaring metric variables
2025-10-09 02:32:56,724:INFO:Defining Hyperparameters
2025-10-09 02:32:56,824:INFO:Tuning with n_jobs=-1
2025-10-09 02:32:56,824:INFO:Initializing RandomizedSearchCV
2025-10-09 02:33:02,093:INFO:best_params: {'actual_estimator__reg_lambda': 1e-06, 'actual_estimator__reg_alpha': 4, 'actual_estimator__num_leaves': 80, 'actual_estimator__n_estimators': 130, 'actual_estimator__min_split_gain': 0.5, 'actual_estimator__min_child_samples': 91, 'actual_estimator__learning_rate': 1e-07, 'actual_estimator__feature_fraction': 0.9, 'actual_estimator__bagging_freq': 0, 'actual_estimator__bagging_fraction': 0.5}
2025-10-09 02:33:02,094:INFO:Hyperparameter search completed
2025-10-09 02:33:02,094:INFO:SubProcess create_model() called ==================================
2025-10-09 02:33:02,096:INFO:Initializing create_model()
2025-10-09 02:33:02,096:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A66406FD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025A09F2CF50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 1e-06, 'reg_alpha': 4, 'num_leaves': 80, 'n_estimators': 130, 'min_split_gain': 0.5, 'min_child_samples': 91, 'learning_rate': 1e-07, 'feature_fraction': 0.9, 'bagging_freq': 0, 'bagging_fraction': 0.5})
2025-10-09 02:33:02,097:INFO:Checking exceptions
2025-10-09 02:33:02,097:INFO:Importing libraries
2025-10-09 02:33:02,097:INFO:Copying training dataset
2025-10-09 02:33:02,102:INFO:Defining folds
2025-10-09 02:33:02,103:INFO:Declaring metric variables
2025-10-09 02:33:02,107:INFO:Importing untrained model
2025-10-09 02:33:02,107:INFO:Declaring custom model
2025-10-09 02:33:02,113:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-09 02:33:02,122:INFO:Starting cross validation
2025-10-09 02:33:02,125:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:33:02,338:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:33:02,341:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:33:02,349:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:33:02,374:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:33:02,436:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:33:02,455:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:33:02,500:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:33:02,505:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:33:02,535:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:33:02,556:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:33:02,570:INFO:Calculating mean and std
2025-10-09 02:33:02,572:INFO:Creating metrics dataframe
2025-10-09 02:33:02,579:INFO:Finalizing model
2025-10-09 02:33:02,636:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2025-10-09 02:33:02,637:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2025-10-09 02:33:02,637:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-10-09 02:33:02,637:INFO:[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.
2025-10-09 02:33:02,638:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2025-10-09 02:33:02,638:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2025-10-09 02:33:02,638:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-10-09 02:33:02,638:INFO:[LightGBM] [Info] Number of positive: 18, number of negative: 87
2025-10-09 02:33:02,639:INFO:[LightGBM] [Info] Total Bins 0
2025-10-09 02:33:02,639:INFO:[LightGBM] [Info] Number of data points in the train set: 105, number of used features: 0
2025-10-09 02:33:02,639:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.171429 -> initscore=-1.575536
2025-10-09 02:33:02,639:INFO:[LightGBM] [Info] Start training from score -1.575536
2025-10-09 02:33:02,639:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,639:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,639:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,639:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,640:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,640:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,640:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,640:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,640:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,640:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,640:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,640:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,640:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,641:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,641:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,641:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,641:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,641:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,641:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,641:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,641:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,641:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,642:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,642:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,642:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,642:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,642:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,642:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,642:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,642:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,643:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,643:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,643:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,643:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,643:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,643:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,643:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,643:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,643:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,644:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,644:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,644:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,644:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,644:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,644:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,644:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,644:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,645:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,645:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,645:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,645:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,645:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,645:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,645:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,645:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,645:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,645:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,646:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,646:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,646:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,646:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,646:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,646:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,646:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,646:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,647:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,647:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,647:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,647:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,647:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,647:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,647:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,647:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,648:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,648:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,648:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,648:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,648:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,648:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,648:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,649:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,649:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,649:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,650:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,650:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,650:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,650:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,650:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,650:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,650:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,650:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,650:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,651:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,651:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,651:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,651:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,651:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,651:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,651:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,651:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,651:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,652:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,652:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,652:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,652:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,652:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,652:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,652:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,652:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,653:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,653:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,653:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,653:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,653:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,653:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,653:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,653:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,654:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,654:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,654:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,654:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,654:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,654:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,654:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,654:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,654:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,655:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,655:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,655:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,655:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:02,661:INFO:Uploading results into container
2025-10-09 02:33:02,662:INFO:Uploading model into container now
2025-10-09 02:33:02,663:INFO:_master_model_container: 32
2025-10-09 02:33:02,663:INFO:_display_container: 6
2025-10-09 02:33:02,665:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-09 02:33:02,665:INFO:create_model() successfully completed......................................
2025-10-09 02:33:02,793:INFO:SubProcess create_model() end ==================================
2025-10-09 02:33:02,793:INFO:choose_better activated
2025-10-09 02:33:02,798:INFO:SubProcess create_model() called ==================================
2025-10-09 02:33:02,800:INFO:Initializing create_model()
2025-10-09 02:33:02,800:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A66406FD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:33:02,800:INFO:Checking exceptions
2025-10-09 02:33:02,802:INFO:Importing libraries
2025-10-09 02:33:02,803:INFO:Copying training dataset
2025-10-09 02:33:02,808:INFO:Defining folds
2025-10-09 02:33:02,809:INFO:Declaring metric variables
2025-10-09 02:33:02,809:INFO:Importing untrained model
2025-10-09 02:33:02,809:INFO:Declaring custom model
2025-10-09 02:33:02,811:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-09 02:33:02,812:INFO:Starting cross validation
2025-10-09 02:33:02,814:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:33:03,067:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:33:03,067:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:33:03,074:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:33:03,240:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:33:03,306:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:33:03,368:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:33:03,387:INFO:Calculating mean and std
2025-10-09 02:33:03,388:INFO:Creating metrics dataframe
2025-10-09 02:33:03,390:INFO:Finalizing model
2025-10-09 02:33:03,446:INFO:[LightGBM] [Info] Number of positive: 18, number of negative: 87
2025-10-09 02:33:03,446:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000069 seconds.
2025-10-09 02:33:03,446:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-10-09 02:33:03,446:INFO:[LightGBM] [Info] Total Bins 117
2025-10-09 02:33:03,446:INFO:[LightGBM] [Info] Number of data points in the train set: 105, number of used features: 10
2025-10-09 02:33:03,446:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.171429 -> initscore=-1.575536
2025-10-09 02:33:03,447:INFO:[LightGBM] [Info] Start training from score -1.575536
2025-10-09 02:33:03,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:03,475:INFO:Uploading results into container
2025-10-09 02:33:03,476:INFO:Uploading model into container now
2025-10-09 02:33:03,477:INFO:_master_model_container: 33
2025-10-09 02:33:03,477:INFO:_display_container: 7
2025-10-09 02:33:03,478:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-09 02:33:03,478:INFO:create_model() successfully completed......................................
2025-10-09 02:33:03,593:INFO:SubProcess create_model() end ==================================
2025-10-09 02:33:03,594:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.7891
2025-10-09 02:33:03,595:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.8291
2025-10-09 02:33:03,596:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-10-09 02:33:03,596:INFO:choose_better completed
2025-10-09 02:33:03,608:INFO:_master_model_container: 33
2025-10-09 02:33:03,608:INFO:_display_container: 6
2025-10-09 02:33:03,609:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-09 02:33:03,609:INFO:tune_model() successfully completed......................................
2025-10-09 02:33:11,294:INFO:Initializing evaluate_model()
2025-10-09 02:33:11,294:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A66406FD0>, estimator=LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-10-09 02:33:11,306:INFO:Initializing plot_model()
2025-10-09 02:33:11,306:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A66406FD0>, estimator=LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 02:33:11,307:INFO:Checking exceptions
2025-10-09 02:33:11,308:INFO:Preloading libraries
2025-10-09 02:33:11,310:INFO:Copying training dataset
2025-10-09 02:33:11,310:INFO:Plot type: pipeline
2025-10-09 02:33:11,516:INFO:Visual Rendered Successfully
2025-10-09 02:33:11,614:INFO:plot_model() successfully completed......................................
2025-10-09 02:33:15,649:INFO:Initializing predict_model()
2025-10-09 02:33:15,649:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A66406FD0>, estimator=LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000025A0AF9F380>)
2025-10-09 02:33:15,649:INFO:Checking exceptions
2025-10-09 02:33:15,649:INFO:Preloading libraries
2025-10-09 02:33:15,767:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:33:32,090:INFO:Initializing tune_model()
2025-10-09 02:33:32,090:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A66406FD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-10-09 02:33:32,090:INFO:Checking exceptions
2025-10-09 02:33:32,108:INFO:Copying training dataset
2025-10-09 02:33:32,112:INFO:Checking base model
2025-10-09 02:33:32,112:INFO:Base model : Light Gradient Boosting Machine
2025-10-09 02:33:32,116:INFO:Declaring metric variables
2025-10-09 02:33:32,120:INFO:Defining Hyperparameters
2025-10-09 02:33:32,218:INFO:Tuning with n_jobs=-1
2025-10-09 02:33:32,218:INFO:Initializing RandomizedSearchCV
2025-10-09 02:33:37,468:INFO:best_params: {'actual_estimator__reg_lambda': 1e-06, 'actual_estimator__reg_alpha': 4, 'actual_estimator__num_leaves': 80, 'actual_estimator__n_estimators': 130, 'actual_estimator__min_split_gain': 0.5, 'actual_estimator__min_child_samples': 91, 'actual_estimator__learning_rate': 1e-07, 'actual_estimator__feature_fraction': 0.9, 'actual_estimator__bagging_freq': 0, 'actual_estimator__bagging_fraction': 0.5}
2025-10-09 02:33:37,469:INFO:Hyperparameter search completed
2025-10-09 02:33:37,469:INFO:SubProcess create_model() called ==================================
2025-10-09 02:33:37,470:INFO:Initializing create_model()
2025-10-09 02:33:37,470:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A66406FD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025A0AEB4B50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 1e-06, 'reg_alpha': 4, 'num_leaves': 80, 'n_estimators': 130, 'min_split_gain': 0.5, 'min_child_samples': 91, 'learning_rate': 1e-07, 'feature_fraction': 0.9, 'bagging_freq': 0, 'bagging_fraction': 0.5})
2025-10-09 02:33:37,471:INFO:Checking exceptions
2025-10-09 02:33:37,471:INFO:Importing libraries
2025-10-09 02:33:37,471:INFO:Copying training dataset
2025-10-09 02:33:37,477:INFO:Defining folds
2025-10-09 02:33:37,478:INFO:Declaring metric variables
2025-10-09 02:33:37,482:INFO:Importing untrained model
2025-10-09 02:33:37,482:INFO:Declaring custom model
2025-10-09 02:33:37,488:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-09 02:33:37,500:INFO:Starting cross validation
2025-10-09 02:33:37,502:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:33:37,749:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:33:37,779:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:33:37,809:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:33:37,823:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:33:37,872:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:33:37,887:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:33:37,887:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:33:37,947:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:33:37,953:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:33:37,953:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:33:37,972:INFO:Calculating mean and std
2025-10-09 02:33:37,974:INFO:Creating metrics dataframe
2025-10-09 02:33:37,981:INFO:Finalizing model
2025-10-09 02:33:38,041:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2025-10-09 02:33:38,041:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2025-10-09 02:33:38,041:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-10-09 02:33:38,042:INFO:[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.
2025-10-09 02:33:38,042:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2025-10-09 02:33:38,042:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2025-10-09 02:33:38,042:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-10-09 02:33:38,042:INFO:[LightGBM] [Info] Number of positive: 18, number of negative: 87
2025-10-09 02:33:38,043:INFO:[LightGBM] [Info] Total Bins 0
2025-10-09 02:33:38,043:INFO:[LightGBM] [Info] Number of data points in the train set: 105, number of used features: 0
2025-10-09 02:33:38,043:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.171429 -> initscore=-1.575536
2025-10-09 02:33:38,043:INFO:[LightGBM] [Info] Start training from score -1.575536
2025-10-09 02:33:38,043:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,044:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,044:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,044:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,044:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,044:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,045:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,045:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,045:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,046:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,046:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,046:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,046:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,046:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,046:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,046:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,047:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,047:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,047:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,047:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,047:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,047:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,047:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,047:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,048:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,048:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,048:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,048:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,048:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,048:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,049:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,049:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,049:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,049:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,049:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,049:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,050:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,050:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,050:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,050:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,050:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,050:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,050:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,050:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,051:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,051:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,051:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,051:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,051:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,051:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,052:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,052:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,052:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,052:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,052:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,053:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,053:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,053:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,053:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,053:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,053:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,053:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,053:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,054:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,054:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,054:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,054:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,054:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,054:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,054:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,055:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,055:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,055:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,055:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,055:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,055:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,055:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,055:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,055:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,056:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,056:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,056:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,056:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,056:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,057:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,057:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,057:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,057:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,057:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,057:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,057:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,057:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,058:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,058:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,058:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,058:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,058:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,059:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,059:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,059:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,059:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,059:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,059:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,060:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,060:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,060:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,060:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,060:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,060:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,060:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,061:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,061:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,061:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,061:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,061:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,061:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,061:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,061:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,062:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,062:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,062:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,062:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,062:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,062:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,062:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,063:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,063:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,063:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,063:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,063:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:33:38,070:INFO:Uploading results into container
2025-10-09 02:33:38,072:INFO:Uploading model into container now
2025-10-09 02:33:38,073:INFO:_master_model_container: 34
2025-10-09 02:33:38,073:INFO:_display_container: 8
2025-10-09 02:33:38,074:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-09 02:33:38,075:INFO:create_model() successfully completed......................................
2025-10-09 02:33:38,234:INFO:SubProcess create_model() end ==================================
2025-10-09 02:33:38,234:INFO:choose_better activated
2025-10-09 02:33:38,237:INFO:SubProcess create_model() called ==================================
2025-10-09 02:33:38,238:INFO:Initializing create_model()
2025-10-09 02:33:38,238:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A66406FD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:33:38,238:INFO:Checking exceptions
2025-10-09 02:33:38,240:INFO:Importing libraries
2025-10-09 02:33:38,240:INFO:Copying training dataset
2025-10-09 02:33:38,243:INFO:Defining folds
2025-10-09 02:33:38,243:INFO:Declaring metric variables
2025-10-09 02:33:38,243:INFO:Importing untrained model
2025-10-09 02:33:38,243:INFO:Declaring custom model
2025-10-09 02:33:38,245:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-09 02:33:38,245:INFO:Starting cross validation
2025-10-09 02:33:38,246:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:33:38,463:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:33:38,480:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:33:38,612:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:33:38,669:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:33:38,695:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:33:38,765:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:33:38,784:INFO:Calculating mean and std
2025-10-09 02:33:38,785:INFO:Creating metrics dataframe
2025-10-09 02:33:38,788:INFO:Finalizing model
2025-10-09 02:33:38,844:INFO:[LightGBM] [Info] Number of positive: 18, number of negative: 87
2025-10-09 02:33:38,844:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000063 seconds.
2025-10-09 02:33:38,844:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-10-09 02:33:38,844:INFO:[LightGBM] [Info] Total Bins 117
2025-10-09 02:33:38,844:INFO:[LightGBM] [Info] Number of data points in the train set: 105, number of used features: 10
2025-10-09 02:33:38,844:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.171429 -> initscore=-1.575536
2025-10-09 02:33:38,844:INFO:[LightGBM] [Info] Start training from score -1.575536
2025-10-09 02:33:38,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:33:38,872:INFO:Uploading results into container
2025-10-09 02:33:38,873:INFO:Uploading model into container now
2025-10-09 02:33:38,874:INFO:_master_model_container: 35
2025-10-09 02:33:38,874:INFO:_display_container: 9
2025-10-09 02:33:38,875:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-09 02:33:38,875:INFO:create_model() successfully completed......................................
2025-10-09 02:33:38,974:INFO:SubProcess create_model() end ==================================
2025-10-09 02:33:38,975:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.7891
2025-10-09 02:33:38,976:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.8291
2025-10-09 02:33:38,977:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-10-09 02:33:38,977:INFO:choose_better completed
2025-10-09 02:33:38,986:INFO:_master_model_container: 35
2025-10-09 02:33:38,986:INFO:_display_container: 8
2025-10-09 02:33:38,987:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-09 02:33:38,987:INFO:tune_model() successfully completed......................................
2025-10-09 02:34:02,140:INFO:PyCaret ClassificationExperiment
2025-10-09 02:34:02,140:INFO:Logging name: clf-default-name
2025-10-09 02:34:02,140:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-10-09 02:34:02,140:INFO:version 3.3.2
2025-10-09 02:34:02,140:INFO:Initializing setup()
2025-10-09 02:34:02,140:INFO:self.USI: 1c77
2025-10-09 02:34:02,140:INFO:self._variable_keys: {'y_test', 'fold_shuffle_param', 'y', 'exp_name_log', 'n_jobs_param', 'exp_id', 'target_param', 'X_test', 'fold_groups_param', 'fix_imbalance', 'is_multiclass', 'pipeline', '_available_plots', 'gpu_param', 'memory', 'X', 'seed', 'data', 'idx', 'USI', 'X_train', '_ml_usecase', 'y_train', 'log_plots_param', 'logging_param', 'html_param', 'fold_generator', 'gpu_n_jobs_param'}
2025-10-09 02:34:02,140:INFO:Checking environment
2025-10-09 02:34:02,140:INFO:python_version: 3.11.0
2025-10-09 02:34:02,141:INFO:python_build: ('main', 'Oct 24 2022 18:26:48')
2025-10-09 02:34:02,141:INFO:machine: AMD64
2025-10-09 02:34:02,141:INFO:platform: Windows-10-10.0.19045-SP0
2025-10-09 02:34:02,147:INFO:Memory: svmem(total=12713988096, available=595800064, percent=95.3, used=12118188032, free=595800064)
2025-10-09 02:34:02,147:INFO:Physical Core: 4
2025-10-09 02:34:02,147:INFO:Logical Core: 8
2025-10-09 02:34:02,147:INFO:Checking libraries
2025-10-09 02:34:02,147:INFO:System:
2025-10-09 02:34:02,147:INFO:    python: 3.11.0 (main, Oct 24 2022, 18:26:48) [MSC v.1933 64 bit (AMD64)]
2025-10-09 02:34:02,147:INFO:executable: c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\python.exe
2025-10-09 02:34:02,147:INFO:   machine: Windows-10-10.0.19045-SP0
2025-10-09 02:34:02,147:INFO:PyCaret required dependencies:
2025-10-09 02:34:02,147:INFO:                 pip: 25.2
2025-10-09 02:34:02,147:INFO:          setuptools: 65.5.0
2025-10-09 02:34:02,147:INFO:             pycaret: 3.3.2
2025-10-09 02:34:02,147:INFO:             IPython: 9.6.0
2025-10-09 02:34:02,148:INFO:          ipywidgets: 8.1.7
2025-10-09 02:34:02,148:INFO:                tqdm: 4.67.1
2025-10-09 02:34:02,148:INFO:               numpy: 1.26.4
2025-10-09 02:34:02,148:INFO:              pandas: 2.1.4
2025-10-09 02:34:02,148:INFO:              jinja2: 3.1.6
2025-10-09 02:34:02,148:INFO:               scipy: 1.11.4
2025-10-09 02:34:02,148:INFO:              joblib: 1.3.2
2025-10-09 02:34:02,148:INFO:             sklearn: 1.4.2
2025-10-09 02:34:02,148:INFO:                pyod: 2.0.5
2025-10-09 02:34:02,148:INFO:            imblearn: 0.14.0
2025-10-09 02:34:02,148:INFO:   category_encoders: 2.7.0
2025-10-09 02:34:02,148:INFO:            lightgbm: 4.6.0
2025-10-09 02:34:02,148:INFO:               numba: 0.62.1
2025-10-09 02:34:02,148:INFO:            requests: 2.32.5
2025-10-09 02:34:02,148:INFO:          matplotlib: 3.7.5
2025-10-09 02:34:02,148:INFO:          scikitplot: 0.3.7
2025-10-09 02:34:02,148:INFO:         yellowbrick: 1.5
2025-10-09 02:34:02,148:INFO:              plotly: 6.3.1
2025-10-09 02:34:02,148:INFO:    plotly-resampler: Not installed
2025-10-09 02:34:02,148:INFO:             kaleido: 1.1.0
2025-10-09 02:34:02,148:INFO:           schemdraw: 0.15
2025-10-09 02:34:02,148:INFO:         statsmodels: 0.14.5
2025-10-09 02:34:02,149:INFO:              sktime: 0.26.0
2025-10-09 02:34:02,149:INFO:               tbats: 1.1.3
2025-10-09 02:34:02,149:INFO:            pmdarima: 2.0.4
2025-10-09 02:34:02,149:INFO:              psutil: 7.1.0
2025-10-09 02:34:02,149:INFO:          markupsafe: 3.0.3
2025-10-09 02:34:02,149:INFO:             pickle5: Not installed
2025-10-09 02:34:02,149:INFO:         cloudpickle: 3.1.1
2025-10-09 02:34:02,149:INFO:         deprecation: 2.1.0
2025-10-09 02:34:02,149:INFO:              xxhash: 3.6.0
2025-10-09 02:34:02,149:INFO:           wurlitzer: Not installed
2025-10-09 02:34:02,149:INFO:PyCaret optional dependencies:
2025-10-09 02:34:02,149:INFO:                shap: Not installed
2025-10-09 02:34:02,149:INFO:           interpret: Not installed
2025-10-09 02:34:02,149:INFO:                umap: Not installed
2025-10-09 02:34:02,149:INFO:     ydata_profiling: Not installed
2025-10-09 02:34:02,149:INFO:  explainerdashboard: Not installed
2025-10-09 02:34:02,149:INFO:             autoviz: Not installed
2025-10-09 02:34:02,149:INFO:           fairlearn: Not installed
2025-10-09 02:34:02,150:INFO:          deepchecks: Not installed
2025-10-09 02:34:02,150:INFO:             xgboost: Not installed
2025-10-09 02:34:02,150:INFO:            catboost: Not installed
2025-10-09 02:34:02,150:INFO:              kmodes: Not installed
2025-10-09 02:34:02,150:INFO:             mlxtend: Not installed
2025-10-09 02:34:02,150:INFO:       statsforecast: Not installed
2025-10-09 02:34:02,150:INFO:        tune_sklearn: Not installed
2025-10-09 02:34:02,150:INFO:                 ray: Not installed
2025-10-09 02:34:02,150:INFO:            hyperopt: Not installed
2025-10-09 02:34:02,150:INFO:              optuna: Not installed
2025-10-09 02:34:02,150:INFO:               skopt: Not installed
2025-10-09 02:34:02,150:INFO:              mlflow: Not installed
2025-10-09 02:34:02,150:INFO:              gradio: Not installed
2025-10-09 02:34:02,150:INFO:             fastapi: Not installed
2025-10-09 02:34:02,151:INFO:             uvicorn: Not installed
2025-10-09 02:34:02,151:INFO:              m2cgen: Not installed
2025-10-09 02:34:02,151:INFO:           evidently: Not installed
2025-10-09 02:34:02,151:INFO:               fugue: Not installed
2025-10-09 02:34:02,151:INFO:           streamlit: Not installed
2025-10-09 02:34:02,151:INFO:             prophet: Not installed
2025-10-09 02:34:02,151:INFO:None
2025-10-09 02:34:02,151:INFO:Set up data.
2025-10-09 02:34:02,157:INFO:Set up folding strategy.
2025-10-09 02:34:02,157:INFO:Set up train/test split.
2025-10-09 02:34:02,161:INFO:Set up index.
2025-10-09 02:34:02,162:INFO:Assigning column types.
2025-10-09 02:34:02,165:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-09 02:34:02,221:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-09 02:34:02,223:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-09 02:34:02,263:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 02:34:02,263:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 02:34:02,329:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-09 02:34:02,330:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-09 02:34:02,360:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 02:34:02,360:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 02:34:02,361:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-09 02:34:02,405:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-09 02:34:02,431:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 02:34:02,431:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 02:34:02,481:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-09 02:34:02,508:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 02:34:02,508:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 02:34:02,508:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-10-09 02:34:02,582:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 02:34:02,582:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 02:34:02,653:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 02:34:02,653:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 02:34:02,654:INFO:Preparing preprocessing pipeline...
2025-10-09 02:34:02,656:INFO:Set up simple imputation.
2025-10-09 02:34:02,659:INFO:Set up encoding of ordinal features.
2025-10-09 02:34:02,660:INFO:Set up encoding of categorical features.
2025-10-09 02:34:02,660:INFO:Set up feature normalization.
2025-10-09 02:34:02,764:INFO:Finished creating preprocessing pipeline.
2025-10-09 02:34:02,785:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\jjqs_\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'ingresos_mensuales',
                                             'nro_creditos_previos',
                                             'cuota_vs_ingreso'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'...
                                    include=['estado_civil',
                                             'historia_credito'],
                                    transformer=OneHotEncoder(cols=['estado_civil',
                                                                    'historia_credito'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-10-09 02:34:02,786:INFO:Creating final display dataframe.
2025-10-09 02:34:03,094:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target           default
2                   Target type            Binary
3           Original data shape          (150, 8)
4        Transformed data shape         (150, 12)
5   Transformed train set shape         (105, 12)
6    Transformed test set shape          (45, 12)
7              Numeric features                 4
8          Categorical features                 3
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                    Normalize              True
16             Normalize method            zscore
17               Fold Generator   StratifiedKFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  clf-default-name
23                          USI              1c77
2025-10-09 02:34:03,170:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 02:34:03,170:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 02:34:03,237:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 02:34:03,237:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-09 02:34:03,238:INFO:setup() successfully completed in 1.1s...............
2025-10-09 02:34:06,184:INFO:Initializing compare_models()
2025-10-09 02:34:06,184:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A0ADFF950>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000025A0ADFF950>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-10-09 02:34:06,184:INFO:Checking exceptions
2025-10-09 02:34:06,188:INFO:Preparing display monitor
2025-10-09 02:34:06,212:INFO:Initializing Logistic Regression
2025-10-09 02:34:06,212:INFO:Total runtime is 0.0 minutes
2025-10-09 02:34:06,217:INFO:SubProcess create_model() called ==================================
2025-10-09 02:34:06,217:INFO:Initializing create_model()
2025-10-09 02:34:06,217:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A0ADFF950>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025A0B6BBA90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:34:06,217:INFO:Checking exceptions
2025-10-09 02:34:06,218:INFO:Importing libraries
2025-10-09 02:34:06,218:INFO:Copying training dataset
2025-10-09 02:34:06,224:INFO:Defining folds
2025-10-09 02:34:06,224:INFO:Declaring metric variables
2025-10-09 02:34:06,228:INFO:Importing untrained model
2025-10-09 02:34:06,234:INFO:Logistic Regression Imported successfully
2025-10-09 02:34:06,241:INFO:Starting cross validation
2025-10-09 02:34:06,243:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:34:06,487:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:06,510:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:06,526:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:06,534:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:06,546:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:06,574:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:06,579:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:06,646:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:06,661:INFO:Calculating mean and std
2025-10-09 02:34:06,661:INFO:Creating metrics dataframe
2025-10-09 02:34:06,662:INFO:Uploading results into container
2025-10-09 02:34:06,663:INFO:Uploading model into container now
2025-10-09 02:34:06,663:INFO:_master_model_container: 1
2025-10-09 02:34:06,663:INFO:_display_container: 2
2025-10-09 02:34:06,663:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-09 02:34:06,663:INFO:create_model() successfully completed......................................
2025-10-09 02:34:06,740:INFO:SubProcess create_model() end ==================================
2025-10-09 02:34:06,740:INFO:Creating metrics dataframe
2025-10-09 02:34:06,746:INFO:Initializing K Neighbors Classifier
2025-10-09 02:34:06,746:INFO:Total runtime is 0.008910087744394939 minutes
2025-10-09 02:34:06,750:INFO:SubProcess create_model() called ==================================
2025-10-09 02:34:06,750:INFO:Initializing create_model()
2025-10-09 02:34:06,750:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A0ADFF950>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025A0B6BBA90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:34:06,750:INFO:Checking exceptions
2025-10-09 02:34:06,751:INFO:Importing libraries
2025-10-09 02:34:06,751:INFO:Copying training dataset
2025-10-09 02:34:06,755:INFO:Defining folds
2025-10-09 02:34:06,755:INFO:Declaring metric variables
2025-10-09 02:34:06,758:INFO:Importing untrained model
2025-10-09 02:34:06,762:INFO:K Neighbors Classifier Imported successfully
2025-10-09 02:34:06,770:INFO:Starting cross validation
2025-10-09 02:34:06,772:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:34:07,036:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:07,037:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:07,040:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:07,045:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:07,073:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:07,169:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:07,177:INFO:Calculating mean and std
2025-10-09 02:34:07,177:INFO:Creating metrics dataframe
2025-10-09 02:34:07,179:INFO:Uploading results into container
2025-10-09 02:34:07,179:INFO:Uploading model into container now
2025-10-09 02:34:07,180:INFO:_master_model_container: 2
2025-10-09 02:34:07,180:INFO:_display_container: 2
2025-10-09 02:34:07,180:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-10-09 02:34:07,180:INFO:create_model() successfully completed......................................
2025-10-09 02:34:07,259:INFO:SubProcess create_model() end ==================================
2025-10-09 02:34:07,259:INFO:Creating metrics dataframe
2025-10-09 02:34:07,265:INFO:Initializing Naive Bayes
2025-10-09 02:34:07,266:INFO:Total runtime is 0.017570380369822183 minutes
2025-10-09 02:34:07,269:INFO:SubProcess create_model() called ==================================
2025-10-09 02:34:07,269:INFO:Initializing create_model()
2025-10-09 02:34:07,269:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A0ADFF950>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025A0B6BBA90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:34:07,269:INFO:Checking exceptions
2025-10-09 02:34:07,269:INFO:Importing libraries
2025-10-09 02:34:07,269:INFO:Copying training dataset
2025-10-09 02:34:07,273:INFO:Defining folds
2025-10-09 02:34:07,274:INFO:Declaring metric variables
2025-10-09 02:34:07,277:INFO:Importing untrained model
2025-10-09 02:34:07,280:INFO:Naive Bayes Imported successfully
2025-10-09 02:34:07,287:INFO:Starting cross validation
2025-10-09 02:34:07,289:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:34:07,447:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:07,472:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:07,499:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:07,569:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:07,586:INFO:Calculating mean and std
2025-10-09 02:34:07,587:INFO:Creating metrics dataframe
2025-10-09 02:34:07,589:INFO:Uploading results into container
2025-10-09 02:34:07,590:INFO:Uploading model into container now
2025-10-09 02:34:07,590:INFO:_master_model_container: 3
2025-10-09 02:34:07,590:INFO:_display_container: 2
2025-10-09 02:34:07,590:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-10-09 02:34:07,591:INFO:create_model() successfully completed......................................
2025-10-09 02:34:07,672:INFO:SubProcess create_model() end ==================================
2025-10-09 02:34:07,672:INFO:Creating metrics dataframe
2025-10-09 02:34:07,679:INFO:Initializing Decision Tree Classifier
2025-10-09 02:34:07,679:INFO:Total runtime is 0.024448752403259277 minutes
2025-10-09 02:34:07,682:INFO:SubProcess create_model() called ==================================
2025-10-09 02:34:07,682:INFO:Initializing create_model()
2025-10-09 02:34:07,682:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A0ADFF950>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025A0B6BBA90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:34:07,682:INFO:Checking exceptions
2025-10-09 02:34:07,682:INFO:Importing libraries
2025-10-09 02:34:07,682:INFO:Copying training dataset
2025-10-09 02:34:07,687:INFO:Defining folds
2025-10-09 02:34:07,687:INFO:Declaring metric variables
2025-10-09 02:34:07,690:INFO:Importing untrained model
2025-10-09 02:34:07,694:INFO:Decision Tree Classifier Imported successfully
2025-10-09 02:34:07,701:INFO:Starting cross validation
2025-10-09 02:34:07,703:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:34:07,923:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:08,032:INFO:Calculating mean and std
2025-10-09 02:34:08,034:INFO:Creating metrics dataframe
2025-10-09 02:34:08,036:INFO:Uploading results into container
2025-10-09 02:34:08,036:INFO:Uploading model into container now
2025-10-09 02:34:08,037:INFO:_master_model_container: 4
2025-10-09 02:34:08,037:INFO:_display_container: 2
2025-10-09 02:34:08,038:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-10-09 02:34:08,038:INFO:create_model() successfully completed......................................
2025-10-09 02:34:08,137:INFO:SubProcess create_model() end ==================================
2025-10-09 02:34:08,137:INFO:Creating metrics dataframe
2025-10-09 02:34:08,145:INFO:Initializing SVM - Linear Kernel
2025-10-09 02:34:08,145:INFO:Total runtime is 0.03222585121790568 minutes
2025-10-09 02:34:08,148:INFO:SubProcess create_model() called ==================================
2025-10-09 02:34:08,149:INFO:Initializing create_model()
2025-10-09 02:34:08,149:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A0ADFF950>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025A0B6BBA90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:34:08,149:INFO:Checking exceptions
2025-10-09 02:34:08,149:INFO:Importing libraries
2025-10-09 02:34:08,149:INFO:Copying training dataset
2025-10-09 02:34:08,153:INFO:Defining folds
2025-10-09 02:34:08,153:INFO:Declaring metric variables
2025-10-09 02:34:08,158:INFO:Importing untrained model
2025-10-09 02:34:08,161:INFO:SVM - Linear Kernel Imported successfully
2025-10-09 02:34:08,168:INFO:Starting cross validation
2025-10-09 02:34:08,170:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:34:08,333:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:08,351:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:08,455:INFO:Calculating mean and std
2025-10-09 02:34:08,456:INFO:Creating metrics dataframe
2025-10-09 02:34:08,458:INFO:Uploading results into container
2025-10-09 02:34:08,459:INFO:Uploading model into container now
2025-10-09 02:34:08,459:INFO:_master_model_container: 5
2025-10-09 02:34:08,459:INFO:_display_container: 2
2025-10-09 02:34:08,460:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-10-09 02:34:08,460:INFO:create_model() successfully completed......................................
2025-10-09 02:34:08,543:INFO:SubProcess create_model() end ==================================
2025-10-09 02:34:08,543:INFO:Creating metrics dataframe
2025-10-09 02:34:08,550:INFO:Initializing Ridge Classifier
2025-10-09 02:34:08,550:INFO:Total runtime is 0.038976967334747314 minutes
2025-10-09 02:34:08,553:INFO:SubProcess create_model() called ==================================
2025-10-09 02:34:08,553:INFO:Initializing create_model()
2025-10-09 02:34:08,554:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A0ADFF950>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025A0B6BBA90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:34:08,554:INFO:Checking exceptions
2025-10-09 02:34:08,554:INFO:Importing libraries
2025-10-09 02:34:08,554:INFO:Copying training dataset
2025-10-09 02:34:08,558:INFO:Defining folds
2025-10-09 02:34:08,558:INFO:Declaring metric variables
2025-10-09 02:34:08,562:INFO:Importing untrained model
2025-10-09 02:34:08,567:INFO:Ridge Classifier Imported successfully
2025-10-09 02:34:08,575:INFO:Starting cross validation
2025-10-09 02:34:08,577:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:34:08,730:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:08,742:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:08,746:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:08,748:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:08,751:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:08,768:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:08,771:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:08,852:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:08,859:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:08,869:INFO:Calculating mean and std
2025-10-09 02:34:08,870:INFO:Creating metrics dataframe
2025-10-09 02:34:08,872:INFO:Uploading results into container
2025-10-09 02:34:08,873:INFO:Uploading model into container now
2025-10-09 02:34:08,873:INFO:_master_model_container: 6
2025-10-09 02:34:08,873:INFO:_display_container: 2
2025-10-09 02:34:08,874:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-10-09 02:34:08,874:INFO:create_model() successfully completed......................................
2025-10-09 02:34:08,963:INFO:SubProcess create_model() end ==================================
2025-10-09 02:34:08,963:INFO:Creating metrics dataframe
2025-10-09 02:34:08,971:INFO:Initializing Random Forest Classifier
2025-10-09 02:34:08,971:INFO:Total runtime is 0.04599475463231405 minutes
2025-10-09 02:34:08,974:INFO:SubProcess create_model() called ==================================
2025-10-09 02:34:08,975:INFO:Initializing create_model()
2025-10-09 02:34:08,975:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A0ADFF950>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025A0B6BBA90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:34:08,975:INFO:Checking exceptions
2025-10-09 02:34:08,975:INFO:Importing libraries
2025-10-09 02:34:08,975:INFO:Copying training dataset
2025-10-09 02:34:08,979:INFO:Defining folds
2025-10-09 02:34:08,979:INFO:Declaring metric variables
2025-10-09 02:34:08,984:INFO:Importing untrained model
2025-10-09 02:34:08,987:INFO:Random Forest Classifier Imported successfully
2025-10-09 02:34:08,994:INFO:Starting cross validation
2025-10-09 02:34:08,996:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:34:09,471:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:09,484:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:09,485:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:09,507:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:09,525:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:09,538:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:09,622:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:09,788:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:09,800:INFO:Calculating mean and std
2025-10-09 02:34:09,801:INFO:Creating metrics dataframe
2025-10-09 02:34:09,803:INFO:Uploading results into container
2025-10-09 02:34:09,804:INFO:Uploading model into container now
2025-10-09 02:34:09,804:INFO:_master_model_container: 7
2025-10-09 02:34:09,804:INFO:_display_container: 2
2025-10-09 02:34:09,805:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-10-09 02:34:09,805:INFO:create_model() successfully completed......................................
2025-10-09 02:34:09,899:INFO:SubProcess create_model() end ==================================
2025-10-09 02:34:09,899:INFO:Creating metrics dataframe
2025-10-09 02:34:09,908:INFO:Initializing Quadratic Discriminant Analysis
2025-10-09 02:34:09,908:INFO:Total runtime is 0.06160586675008138 minutes
2025-10-09 02:34:09,911:INFO:SubProcess create_model() called ==================================
2025-10-09 02:34:09,912:INFO:Initializing create_model()
2025-10-09 02:34:09,912:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A0ADFF950>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025A0B6BBA90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:34:09,912:INFO:Checking exceptions
2025-10-09 02:34:09,912:INFO:Importing libraries
2025-10-09 02:34:09,912:INFO:Copying training dataset
2025-10-09 02:34:09,918:INFO:Defining folds
2025-10-09 02:34:09,918:INFO:Declaring metric variables
2025-10-09 02:34:09,923:INFO:Importing untrained model
2025-10-09 02:34:09,928:INFO:Quadratic Discriminant Analysis Imported successfully
2025-10-09 02:34:09,937:INFO:Starting cross validation
2025-10-09 02:34:09,939:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:34:10,060:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 02:34:10,062:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 02:34:10,065:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 02:34:10,067:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 02:34:10,068:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 02:34:10,072:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 02:34:10,074:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 02:34:10,159:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 02:34:10,212:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:10,294:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 02:34:10,295:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 02:34:10,341:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:10,355:INFO:Calculating mean and std
2025-10-09 02:34:10,356:INFO:Creating metrics dataframe
2025-10-09 02:34:10,359:INFO:Uploading results into container
2025-10-09 02:34:10,360:INFO:Uploading model into container now
2025-10-09 02:34:10,360:INFO:_master_model_container: 8
2025-10-09 02:34:10,360:INFO:_display_container: 2
2025-10-09 02:34:10,361:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-10-09 02:34:10,361:INFO:create_model() successfully completed......................................
2025-10-09 02:34:10,451:INFO:SubProcess create_model() end ==================================
2025-10-09 02:34:10,451:INFO:Creating metrics dataframe
2025-10-09 02:34:10,459:INFO:Initializing Ada Boost Classifier
2025-10-09 02:34:10,459:INFO:Total runtime is 0.07079358498255411 minutes
2025-10-09 02:34:10,463:INFO:SubProcess create_model() called ==================================
2025-10-09 02:34:10,463:INFO:Initializing create_model()
2025-10-09 02:34:10,463:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A0ADFF950>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025A0B6BBA90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:34:10,463:INFO:Checking exceptions
2025-10-09 02:34:10,463:INFO:Importing libraries
2025-10-09 02:34:10,463:INFO:Copying training dataset
2025-10-09 02:34:10,467:INFO:Defining folds
2025-10-09 02:34:10,467:INFO:Declaring metric variables
2025-10-09 02:34:10,471:INFO:Importing untrained model
2025-10-09 02:34:10,475:INFO:Ada Boost Classifier Imported successfully
2025-10-09 02:34:10,482:INFO:Starting cross validation
2025-10-09 02:34:10,485:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:34:10,591:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 02:34:10,592:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 02:34:10,592:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 02:34:10,592:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 02:34:10,601:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 02:34:10,601:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 02:34:10,630:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 02:34:10,630:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 02:34:10,883:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:10,924:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 02:34:10,928:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 02:34:10,961:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:11,062:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:11,073:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:11,084:INFO:Calculating mean and std
2025-10-09 02:34:11,085:INFO:Creating metrics dataframe
2025-10-09 02:34:11,087:INFO:Uploading results into container
2025-10-09 02:34:11,087:INFO:Uploading model into container now
2025-10-09 02:34:11,088:INFO:_master_model_container: 9
2025-10-09 02:34:11,088:INFO:_display_container: 2
2025-10-09 02:34:11,088:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-10-09 02:34:11,088:INFO:create_model() successfully completed......................................
2025-10-09 02:34:11,167:INFO:SubProcess create_model() end ==================================
2025-10-09 02:34:11,167:INFO:Creating metrics dataframe
2025-10-09 02:34:11,174:INFO:Initializing Gradient Boosting Classifier
2025-10-09 02:34:11,174:INFO:Total runtime is 0.08269910812377929 minutes
2025-10-09 02:34:11,178:INFO:SubProcess create_model() called ==================================
2025-10-09 02:34:11,178:INFO:Initializing create_model()
2025-10-09 02:34:11,178:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A0ADFF950>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025A0B6BBA90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:34:11,178:INFO:Checking exceptions
2025-10-09 02:34:11,178:INFO:Importing libraries
2025-10-09 02:34:11,178:INFO:Copying training dataset
2025-10-09 02:34:11,181:INFO:Defining folds
2025-10-09 02:34:11,181:INFO:Declaring metric variables
2025-10-09 02:34:11,184:INFO:Importing untrained model
2025-10-09 02:34:11,187:INFO:Gradient Boosting Classifier Imported successfully
2025-10-09 02:34:11,196:INFO:Starting cross validation
2025-10-09 02:34:11,198:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:34:11,591:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:11,836:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:11,842:INFO:Calculating mean and std
2025-10-09 02:34:11,843:INFO:Creating metrics dataframe
2025-10-09 02:34:11,845:INFO:Uploading results into container
2025-10-09 02:34:11,846:INFO:Uploading model into container now
2025-10-09 02:34:11,846:INFO:_master_model_container: 10
2025-10-09 02:34:11,846:INFO:_display_container: 2
2025-10-09 02:34:11,847:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-09 02:34:11,847:INFO:create_model() successfully completed......................................
2025-10-09 02:34:11,928:INFO:SubProcess create_model() end ==================================
2025-10-09 02:34:11,928:INFO:Creating metrics dataframe
2025-10-09 02:34:11,937:INFO:Initializing Linear Discriminant Analysis
2025-10-09 02:34:11,937:INFO:Total runtime is 0.0954302668571472 minutes
2025-10-09 02:34:11,940:INFO:SubProcess create_model() called ==================================
2025-10-09 02:34:11,941:INFO:Initializing create_model()
2025-10-09 02:34:11,941:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A0ADFF950>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025A0B6BBA90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:34:11,941:INFO:Checking exceptions
2025-10-09 02:34:11,941:INFO:Importing libraries
2025-10-09 02:34:11,941:INFO:Copying training dataset
2025-10-09 02:34:11,944:INFO:Defining folds
2025-10-09 02:34:11,944:INFO:Declaring metric variables
2025-10-09 02:34:11,947:INFO:Importing untrained model
2025-10-09 02:34:11,950:INFO:Linear Discriminant Analysis Imported successfully
2025-10-09 02:34:11,957:INFO:Starting cross validation
2025-10-09 02:34:11,959:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:34:12,107:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:12,124:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:12,125:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:12,136:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:12,167:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:12,220:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:12,226:INFO:Calculating mean and std
2025-10-09 02:34:12,226:INFO:Creating metrics dataframe
2025-10-09 02:34:12,229:INFO:Uploading results into container
2025-10-09 02:34:12,229:INFO:Uploading model into container now
2025-10-09 02:34:12,229:INFO:_master_model_container: 11
2025-10-09 02:34:12,230:INFO:_display_container: 2
2025-10-09 02:34:12,230:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-09 02:34:12,230:INFO:create_model() successfully completed......................................
2025-10-09 02:34:12,308:INFO:SubProcess create_model() end ==================================
2025-10-09 02:34:12,308:INFO:Creating metrics dataframe
2025-10-09 02:34:12,317:INFO:Initializing Extra Trees Classifier
2025-10-09 02:34:12,317:INFO:Total runtime is 0.10174988110860188 minutes
2025-10-09 02:34:12,320:INFO:SubProcess create_model() called ==================================
2025-10-09 02:34:12,320:INFO:Initializing create_model()
2025-10-09 02:34:12,320:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A0ADFF950>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025A0B6BBA90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:34:12,320:INFO:Checking exceptions
2025-10-09 02:34:12,320:INFO:Importing libraries
2025-10-09 02:34:12,321:INFO:Copying training dataset
2025-10-09 02:34:12,324:INFO:Defining folds
2025-10-09 02:34:12,325:INFO:Declaring metric variables
2025-10-09 02:34:12,328:INFO:Importing untrained model
2025-10-09 02:34:12,332:INFO:Extra Trees Classifier Imported successfully
2025-10-09 02:34:12,343:INFO:Starting cross validation
2025-10-09 02:34:12,346:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:34:12,799:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:12,807:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:12,851:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:13,113:INFO:Calculating mean and std
2025-10-09 02:34:13,114:INFO:Creating metrics dataframe
2025-10-09 02:34:13,116:INFO:Uploading results into container
2025-10-09 02:34:13,117:INFO:Uploading model into container now
2025-10-09 02:34:13,117:INFO:_master_model_container: 12
2025-10-09 02:34:13,117:INFO:_display_container: 2
2025-10-09 02:34:13,118:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-10-09 02:34:13,118:INFO:create_model() successfully completed......................................
2025-10-09 02:34:13,206:INFO:SubProcess create_model() end ==================================
2025-10-09 02:34:13,206:INFO:Creating metrics dataframe
2025-10-09 02:34:13,216:INFO:Initializing Light Gradient Boosting Machine
2025-10-09 02:34:13,216:INFO:Total runtime is 0.11673393249511718 minutes
2025-10-09 02:34:13,219:INFO:SubProcess create_model() called ==================================
2025-10-09 02:34:13,219:INFO:Initializing create_model()
2025-10-09 02:34:13,220:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A0ADFF950>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025A0B6BBA90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:34:13,220:INFO:Checking exceptions
2025-10-09 02:34:13,220:INFO:Importing libraries
2025-10-09 02:34:13,220:INFO:Copying training dataset
2025-10-09 02:34:13,224:INFO:Defining folds
2025-10-09 02:34:13,224:INFO:Declaring metric variables
2025-10-09 02:34:13,227:INFO:Importing untrained model
2025-10-09 02:34:13,230:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-09 02:34:13,240:INFO:Starting cross validation
2025-10-09 02:34:13,243:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:34:13,553:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:13,560:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:13,680:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:13,704:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:13,784:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:13,888:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:13,905:INFO:Calculating mean and std
2025-10-09 02:34:13,906:INFO:Creating metrics dataframe
2025-10-09 02:34:13,910:INFO:Uploading results into container
2025-10-09 02:34:13,911:INFO:Uploading model into container now
2025-10-09 02:34:13,911:INFO:_master_model_container: 13
2025-10-09 02:34:13,911:INFO:_display_container: 2
2025-10-09 02:34:13,913:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-09 02:34:13,913:INFO:create_model() successfully completed......................................
2025-10-09 02:34:14,035:INFO:SubProcess create_model() end ==================================
2025-10-09 02:34:14,035:INFO:Creating metrics dataframe
2025-10-09 02:34:14,044:INFO:Initializing Dummy Classifier
2025-10-09 02:34:14,044:INFO:Total runtime is 0.13053196668624878 minutes
2025-10-09 02:34:14,047:INFO:SubProcess create_model() called ==================================
2025-10-09 02:34:14,047:INFO:Initializing create_model()
2025-10-09 02:34:14,047:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A0ADFF950>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025A0B6BBA90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:34:14,047:INFO:Checking exceptions
2025-10-09 02:34:14,048:INFO:Importing libraries
2025-10-09 02:34:14,048:INFO:Copying training dataset
2025-10-09 02:34:14,052:INFO:Defining folds
2025-10-09 02:34:14,052:INFO:Declaring metric variables
2025-10-09 02:34:14,056:INFO:Importing untrained model
2025-10-09 02:34:14,060:INFO:Dummy Classifier Imported successfully
2025-10-09 02:34:14,069:INFO:Starting cross validation
2025-10-09 02:34:14,071:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:34:14,273:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:14,298:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:14,332:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:14,335:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:14,345:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:14,349:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:14,351:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:14,362:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:14,422:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:14,423:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:14,431:INFO:Calculating mean and std
2025-10-09 02:34:14,432:INFO:Creating metrics dataframe
2025-10-09 02:34:14,434:INFO:Uploading results into container
2025-10-09 02:34:14,434:INFO:Uploading model into container now
2025-10-09 02:34:14,434:INFO:_master_model_container: 14
2025-10-09 02:34:14,434:INFO:_display_container: 2
2025-10-09 02:34:14,435:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-10-09 02:34:14,435:INFO:create_model() successfully completed......................................
2025-10-09 02:34:14,519:INFO:SubProcess create_model() end ==================================
2025-10-09 02:34:14,519:INFO:Creating metrics dataframe
2025-10-09 02:34:14,532:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-10-09 02:34:14,541:INFO:Initializing create_model()
2025-10-09 02:34:14,541:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A0ADFF950>, estimator=DummyClassifier(constant=None, random_state=123, strategy='prior'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:34:14,541:INFO:Checking exceptions
2025-10-09 02:34:14,543:INFO:Importing libraries
2025-10-09 02:34:14,543:INFO:Copying training dataset
2025-10-09 02:34:14,548:INFO:Defining folds
2025-10-09 02:34:14,548:INFO:Declaring metric variables
2025-10-09 02:34:14,548:INFO:Importing untrained model
2025-10-09 02:34:14,548:INFO:Declaring custom model
2025-10-09 02:34:14,549:INFO:Dummy Classifier Imported successfully
2025-10-09 02:34:14,550:INFO:Cross validation set to False
2025-10-09 02:34:14,550:INFO:Fitting Model
2025-10-09 02:34:14,604:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-10-09 02:34:14,604:INFO:create_model() successfully completed......................................
2025-10-09 02:34:14,715:INFO:_master_model_container: 14
2025-10-09 02:34:14,715:INFO:_display_container: 2
2025-10-09 02:34:14,715:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-10-09 02:34:14,716:INFO:compare_models() successfully completed......................................
2025-10-09 02:34:32,675:INFO:Initializing compare_models()
2025-10-09 02:34:32,675:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A0ADFF950>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000025A0ADFF950>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-10-09 02:34:32,675:INFO:Checking exceptions
2025-10-09 02:34:32,678:INFO:Preparing display monitor
2025-10-09 02:34:32,703:INFO:Initializing Logistic Regression
2025-10-09 02:34:32,703:INFO:Total runtime is 0.0 minutes
2025-10-09 02:34:32,707:INFO:SubProcess create_model() called ==================================
2025-10-09 02:34:32,708:INFO:Initializing create_model()
2025-10-09 02:34:32,708:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A0ADFF950>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025A0AFB9FD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:34:32,708:INFO:Checking exceptions
2025-10-09 02:34:32,708:INFO:Importing libraries
2025-10-09 02:34:32,708:INFO:Copying training dataset
2025-10-09 02:34:32,713:INFO:Defining folds
2025-10-09 02:34:32,713:INFO:Declaring metric variables
2025-10-09 02:34:32,716:INFO:Importing untrained model
2025-10-09 02:34:32,720:INFO:Logistic Regression Imported successfully
2025-10-09 02:34:32,727:INFO:Starting cross validation
2025-10-09 02:34:32,729:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:34:32,911:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:32,933:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:32,964:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:32,982:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:32,983:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:33,003:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:33,007:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:33,095:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:33,103:INFO:Calculating mean and std
2025-10-09 02:34:33,103:INFO:Creating metrics dataframe
2025-10-09 02:34:33,105:INFO:Uploading results into container
2025-10-09 02:34:33,106:INFO:Uploading model into container now
2025-10-09 02:34:33,106:INFO:_master_model_container: 15
2025-10-09 02:34:33,106:INFO:_display_container: 3
2025-10-09 02:34:33,106:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-09 02:34:33,107:INFO:create_model() successfully completed......................................
2025-10-09 02:34:33,199:INFO:SubProcess create_model() end ==================================
2025-10-09 02:34:33,199:INFO:Creating metrics dataframe
2025-10-09 02:34:33,205:INFO:Initializing K Neighbors Classifier
2025-10-09 02:34:33,206:INFO:Total runtime is 0.00838329792022705 minutes
2025-10-09 02:34:33,209:INFO:SubProcess create_model() called ==================================
2025-10-09 02:34:33,209:INFO:Initializing create_model()
2025-10-09 02:34:33,209:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A0ADFF950>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025A0AFB9FD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:34:33,209:INFO:Checking exceptions
2025-10-09 02:34:33,209:INFO:Importing libraries
2025-10-09 02:34:33,210:INFO:Copying training dataset
2025-10-09 02:34:33,214:INFO:Defining folds
2025-10-09 02:34:33,214:INFO:Declaring metric variables
2025-10-09 02:34:33,218:INFO:Importing untrained model
2025-10-09 02:34:33,222:INFO:K Neighbors Classifier Imported successfully
2025-10-09 02:34:33,230:INFO:Starting cross validation
2025-10-09 02:34:33,233:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:34:33,510:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:33,510:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:33,517:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:33,576:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:33,583:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:33,725:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:33,733:INFO:Calculating mean and std
2025-10-09 02:34:33,734:INFO:Creating metrics dataframe
2025-10-09 02:34:33,736:INFO:Uploading results into container
2025-10-09 02:34:33,737:INFO:Uploading model into container now
2025-10-09 02:34:33,738:INFO:_master_model_container: 16
2025-10-09 02:34:33,738:INFO:_display_container: 3
2025-10-09 02:34:33,738:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-10-09 02:34:33,738:INFO:create_model() successfully completed......................................
2025-10-09 02:34:33,829:INFO:SubProcess create_model() end ==================================
2025-10-09 02:34:33,829:INFO:Creating metrics dataframe
2025-10-09 02:34:33,836:INFO:Initializing Naive Bayes
2025-10-09 02:34:33,836:INFO:Total runtime is 0.018879107634226483 minutes
2025-10-09 02:34:33,840:INFO:SubProcess create_model() called ==================================
2025-10-09 02:34:33,840:INFO:Initializing create_model()
2025-10-09 02:34:33,840:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A0ADFF950>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025A0AFB9FD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:34:33,840:INFO:Checking exceptions
2025-10-09 02:34:33,840:INFO:Importing libraries
2025-10-09 02:34:33,840:INFO:Copying training dataset
2025-10-09 02:34:33,845:INFO:Defining folds
2025-10-09 02:34:33,845:INFO:Declaring metric variables
2025-10-09 02:34:33,848:INFO:Importing untrained model
2025-10-09 02:34:33,853:INFO:Naive Bayes Imported successfully
2025-10-09 02:34:33,874:INFO:Starting cross validation
2025-10-09 02:34:33,876:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:34:34,146:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:34,160:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:34,182:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:34,248:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:34,254:INFO:Calculating mean and std
2025-10-09 02:34:34,255:INFO:Creating metrics dataframe
2025-10-09 02:34:34,257:INFO:Uploading results into container
2025-10-09 02:34:34,257:INFO:Uploading model into container now
2025-10-09 02:34:34,258:INFO:_master_model_container: 17
2025-10-09 02:34:34,258:INFO:_display_container: 3
2025-10-09 02:34:34,258:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-10-09 02:34:34,258:INFO:create_model() successfully completed......................................
2025-10-09 02:34:34,338:INFO:SubProcess create_model() end ==================================
2025-10-09 02:34:34,338:INFO:Creating metrics dataframe
2025-10-09 02:34:34,344:INFO:Initializing Decision Tree Classifier
2025-10-09 02:34:34,344:INFO:Total runtime is 0.02734963893890381 minutes
2025-10-09 02:34:34,347:INFO:SubProcess create_model() called ==================================
2025-10-09 02:34:34,348:INFO:Initializing create_model()
2025-10-09 02:34:34,348:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A0ADFF950>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025A0AFB9FD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:34:34,348:INFO:Checking exceptions
2025-10-09 02:34:34,348:INFO:Importing libraries
2025-10-09 02:34:34,348:INFO:Copying training dataset
2025-10-09 02:34:34,352:INFO:Defining folds
2025-10-09 02:34:34,352:INFO:Declaring metric variables
2025-10-09 02:34:34,355:INFO:Importing untrained model
2025-10-09 02:34:34,359:INFO:Decision Tree Classifier Imported successfully
2025-10-09 02:34:34,367:INFO:Starting cross validation
2025-10-09 02:34:34,369:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:34:34,531:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:34,651:INFO:Calculating mean and std
2025-10-09 02:34:34,651:INFO:Creating metrics dataframe
2025-10-09 02:34:34,653:INFO:Uploading results into container
2025-10-09 02:34:34,654:INFO:Uploading model into container now
2025-10-09 02:34:34,655:INFO:_master_model_container: 18
2025-10-09 02:34:34,655:INFO:_display_container: 3
2025-10-09 02:34:34,655:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-10-09 02:34:34,655:INFO:create_model() successfully completed......................................
2025-10-09 02:34:34,738:INFO:SubProcess create_model() end ==================================
2025-10-09 02:34:34,738:INFO:Creating metrics dataframe
2025-10-09 02:34:34,745:INFO:Initializing SVM - Linear Kernel
2025-10-09 02:34:34,746:INFO:Total runtime is 0.034043689568837486 minutes
2025-10-09 02:34:34,750:INFO:SubProcess create_model() called ==================================
2025-10-09 02:34:34,750:INFO:Initializing create_model()
2025-10-09 02:34:34,750:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A0ADFF950>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025A0AFB9FD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:34:34,750:INFO:Checking exceptions
2025-10-09 02:34:34,750:INFO:Importing libraries
2025-10-09 02:34:34,750:INFO:Copying training dataset
2025-10-09 02:34:34,755:INFO:Defining folds
2025-10-09 02:34:34,755:INFO:Declaring metric variables
2025-10-09 02:34:34,758:INFO:Importing untrained model
2025-10-09 02:34:34,763:INFO:SVM - Linear Kernel Imported successfully
2025-10-09 02:34:34,773:INFO:Starting cross validation
2025-10-09 02:34:34,776:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:34:34,952:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:35,002:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:35,062:INFO:Calculating mean and std
2025-10-09 02:34:35,062:INFO:Creating metrics dataframe
2025-10-09 02:34:35,065:INFO:Uploading results into container
2025-10-09 02:34:35,066:INFO:Uploading model into container now
2025-10-09 02:34:35,066:INFO:_master_model_container: 19
2025-10-09 02:34:35,067:INFO:_display_container: 3
2025-10-09 02:34:35,067:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-10-09 02:34:35,067:INFO:create_model() successfully completed......................................
2025-10-09 02:34:35,153:INFO:SubProcess create_model() end ==================================
2025-10-09 02:34:35,154:INFO:Creating metrics dataframe
2025-10-09 02:34:35,161:INFO:Initializing Ridge Classifier
2025-10-09 02:34:35,161:INFO:Total runtime is 0.04096217552820842 minutes
2025-10-09 02:34:35,164:INFO:SubProcess create_model() called ==================================
2025-10-09 02:34:35,165:INFO:Initializing create_model()
2025-10-09 02:34:35,165:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A0ADFF950>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025A0AFB9FD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:34:35,165:INFO:Checking exceptions
2025-10-09 02:34:35,165:INFO:Importing libraries
2025-10-09 02:34:35,165:INFO:Copying training dataset
2025-10-09 02:34:35,170:INFO:Defining folds
2025-10-09 02:34:35,170:INFO:Declaring metric variables
2025-10-09 02:34:35,174:INFO:Importing untrained model
2025-10-09 02:34:35,178:INFO:Ridge Classifier Imported successfully
2025-10-09 02:34:35,188:INFO:Starting cross validation
2025-10-09 02:34:35,190:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:34:35,344:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:35,350:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:35,366:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:35,366:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:35,374:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:35,374:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:35,387:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:35,456:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:35,458:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:35,474:INFO:Calculating mean and std
2025-10-09 02:34:35,474:INFO:Creating metrics dataframe
2025-10-09 02:34:35,477:INFO:Uploading results into container
2025-10-09 02:34:35,477:INFO:Uploading model into container now
2025-10-09 02:34:35,477:INFO:_master_model_container: 20
2025-10-09 02:34:35,478:INFO:_display_container: 3
2025-10-09 02:34:35,478:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-10-09 02:34:35,478:INFO:create_model() successfully completed......................................
2025-10-09 02:34:35,560:INFO:SubProcess create_model() end ==================================
2025-10-09 02:34:35,560:INFO:Creating metrics dataframe
2025-10-09 02:34:35,567:INFO:Initializing Random Forest Classifier
2025-10-09 02:34:35,567:INFO:Total runtime is 0.04773117303848267 minutes
2025-10-09 02:34:35,570:INFO:SubProcess create_model() called ==================================
2025-10-09 02:34:35,570:INFO:Initializing create_model()
2025-10-09 02:34:35,570:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A0ADFF950>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025A0AFB9FD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:34:35,570:INFO:Checking exceptions
2025-10-09 02:34:35,570:INFO:Importing libraries
2025-10-09 02:34:35,571:INFO:Copying training dataset
2025-10-09 02:34:35,574:INFO:Defining folds
2025-10-09 02:34:35,574:INFO:Declaring metric variables
2025-10-09 02:34:35,577:INFO:Importing untrained model
2025-10-09 02:34:35,581:INFO:Random Forest Classifier Imported successfully
2025-10-09 02:34:35,589:INFO:Starting cross validation
2025-10-09 02:34:35,591:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:34:36,072:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:36,089:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:36,124:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:36,127:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:36,139:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:36,210:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:36,236:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:36,410:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:36,424:INFO:Calculating mean and std
2025-10-09 02:34:36,424:INFO:Creating metrics dataframe
2025-10-09 02:34:36,427:INFO:Uploading results into container
2025-10-09 02:34:36,428:INFO:Uploading model into container now
2025-10-09 02:34:36,428:INFO:_master_model_container: 21
2025-10-09 02:34:36,428:INFO:_display_container: 3
2025-10-09 02:34:36,429:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-10-09 02:34:36,429:INFO:create_model() successfully completed......................................
2025-10-09 02:34:36,510:INFO:SubProcess create_model() end ==================================
2025-10-09 02:34:36,511:INFO:Creating metrics dataframe
2025-10-09 02:34:36,519:INFO:Initializing Quadratic Discriminant Analysis
2025-10-09 02:34:36,519:INFO:Total runtime is 0.06359207232793172 minutes
2025-10-09 02:34:36,523:INFO:SubProcess create_model() called ==================================
2025-10-09 02:34:36,523:INFO:Initializing create_model()
2025-10-09 02:34:36,524:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A0ADFF950>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025A0AFB9FD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:34:36,524:INFO:Checking exceptions
2025-10-09 02:34:36,524:INFO:Importing libraries
2025-10-09 02:34:36,524:INFO:Copying training dataset
2025-10-09 02:34:36,528:INFO:Defining folds
2025-10-09 02:34:36,528:INFO:Declaring metric variables
2025-10-09 02:34:36,531:INFO:Importing untrained model
2025-10-09 02:34:36,535:INFO:Quadratic Discriminant Analysis Imported successfully
2025-10-09 02:34:36,543:INFO:Starting cross validation
2025-10-09 02:34:36,545:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:34:36,644:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 02:34:36,645:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 02:34:36,646:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 02:34:36,649:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 02:34:36,649:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 02:34:36,660:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 02:34:36,675:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 02:34:36,703:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:36,714:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 02:34:36,785:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 02:34:36,787:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 02:34:36,824:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:36,839:INFO:Calculating mean and std
2025-10-09 02:34:36,839:INFO:Creating metrics dataframe
2025-10-09 02:34:36,842:INFO:Uploading results into container
2025-10-09 02:34:36,843:INFO:Uploading model into container now
2025-10-09 02:34:36,844:INFO:_master_model_container: 22
2025-10-09 02:34:36,844:INFO:_display_container: 3
2025-10-09 02:34:36,844:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-10-09 02:34:36,844:INFO:create_model() successfully completed......................................
2025-10-09 02:34:36,922:INFO:SubProcess create_model() end ==================================
2025-10-09 02:34:36,923:INFO:Creating metrics dataframe
2025-10-09 02:34:36,931:INFO:Initializing Ada Boost Classifier
2025-10-09 02:34:36,931:INFO:Total runtime is 0.07046141227086385 minutes
2025-10-09 02:34:36,936:INFO:SubProcess create_model() called ==================================
2025-10-09 02:34:36,936:INFO:Initializing create_model()
2025-10-09 02:34:36,936:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A0ADFF950>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025A0AFB9FD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:34:36,936:INFO:Checking exceptions
2025-10-09 02:34:36,937:INFO:Importing libraries
2025-10-09 02:34:36,937:INFO:Copying training dataset
2025-10-09 02:34:36,941:INFO:Defining folds
2025-10-09 02:34:36,941:INFO:Declaring metric variables
2025-10-09 02:34:36,944:INFO:Importing untrained model
2025-10-09 02:34:36,946:INFO:Ada Boost Classifier Imported successfully
2025-10-09 02:34:36,955:INFO:Starting cross validation
2025-10-09 02:34:36,957:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:34:37,053:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 02:34:37,056:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 02:34:37,061:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 02:34:37,064:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 02:34:37,064:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 02:34:37,068:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 02:34:37,093:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 02:34:37,094:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 02:34:37,298:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:37,343:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:37,361:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 02:34:37,377:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 02:34:37,500:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:37,514:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:37,522:INFO:Calculating mean and std
2025-10-09 02:34:37,523:INFO:Creating metrics dataframe
2025-10-09 02:34:37,526:INFO:Uploading results into container
2025-10-09 02:34:37,526:INFO:Uploading model into container now
2025-10-09 02:34:37,527:INFO:_master_model_container: 23
2025-10-09 02:34:37,527:INFO:_display_container: 3
2025-10-09 02:34:37,527:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-10-09 02:34:37,527:INFO:create_model() successfully completed......................................
2025-10-09 02:34:37,605:INFO:SubProcess create_model() end ==================================
2025-10-09 02:34:37,605:INFO:Creating metrics dataframe
2025-10-09 02:34:37,613:INFO:Initializing Gradient Boosting Classifier
2025-10-09 02:34:37,613:INFO:Total runtime is 0.08182722330093384 minutes
2025-10-09 02:34:37,616:INFO:SubProcess create_model() called ==================================
2025-10-09 02:34:37,617:INFO:Initializing create_model()
2025-10-09 02:34:37,617:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A0ADFF950>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025A0AFB9FD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:34:37,617:INFO:Checking exceptions
2025-10-09 02:34:37,617:INFO:Importing libraries
2025-10-09 02:34:37,617:INFO:Copying training dataset
2025-10-09 02:34:37,621:INFO:Defining folds
2025-10-09 02:34:37,621:INFO:Declaring metric variables
2025-10-09 02:34:37,623:INFO:Importing untrained model
2025-10-09 02:34:37,626:INFO:Gradient Boosting Classifier Imported successfully
2025-10-09 02:34:37,636:INFO:Starting cross validation
2025-10-09 02:34:37,638:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:34:38,034:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:38,243:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:38,258:INFO:Calculating mean and std
2025-10-09 02:34:38,258:INFO:Creating metrics dataframe
2025-10-09 02:34:38,261:INFO:Uploading results into container
2025-10-09 02:34:38,261:INFO:Uploading model into container now
2025-10-09 02:34:38,262:INFO:_master_model_container: 24
2025-10-09 02:34:38,262:INFO:_display_container: 3
2025-10-09 02:34:38,262:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-09 02:34:38,262:INFO:create_model() successfully completed......................................
2025-10-09 02:34:38,339:INFO:SubProcess create_model() end ==================================
2025-10-09 02:34:38,340:INFO:Creating metrics dataframe
2025-10-09 02:34:38,348:INFO:Initializing Linear Discriminant Analysis
2025-10-09 02:34:38,348:INFO:Total runtime is 0.09406818548838297 minutes
2025-10-09 02:34:38,351:INFO:SubProcess create_model() called ==================================
2025-10-09 02:34:38,351:INFO:Initializing create_model()
2025-10-09 02:34:38,351:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A0ADFF950>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025A0AFB9FD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:34:38,351:INFO:Checking exceptions
2025-10-09 02:34:38,351:INFO:Importing libraries
2025-10-09 02:34:38,351:INFO:Copying training dataset
2025-10-09 02:34:38,354:INFO:Defining folds
2025-10-09 02:34:38,354:INFO:Declaring metric variables
2025-10-09 02:34:38,357:INFO:Importing untrained model
2025-10-09 02:34:38,360:INFO:Linear Discriminant Analysis Imported successfully
2025-10-09 02:34:38,368:INFO:Starting cross validation
2025-10-09 02:34:38,369:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:34:38,525:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:38,541:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:38,545:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:38,551:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:38,554:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:38,646:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:38,656:INFO:Calculating mean and std
2025-10-09 02:34:38,656:INFO:Creating metrics dataframe
2025-10-09 02:34:38,658:INFO:Uploading results into container
2025-10-09 02:34:38,659:INFO:Uploading model into container now
2025-10-09 02:34:38,659:INFO:_master_model_container: 25
2025-10-09 02:34:38,659:INFO:_display_container: 3
2025-10-09 02:34:38,660:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-09 02:34:38,660:INFO:create_model() successfully completed......................................
2025-10-09 02:34:38,738:INFO:SubProcess create_model() end ==================================
2025-10-09 02:34:38,739:INFO:Creating metrics dataframe
2025-10-09 02:34:38,747:INFO:Initializing Extra Trees Classifier
2025-10-09 02:34:38,747:INFO:Total runtime is 0.10072973171869913 minutes
2025-10-09 02:34:38,750:INFO:SubProcess create_model() called ==================================
2025-10-09 02:34:38,750:INFO:Initializing create_model()
2025-10-09 02:34:38,750:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A0ADFF950>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025A0AFB9FD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:34:38,750:INFO:Checking exceptions
2025-10-09 02:34:38,750:INFO:Importing libraries
2025-10-09 02:34:38,750:INFO:Copying training dataset
2025-10-09 02:34:38,755:INFO:Defining folds
2025-10-09 02:34:38,755:INFO:Declaring metric variables
2025-10-09 02:34:38,758:INFO:Importing untrained model
2025-10-09 02:34:38,761:INFO:Extra Trees Classifier Imported successfully
2025-10-09 02:34:38,782:INFO:Starting cross validation
2025-10-09 02:34:38,784:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:34:39,284:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:39,356:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:39,548:INFO:Calculating mean and std
2025-10-09 02:34:39,548:INFO:Creating metrics dataframe
2025-10-09 02:34:39,551:INFO:Uploading results into container
2025-10-09 02:34:39,551:INFO:Uploading model into container now
2025-10-09 02:34:39,552:INFO:_master_model_container: 26
2025-10-09 02:34:39,552:INFO:_display_container: 3
2025-10-09 02:34:39,553:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-10-09 02:34:39,553:INFO:create_model() successfully completed......................................
2025-10-09 02:34:39,631:INFO:SubProcess create_model() end ==================================
2025-10-09 02:34:39,631:INFO:Creating metrics dataframe
2025-10-09 02:34:39,639:INFO:Initializing Light Gradient Boosting Machine
2025-10-09 02:34:39,639:INFO:Total runtime is 0.11558553377787271 minutes
2025-10-09 02:34:39,643:INFO:SubProcess create_model() called ==================================
2025-10-09 02:34:39,643:INFO:Initializing create_model()
2025-10-09 02:34:39,644:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A0ADFF950>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025A0AFB9FD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:34:39,644:INFO:Checking exceptions
2025-10-09 02:34:39,644:INFO:Importing libraries
2025-10-09 02:34:39,644:INFO:Copying training dataset
2025-10-09 02:34:39,647:INFO:Defining folds
2025-10-09 02:34:39,647:INFO:Declaring metric variables
2025-10-09 02:34:39,650:INFO:Importing untrained model
2025-10-09 02:34:39,653:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-09 02:34:39,661:INFO:Starting cross validation
2025-10-09 02:34:39,662:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:34:39,888:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:39,900:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:39,923:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:40,062:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:40,078:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:40,178:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:40,204:INFO:Calculating mean and std
2025-10-09 02:34:40,205:INFO:Creating metrics dataframe
2025-10-09 02:34:40,208:INFO:Uploading results into container
2025-10-09 02:34:40,209:INFO:Uploading model into container now
2025-10-09 02:34:40,210:INFO:_master_model_container: 27
2025-10-09 02:34:40,210:INFO:_display_container: 3
2025-10-09 02:34:40,211:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-09 02:34:40,212:INFO:create_model() successfully completed......................................
2025-10-09 02:34:40,323:INFO:SubProcess create_model() end ==================================
2025-10-09 02:34:40,324:INFO:Creating metrics dataframe
2025-10-09 02:34:40,333:INFO:Initializing Dummy Classifier
2025-10-09 02:34:40,333:INFO:Total runtime is 0.12716031471888223 minutes
2025-10-09 02:34:40,338:INFO:SubProcess create_model() called ==================================
2025-10-09 02:34:40,338:INFO:Initializing create_model()
2025-10-09 02:34:40,339:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A0ADFF950>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025A0AFB9FD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:34:40,339:INFO:Checking exceptions
2025-10-09 02:34:40,339:INFO:Importing libraries
2025-10-09 02:34:40,339:INFO:Copying training dataset
2025-10-09 02:34:40,343:INFO:Defining folds
2025-10-09 02:34:40,343:INFO:Declaring metric variables
2025-10-09 02:34:40,347:INFO:Importing untrained model
2025-10-09 02:34:40,351:INFO:Dummy Classifier Imported successfully
2025-10-09 02:34:40,375:INFO:Starting cross validation
2025-10-09 02:34:40,378:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:34:40,546:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:40,550:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:40,551:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:40,555:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:40,569:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:40,578:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:40,597:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:40,610:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:40,663:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:40,671:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:40,687:INFO:Calculating mean and std
2025-10-09 02:34:40,687:INFO:Creating metrics dataframe
2025-10-09 02:34:40,690:INFO:Uploading results into container
2025-10-09 02:34:40,690:INFO:Uploading model into container now
2025-10-09 02:34:40,691:INFO:_master_model_container: 28
2025-10-09 02:34:40,691:INFO:_display_container: 3
2025-10-09 02:34:40,691:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-10-09 02:34:40,691:INFO:create_model() successfully completed......................................
2025-10-09 02:34:40,772:INFO:SubProcess create_model() end ==================================
2025-10-09 02:34:40,772:INFO:Creating metrics dataframe
2025-10-09 02:34:40,782:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-10-09 02:34:40,789:INFO:Initializing create_model()
2025-10-09 02:34:40,789:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A0ADFF950>, estimator=DummyClassifier(constant=None, random_state=123, strategy='prior'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:34:40,789:INFO:Checking exceptions
2025-10-09 02:34:40,790:INFO:Importing libraries
2025-10-09 02:34:40,790:INFO:Copying training dataset
2025-10-09 02:34:40,794:INFO:Defining folds
2025-10-09 02:34:40,794:INFO:Declaring metric variables
2025-10-09 02:34:40,794:INFO:Importing untrained model
2025-10-09 02:34:40,794:INFO:Declaring custom model
2025-10-09 02:34:40,794:INFO:Dummy Classifier Imported successfully
2025-10-09 02:34:40,795:INFO:Cross validation set to False
2025-10-09 02:34:40,795:INFO:Fitting Model
2025-10-09 02:34:40,842:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-10-09 02:34:40,842:INFO:create_model() successfully completed......................................
2025-10-09 02:34:40,945:INFO:_master_model_container: 28
2025-10-09 02:34:40,946:INFO:_display_container: 3
2025-10-09 02:34:40,946:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-10-09 02:34:40,946:INFO:compare_models() successfully completed......................................
2025-10-09 02:34:42,677:INFO:Initializing compare_models()
2025-10-09 02:34:42,677:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A0ADFF950>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000025A0ADFF950>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-10-09 02:34:42,677:INFO:Checking exceptions
2025-10-09 02:34:42,679:INFO:Preparing display monitor
2025-10-09 02:34:42,703:INFO:Initializing Logistic Regression
2025-10-09 02:34:42,703:INFO:Total runtime is 0.0 minutes
2025-10-09 02:34:42,707:INFO:SubProcess create_model() called ==================================
2025-10-09 02:34:42,708:INFO:Initializing create_model()
2025-10-09 02:34:42,708:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A0ADFF950>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025A0B2A8BD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:34:42,708:INFO:Checking exceptions
2025-10-09 02:34:42,708:INFO:Importing libraries
2025-10-09 02:34:42,708:INFO:Copying training dataset
2025-10-09 02:34:42,713:INFO:Defining folds
2025-10-09 02:34:42,713:INFO:Declaring metric variables
2025-10-09 02:34:42,719:INFO:Importing untrained model
2025-10-09 02:34:42,724:INFO:Logistic Regression Imported successfully
2025-10-09 02:34:42,735:INFO:Starting cross validation
2025-10-09 02:34:42,737:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:34:42,986:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:42,998:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:43,018:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:43,024:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:43,045:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:43,059:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:43,063:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:43,112:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:43,122:INFO:Calculating mean and std
2025-10-09 02:34:43,122:INFO:Creating metrics dataframe
2025-10-09 02:34:43,124:INFO:Uploading results into container
2025-10-09 02:34:43,124:INFO:Uploading model into container now
2025-10-09 02:34:43,125:INFO:_master_model_container: 29
2025-10-09 02:34:43,125:INFO:_display_container: 4
2025-10-09 02:34:43,125:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-09 02:34:43,125:INFO:create_model() successfully completed......................................
2025-10-09 02:34:43,199:INFO:SubProcess create_model() end ==================================
2025-10-09 02:34:43,199:INFO:Creating metrics dataframe
2025-10-09 02:34:43,204:INFO:Initializing K Neighbors Classifier
2025-10-09 02:34:43,205:INFO:Total runtime is 0.00837011734644572 minutes
2025-10-09 02:34:43,207:INFO:SubProcess create_model() called ==================================
2025-10-09 02:34:43,208:INFO:Initializing create_model()
2025-10-09 02:34:43,208:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A0ADFF950>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025A0B2A8BD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:34:43,208:INFO:Checking exceptions
2025-10-09 02:34:43,208:INFO:Importing libraries
2025-10-09 02:34:43,208:INFO:Copying training dataset
2025-10-09 02:34:43,212:INFO:Defining folds
2025-10-09 02:34:43,212:INFO:Declaring metric variables
2025-10-09 02:34:43,214:INFO:Importing untrained model
2025-10-09 02:34:43,218:INFO:K Neighbors Classifier Imported successfully
2025-10-09 02:34:43,226:INFO:Starting cross validation
2025-10-09 02:34:43,229:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:34:43,478:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:43,478:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:43,484:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:43,521:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:43,541:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:43,618:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:43,626:INFO:Calculating mean and std
2025-10-09 02:34:43,627:INFO:Creating metrics dataframe
2025-10-09 02:34:43,628:INFO:Uploading results into container
2025-10-09 02:34:43,629:INFO:Uploading model into container now
2025-10-09 02:34:43,629:INFO:_master_model_container: 30
2025-10-09 02:34:43,629:INFO:_display_container: 4
2025-10-09 02:34:43,629:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-10-09 02:34:43,629:INFO:create_model() successfully completed......................................
2025-10-09 02:34:43,709:INFO:SubProcess create_model() end ==================================
2025-10-09 02:34:43,709:INFO:Creating metrics dataframe
2025-10-09 02:34:43,715:INFO:Initializing Naive Bayes
2025-10-09 02:34:43,715:INFO:Total runtime is 0.01687204440434774 minutes
2025-10-09 02:34:43,719:INFO:SubProcess create_model() called ==================================
2025-10-09 02:34:43,719:INFO:Initializing create_model()
2025-10-09 02:34:43,719:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A0ADFF950>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025A0B2A8BD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:34:43,719:INFO:Checking exceptions
2025-10-09 02:34:43,719:INFO:Importing libraries
2025-10-09 02:34:43,719:INFO:Copying training dataset
2025-10-09 02:34:43,723:INFO:Defining folds
2025-10-09 02:34:43,724:INFO:Declaring metric variables
2025-10-09 02:34:43,729:INFO:Importing untrained model
2025-10-09 02:34:43,733:INFO:Naive Bayes Imported successfully
2025-10-09 02:34:43,741:INFO:Starting cross validation
2025-10-09 02:34:43,743:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:34:43,940:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:43,964:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:43,985:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:44,066:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:44,078:INFO:Calculating mean and std
2025-10-09 02:34:44,080:INFO:Creating metrics dataframe
2025-10-09 02:34:44,083:INFO:Uploading results into container
2025-10-09 02:34:44,084:INFO:Uploading model into container now
2025-10-09 02:34:44,084:INFO:_master_model_container: 31
2025-10-09 02:34:44,084:INFO:_display_container: 4
2025-10-09 02:34:44,084:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-10-09 02:34:44,085:INFO:create_model() successfully completed......................................
2025-10-09 02:34:44,205:INFO:SubProcess create_model() end ==================================
2025-10-09 02:34:44,205:INFO:Creating metrics dataframe
2025-10-09 02:34:44,216:INFO:Initializing Decision Tree Classifier
2025-10-09 02:34:44,216:INFO:Total runtime is 0.025208282470703128 minutes
2025-10-09 02:34:44,221:INFO:SubProcess create_model() called ==================================
2025-10-09 02:34:44,221:INFO:Initializing create_model()
2025-10-09 02:34:44,221:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A0ADFF950>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025A0B2A8BD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:34:44,222:INFO:Checking exceptions
2025-10-09 02:34:44,222:INFO:Importing libraries
2025-10-09 02:34:44,222:INFO:Copying training dataset
2025-10-09 02:34:44,228:INFO:Defining folds
2025-10-09 02:34:44,229:INFO:Declaring metric variables
2025-10-09 02:34:44,234:INFO:Importing untrained model
2025-10-09 02:34:44,240:INFO:Decision Tree Classifier Imported successfully
2025-10-09 02:34:44,255:INFO:Starting cross validation
2025-10-09 02:34:44,257:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:34:44,489:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:44,641:INFO:Calculating mean and std
2025-10-09 02:34:44,643:INFO:Creating metrics dataframe
2025-10-09 02:34:44,645:INFO:Uploading results into container
2025-10-09 02:34:44,646:INFO:Uploading model into container now
2025-10-09 02:34:44,647:INFO:_master_model_container: 32
2025-10-09 02:34:44,647:INFO:_display_container: 4
2025-10-09 02:34:44,647:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-10-09 02:34:44,648:INFO:create_model() successfully completed......................................
2025-10-09 02:34:44,736:INFO:SubProcess create_model() end ==================================
2025-10-09 02:34:44,737:INFO:Creating metrics dataframe
2025-10-09 02:34:44,745:INFO:Initializing SVM - Linear Kernel
2025-10-09 02:34:44,745:INFO:Total runtime is 0.034036854902903244 minutes
2025-10-09 02:34:44,749:INFO:SubProcess create_model() called ==================================
2025-10-09 02:34:44,749:INFO:Initializing create_model()
2025-10-09 02:34:44,749:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A0ADFF950>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025A0B2A8BD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:34:44,749:INFO:Checking exceptions
2025-10-09 02:34:44,749:INFO:Importing libraries
2025-10-09 02:34:44,749:INFO:Copying training dataset
2025-10-09 02:34:44,754:INFO:Defining folds
2025-10-09 02:34:44,755:INFO:Declaring metric variables
2025-10-09 02:34:44,758:INFO:Importing untrained model
2025-10-09 02:34:44,762:INFO:SVM - Linear Kernel Imported successfully
2025-10-09 02:34:44,772:INFO:Starting cross validation
2025-10-09 02:34:44,776:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:34:44,977:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:45,027:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:45,121:INFO:Calculating mean and std
2025-10-09 02:34:45,122:INFO:Creating metrics dataframe
2025-10-09 02:34:45,124:INFO:Uploading results into container
2025-10-09 02:34:45,125:INFO:Uploading model into container now
2025-10-09 02:34:45,125:INFO:_master_model_container: 33
2025-10-09 02:34:45,125:INFO:_display_container: 4
2025-10-09 02:34:45,126:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-10-09 02:34:45,126:INFO:create_model() successfully completed......................................
2025-10-09 02:34:45,205:INFO:SubProcess create_model() end ==================================
2025-10-09 02:34:45,205:INFO:Creating metrics dataframe
2025-10-09 02:34:45,212:INFO:Initializing Ridge Classifier
2025-10-09 02:34:45,213:INFO:Total runtime is 0.04183969100316366 minutes
2025-10-09 02:34:45,216:INFO:SubProcess create_model() called ==================================
2025-10-09 02:34:45,216:INFO:Initializing create_model()
2025-10-09 02:34:45,216:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A0ADFF950>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025A0B2A8BD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:34:45,216:INFO:Checking exceptions
2025-10-09 02:34:45,217:INFO:Importing libraries
2025-10-09 02:34:45,217:INFO:Copying training dataset
2025-10-09 02:34:45,220:INFO:Defining folds
2025-10-09 02:34:45,220:INFO:Declaring metric variables
2025-10-09 02:34:45,223:INFO:Importing untrained model
2025-10-09 02:34:45,227:INFO:Ridge Classifier Imported successfully
2025-10-09 02:34:45,236:INFO:Starting cross validation
2025-10-09 02:34:45,238:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:34:45,411:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:45,418:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:45,431:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:45,433:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:45,446:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:45,459:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:45,470:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:45,548:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:45,550:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:45,561:INFO:Calculating mean and std
2025-10-09 02:34:45,561:INFO:Creating metrics dataframe
2025-10-09 02:34:45,564:INFO:Uploading results into container
2025-10-09 02:34:45,564:INFO:Uploading model into container now
2025-10-09 02:34:45,565:INFO:_master_model_container: 34
2025-10-09 02:34:45,565:INFO:_display_container: 4
2025-10-09 02:34:45,566:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-10-09 02:34:45,566:INFO:create_model() successfully completed......................................
2025-10-09 02:34:45,648:INFO:SubProcess create_model() end ==================================
2025-10-09 02:34:45,648:INFO:Creating metrics dataframe
2025-10-09 02:34:45,656:INFO:Initializing Random Forest Classifier
2025-10-09 02:34:45,657:INFO:Total runtime is 0.04923295974731446 minutes
2025-10-09 02:34:45,659:INFO:SubProcess create_model() called ==================================
2025-10-09 02:34:45,660:INFO:Initializing create_model()
2025-10-09 02:34:45,660:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A0ADFF950>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025A0B2A8BD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:34:45,660:INFO:Checking exceptions
2025-10-09 02:34:45,660:INFO:Importing libraries
2025-10-09 02:34:45,660:INFO:Copying training dataset
2025-10-09 02:34:45,664:INFO:Defining folds
2025-10-09 02:34:45,664:INFO:Declaring metric variables
2025-10-09 02:34:45,666:INFO:Importing untrained model
2025-10-09 02:34:45,670:INFO:Random Forest Classifier Imported successfully
2025-10-09 02:34:45,683:INFO:Starting cross validation
2025-10-09 02:34:45,686:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:34:46,179:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:46,201:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:46,203:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:46,243:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:46,290:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:46,319:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:46,357:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:46,501:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:46,525:INFO:Calculating mean and std
2025-10-09 02:34:46,525:INFO:Creating metrics dataframe
2025-10-09 02:34:46,528:INFO:Uploading results into container
2025-10-09 02:34:46,529:INFO:Uploading model into container now
2025-10-09 02:34:46,530:INFO:_master_model_container: 35
2025-10-09 02:34:46,530:INFO:_display_container: 4
2025-10-09 02:34:46,531:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-10-09 02:34:46,531:INFO:create_model() successfully completed......................................
2025-10-09 02:34:46,622:INFO:SubProcess create_model() end ==================================
2025-10-09 02:34:46,622:INFO:Creating metrics dataframe
2025-10-09 02:34:46,630:INFO:Initializing Quadratic Discriminant Analysis
2025-10-09 02:34:46,631:INFO:Total runtime is 0.06547202666600546 minutes
2025-10-09 02:34:46,635:INFO:SubProcess create_model() called ==================================
2025-10-09 02:34:46,635:INFO:Initializing create_model()
2025-10-09 02:34:46,635:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A0ADFF950>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025A0B2A8BD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:34:46,636:INFO:Checking exceptions
2025-10-09 02:34:46,636:INFO:Importing libraries
2025-10-09 02:34:46,636:INFO:Copying training dataset
2025-10-09 02:34:46,641:INFO:Defining folds
2025-10-09 02:34:46,641:INFO:Declaring metric variables
2025-10-09 02:34:46,646:INFO:Importing untrained model
2025-10-09 02:34:46,650:INFO:Quadratic Discriminant Analysis Imported successfully
2025-10-09 02:34:46,661:INFO:Starting cross validation
2025-10-09 02:34:46,665:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:34:46,780:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 02:34:46,783:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 02:34:46,783:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 02:34:46,785:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 02:34:46,785:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 02:34:46,785:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 02:34:46,791:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 02:34:46,831:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 02:34:46,846:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:46,918:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 02:34:46,921:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-09 02:34:46,964:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:46,973:INFO:Calculating mean and std
2025-10-09 02:34:46,974:INFO:Creating metrics dataframe
2025-10-09 02:34:46,977:INFO:Uploading results into container
2025-10-09 02:34:46,978:INFO:Uploading model into container now
2025-10-09 02:34:46,978:INFO:_master_model_container: 36
2025-10-09 02:34:46,978:INFO:_display_container: 4
2025-10-09 02:34:46,979:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-10-09 02:34:46,979:INFO:create_model() successfully completed......................................
2025-10-09 02:34:47,073:INFO:SubProcess create_model() end ==================================
2025-10-09 02:34:47,074:INFO:Creating metrics dataframe
2025-10-09 02:34:47,082:INFO:Initializing Ada Boost Classifier
2025-10-09 02:34:47,082:INFO:Total runtime is 0.0729812224706014 minutes
2025-10-09 02:34:47,085:INFO:SubProcess create_model() called ==================================
2025-10-09 02:34:47,085:INFO:Initializing create_model()
2025-10-09 02:34:47,085:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A0ADFF950>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025A0B2A8BD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:34:47,085:INFO:Checking exceptions
2025-10-09 02:34:47,086:INFO:Importing libraries
2025-10-09 02:34:47,086:INFO:Copying training dataset
2025-10-09 02:34:47,089:INFO:Defining folds
2025-10-09 02:34:47,089:INFO:Declaring metric variables
2025-10-09 02:34:47,092:INFO:Importing untrained model
2025-10-09 02:34:47,096:INFO:Ada Boost Classifier Imported successfully
2025-10-09 02:34:47,105:INFO:Starting cross validation
2025-10-09 02:34:47,108:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:34:47,211:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 02:34:47,216:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 02:34:47,219:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 02:34:47,222:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 02:34:47,224:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 02:34:47,238:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 02:34:47,245:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 02:34:47,256:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 02:34:47,468:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:47,509:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:47,527:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 02:34:47,535:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-09 02:34:47,673:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:47,674:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:47,682:INFO:Calculating mean and std
2025-10-09 02:34:47,682:INFO:Creating metrics dataframe
2025-10-09 02:34:47,685:INFO:Uploading results into container
2025-10-09 02:34:47,685:INFO:Uploading model into container now
2025-10-09 02:34:47,686:INFO:_master_model_container: 37
2025-10-09 02:34:47,686:INFO:_display_container: 4
2025-10-09 02:34:47,686:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-10-09 02:34:47,686:INFO:create_model() successfully completed......................................
2025-10-09 02:34:47,765:INFO:SubProcess create_model() end ==================================
2025-10-09 02:34:47,765:INFO:Creating metrics dataframe
2025-10-09 02:34:47,773:INFO:Initializing Gradient Boosting Classifier
2025-10-09 02:34:47,773:INFO:Total runtime is 0.08450512488683065 minutes
2025-10-09 02:34:47,777:INFO:SubProcess create_model() called ==================================
2025-10-09 02:34:47,777:INFO:Initializing create_model()
2025-10-09 02:34:47,777:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A0ADFF950>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025A0B2A8BD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:34:47,777:INFO:Checking exceptions
2025-10-09 02:34:47,777:INFO:Importing libraries
2025-10-09 02:34:47,777:INFO:Copying training dataset
2025-10-09 02:34:47,781:INFO:Defining folds
2025-10-09 02:34:47,781:INFO:Declaring metric variables
2025-10-09 02:34:47,785:INFO:Importing untrained model
2025-10-09 02:34:47,790:INFO:Gradient Boosting Classifier Imported successfully
2025-10-09 02:34:47,810:INFO:Starting cross validation
2025-10-09 02:34:47,812:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:34:48,277:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:48,481:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:48,493:INFO:Calculating mean and std
2025-10-09 02:34:48,493:INFO:Creating metrics dataframe
2025-10-09 02:34:48,496:INFO:Uploading results into container
2025-10-09 02:34:48,496:INFO:Uploading model into container now
2025-10-09 02:34:48,497:INFO:_master_model_container: 38
2025-10-09 02:34:48,497:INFO:_display_container: 4
2025-10-09 02:34:48,497:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-09 02:34:48,497:INFO:create_model() successfully completed......................................
2025-10-09 02:34:48,577:INFO:SubProcess create_model() end ==================================
2025-10-09 02:34:48,579:INFO:Creating metrics dataframe
2025-10-09 02:34:48,588:INFO:Initializing Linear Discriminant Analysis
2025-10-09 02:34:48,588:INFO:Total runtime is 0.09807595014572144 minutes
2025-10-09 02:34:48,591:INFO:SubProcess create_model() called ==================================
2025-10-09 02:34:48,591:INFO:Initializing create_model()
2025-10-09 02:34:48,592:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A0ADFF950>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025A0B2A8BD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:34:48,592:INFO:Checking exceptions
2025-10-09 02:34:48,592:INFO:Importing libraries
2025-10-09 02:34:48,592:INFO:Copying training dataset
2025-10-09 02:34:48,595:INFO:Defining folds
2025-10-09 02:34:48,595:INFO:Declaring metric variables
2025-10-09 02:34:48,598:INFO:Importing untrained model
2025-10-09 02:34:48,602:INFO:Linear Discriminant Analysis Imported successfully
2025-10-09 02:34:48,610:INFO:Starting cross validation
2025-10-09 02:34:48,613:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:34:48,768:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:48,773:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:48,788:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:48,808:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:48,815:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:48,882:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:48,895:INFO:Calculating mean and std
2025-10-09 02:34:48,895:INFO:Creating metrics dataframe
2025-10-09 02:34:48,898:INFO:Uploading results into container
2025-10-09 02:34:48,899:INFO:Uploading model into container now
2025-10-09 02:34:48,899:INFO:_master_model_container: 39
2025-10-09 02:34:48,900:INFO:_display_container: 4
2025-10-09 02:34:48,900:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-09 02:34:48,900:INFO:create_model() successfully completed......................................
2025-10-09 02:34:48,978:INFO:SubProcess create_model() end ==================================
2025-10-09 02:34:48,978:INFO:Creating metrics dataframe
2025-10-09 02:34:48,986:INFO:Initializing Extra Trees Classifier
2025-10-09 02:34:48,986:INFO:Total runtime is 0.10472039779027303 minutes
2025-10-09 02:34:48,990:INFO:SubProcess create_model() called ==================================
2025-10-09 02:34:48,990:INFO:Initializing create_model()
2025-10-09 02:34:48,990:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A0ADFF950>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025A0B2A8BD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:34:48,990:INFO:Checking exceptions
2025-10-09 02:34:48,990:INFO:Importing libraries
2025-10-09 02:34:48,990:INFO:Copying training dataset
2025-10-09 02:34:48,994:INFO:Defining folds
2025-10-09 02:34:48,994:INFO:Declaring metric variables
2025-10-09 02:34:48,998:INFO:Importing untrained model
2025-10-09 02:34:49,001:INFO:Extra Trees Classifier Imported successfully
2025-10-09 02:34:49,009:INFO:Starting cross validation
2025-10-09 02:34:49,012:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:34:49,445:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:49,447:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:49,536:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:49,737:INFO:Calculating mean and std
2025-10-09 02:34:49,737:INFO:Creating metrics dataframe
2025-10-09 02:34:49,740:INFO:Uploading results into container
2025-10-09 02:34:49,740:INFO:Uploading model into container now
2025-10-09 02:34:49,741:INFO:_master_model_container: 40
2025-10-09 02:34:49,741:INFO:_display_container: 4
2025-10-09 02:34:49,741:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-10-09 02:34:49,741:INFO:create_model() successfully completed......................................
2025-10-09 02:34:49,820:INFO:SubProcess create_model() end ==================================
2025-10-09 02:34:49,820:INFO:Creating metrics dataframe
2025-10-09 02:34:49,829:INFO:Initializing Light Gradient Boosting Machine
2025-10-09 02:34:49,830:INFO:Total runtime is 0.11878538926442464 minutes
2025-10-09 02:34:49,833:INFO:SubProcess create_model() called ==================================
2025-10-09 02:34:49,833:INFO:Initializing create_model()
2025-10-09 02:34:49,833:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A0ADFF950>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025A0B2A8BD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:34:49,833:INFO:Checking exceptions
2025-10-09 02:34:49,833:INFO:Importing libraries
2025-10-09 02:34:49,833:INFO:Copying training dataset
2025-10-09 02:34:49,837:INFO:Defining folds
2025-10-09 02:34:49,837:INFO:Declaring metric variables
2025-10-09 02:34:49,840:INFO:Importing untrained model
2025-10-09 02:34:49,843:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-09 02:34:49,851:INFO:Starting cross validation
2025-10-09 02:34:49,854:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:34:50,106:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:50,109:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:50,121:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:50,143:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:50,374:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:50,413:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:50,429:INFO:Calculating mean and std
2025-10-09 02:34:50,430:INFO:Creating metrics dataframe
2025-10-09 02:34:50,433:INFO:Uploading results into container
2025-10-09 02:34:50,434:INFO:Uploading model into container now
2025-10-09 02:34:50,435:INFO:_master_model_container: 41
2025-10-09 02:34:50,435:INFO:_display_container: 4
2025-10-09 02:34:50,436:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-09 02:34:50,436:INFO:create_model() successfully completed......................................
2025-10-09 02:34:50,558:INFO:SubProcess create_model() end ==================================
2025-10-09 02:34:50,558:INFO:Creating metrics dataframe
2025-10-09 02:34:50,575:INFO:Initializing Dummy Classifier
2025-10-09 02:34:50,575:INFO:Total runtime is 0.13120274543762206 minutes
2025-10-09 02:34:50,581:INFO:SubProcess create_model() called ==================================
2025-10-09 02:34:50,581:INFO:Initializing create_model()
2025-10-09 02:34:50,581:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A0ADFF950>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025A0B2A8BD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:34:50,582:INFO:Checking exceptions
2025-10-09 02:34:50,582:INFO:Importing libraries
2025-10-09 02:34:50,582:INFO:Copying training dataset
2025-10-09 02:34:50,589:INFO:Defining folds
2025-10-09 02:34:50,590:INFO:Declaring metric variables
2025-10-09 02:34:50,595:INFO:Importing untrained model
2025-10-09 02:34:50,605:INFO:Dummy Classifier Imported successfully
2025-10-09 02:34:50,619:INFO:Starting cross validation
2025-10-09 02:34:50,623:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:34:50,787:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:50,791:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:50,881:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:50,885:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:50,907:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:50,913:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:50,916:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:50,918:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:50,922:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:50,938:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:50,951:INFO:Calculating mean and std
2025-10-09 02:34:50,953:INFO:Creating metrics dataframe
2025-10-09 02:34:50,956:INFO:Uploading results into container
2025-10-09 02:34:50,957:INFO:Uploading model into container now
2025-10-09 02:34:50,958:INFO:_master_model_container: 42
2025-10-09 02:34:50,958:INFO:_display_container: 4
2025-10-09 02:34:50,959:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-10-09 02:34:50,959:INFO:create_model() successfully completed......................................
2025-10-09 02:34:51,060:INFO:SubProcess create_model() end ==================================
2025-10-09 02:34:51,060:INFO:Creating metrics dataframe
2025-10-09 02:34:51,071:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-10-09 02:34:51,083:INFO:Initializing create_model()
2025-10-09 02:34:51,083:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A0ADFF950>, estimator=DummyClassifier(constant=None, random_state=123, strategy='prior'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:34:51,083:INFO:Checking exceptions
2025-10-09 02:34:51,086:INFO:Importing libraries
2025-10-09 02:34:51,086:INFO:Copying training dataset
2025-10-09 02:34:51,090:INFO:Defining folds
2025-10-09 02:34:51,090:INFO:Declaring metric variables
2025-10-09 02:34:51,090:INFO:Importing untrained model
2025-10-09 02:34:51,090:INFO:Declaring custom model
2025-10-09 02:34:51,091:INFO:Dummy Classifier Imported successfully
2025-10-09 02:34:51,092:INFO:Cross validation set to False
2025-10-09 02:34:51,092:INFO:Fitting Model
2025-10-09 02:34:51,164:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-10-09 02:34:51,164:INFO:create_model() successfully completed......................................
2025-10-09 02:34:51,270:INFO:_master_model_container: 42
2025-10-09 02:34:51,270:INFO:_display_container: 4
2025-10-09 02:34:51,271:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-10-09 02:34:51,271:INFO:compare_models() successfully completed......................................
2025-10-09 02:34:58,621:INFO:Initializing create_model()
2025-10-09 02:34:58,621:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A0ADFF950>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:34:58,622:INFO:Checking exceptions
2025-10-09 02:34:58,636:INFO:Importing libraries
2025-10-09 02:34:58,636:INFO:Copying training dataset
2025-10-09 02:34:58,641:INFO:Defining folds
2025-10-09 02:34:58,641:INFO:Declaring metric variables
2025-10-09 02:34:58,645:INFO:Importing untrained model
2025-10-09 02:34:58,650:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-09 02:34:58,658:INFO:Starting cross validation
2025-10-09 02:34:58,660:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:34:59,036:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:59,037:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:59,182:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:59,275:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:59,310:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:59,380:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:34:59,392:INFO:Calculating mean and std
2025-10-09 02:34:59,394:INFO:Creating metrics dataframe
2025-10-09 02:34:59,401:INFO:Finalizing model
2025-10-09 02:34:59,473:INFO:[LightGBM] [Info] Number of positive: 18, number of negative: 87
2025-10-09 02:34:59,473:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000086 seconds.
2025-10-09 02:34:59,473:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-10-09 02:34:59,473:INFO:[LightGBM] [Info] Total Bins 117
2025-10-09 02:34:59,473:INFO:[LightGBM] [Info] Number of data points in the train set: 105, number of used features: 10
2025-10-09 02:34:59,474:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.171429 -> initscore=-1.575536
2025-10-09 02:34:59,474:INFO:[LightGBM] [Info] Start training from score -1.575536
2025-10-09 02:34:59,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:34:59,507:INFO:Uploading results into container
2025-10-09 02:34:59,508:INFO:Uploading model into container now
2025-10-09 02:34:59,526:INFO:_master_model_container: 43
2025-10-09 02:34:59,527:INFO:_display_container: 5
2025-10-09 02:34:59,529:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-09 02:34:59,530:INFO:create_model() successfully completed......................................
2025-10-09 02:35:03,391:INFO:Initializing tune_model()
2025-10-09 02:35:03,391:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A0ADFF950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-10-09 02:35:03,392:INFO:Checking exceptions
2025-10-09 02:35:03,409:INFO:Copying training dataset
2025-10-09 02:35:03,413:INFO:Checking base model
2025-10-09 02:35:03,413:INFO:Base model : Light Gradient Boosting Machine
2025-10-09 02:35:03,418:INFO:Declaring metric variables
2025-10-09 02:35:03,424:INFO:Defining Hyperparameters
2025-10-09 02:35:03,627:INFO:Tuning with n_jobs=-1
2025-10-09 02:35:03,627:INFO:Initializing RandomizedSearchCV
2025-10-09 02:35:09,719:INFO:best_params: {'actual_estimator__reg_lambda': 1e-06, 'actual_estimator__reg_alpha': 4, 'actual_estimator__num_leaves': 80, 'actual_estimator__n_estimators': 130, 'actual_estimator__min_split_gain': 0.5, 'actual_estimator__min_child_samples': 91, 'actual_estimator__learning_rate': 1e-07, 'actual_estimator__feature_fraction': 0.9, 'actual_estimator__bagging_freq': 0, 'actual_estimator__bagging_fraction': 0.5}
2025-10-09 02:35:09,720:INFO:Hyperparameter search completed
2025-10-09 02:35:09,720:INFO:SubProcess create_model() called ==================================
2025-10-09 02:35:09,721:INFO:Initializing create_model()
2025-10-09 02:35:09,721:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A0ADFF950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025A0AF8F050>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 1e-06, 'reg_alpha': 4, 'num_leaves': 80, 'n_estimators': 130, 'min_split_gain': 0.5, 'min_child_samples': 91, 'learning_rate': 1e-07, 'feature_fraction': 0.9, 'bagging_freq': 0, 'bagging_fraction': 0.5})
2025-10-09 02:35:09,721:INFO:Checking exceptions
2025-10-09 02:35:09,721:INFO:Importing libraries
2025-10-09 02:35:09,721:INFO:Copying training dataset
2025-10-09 02:35:09,728:INFO:Defining folds
2025-10-09 02:35:09,728:INFO:Declaring metric variables
2025-10-09 02:35:09,733:INFO:Importing untrained model
2025-10-09 02:35:09,733:INFO:Declaring custom model
2025-10-09 02:35:09,739:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-09 02:35:09,748:INFO:Starting cross validation
2025-10-09 02:35:09,750:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:35:09,997:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:35:10,001:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:35:10,003:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:35:10,107:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:35:10,123:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:35:10,155:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:35:10,201:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:35:10,205:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:35:10,230:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:35:10,257:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:35:10,271:INFO:Calculating mean and std
2025-10-09 02:35:10,273:INFO:Creating metrics dataframe
2025-10-09 02:35:10,280:INFO:Finalizing model
2025-10-09 02:35:10,366:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2025-10-09 02:35:10,367:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2025-10-09 02:35:10,367:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-10-09 02:35:10,367:INFO:[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.
2025-10-09 02:35:10,368:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2025-10-09 02:35:10,368:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2025-10-09 02:35:10,368:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2025-10-09 02:35:10,368:INFO:[LightGBM] [Info] Number of positive: 18, number of negative: 87
2025-10-09 02:35:10,368:INFO:[LightGBM] [Info] Total Bins 0
2025-10-09 02:35:10,369:INFO:[LightGBM] [Info] Number of data points in the train set: 105, number of used features: 0
2025-10-09 02:35:10,369:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.171429 -> initscore=-1.575536
2025-10-09 02:35:10,369:INFO:[LightGBM] [Info] Start training from score -1.575536
2025-10-09 02:35:10,369:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,370:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,370:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,370:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,370:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,371:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,371:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,371:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,371:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,371:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,371:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,371:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,371:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,372:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,372:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,372:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,372:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,372:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,372:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,372:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,372:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,373:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,373:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,373:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,373:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,373:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,373:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,373:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,374:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,374:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,374:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,374:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,374:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,374:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,374:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,374:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,375:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,375:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,375:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,375:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,375:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,376:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,376:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,376:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,376:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,376:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,377:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,377:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,377:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,377:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,377:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,377:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,378:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,378:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,378:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,378:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,378:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,378:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,378:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,378:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,379:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,379:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,379:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,379:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,379:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,379:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,379:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,379:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,380:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,380:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,380:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,380:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,380:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,380:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,380:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,380:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,381:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,381:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,381:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,381:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,381:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,381:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,381:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,381:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,381:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,382:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,382:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,382:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,382:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,382:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,382:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,382:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,383:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,383:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,383:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,383:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,383:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,384:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,384:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,384:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,384:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,384:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,384:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,384:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,385:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,385:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,385:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,386:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,386:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,386:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,386:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,386:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,386:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,387:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,387:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,388:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,388:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,388:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,388:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,388:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,388:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,389:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,389:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,389:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,389:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,389:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,389:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,390:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,390:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,390:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2025-10-09 02:35:10,399:INFO:Uploading results into container
2025-10-09 02:35:10,401:INFO:Uploading model into container now
2025-10-09 02:35:10,401:INFO:_master_model_container: 44
2025-10-09 02:35:10,401:INFO:_display_container: 6
2025-10-09 02:35:10,402:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-09 02:35:10,403:INFO:create_model() successfully completed......................................
2025-10-09 02:35:10,550:INFO:SubProcess create_model() end ==================================
2025-10-09 02:35:10,550:INFO:choose_better activated
2025-10-09 02:35:10,557:INFO:SubProcess create_model() called ==================================
2025-10-09 02:35:10,559:INFO:Initializing create_model()
2025-10-09 02:35:10,559:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A0ADFF950>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-09 02:35:10,559:INFO:Checking exceptions
2025-10-09 02:35:10,561:INFO:Importing libraries
2025-10-09 02:35:10,562:INFO:Copying training dataset
2025-10-09 02:35:10,567:INFO:Defining folds
2025-10-09 02:35:10,567:INFO:Declaring metric variables
2025-10-09 02:35:10,567:INFO:Importing untrained model
2025-10-09 02:35:10,568:INFO:Declaring custom model
2025-10-09 02:35:10,569:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-09 02:35:10,569:INFO:Starting cross validation
2025-10-09 02:35:10,571:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-09 02:35:10,902:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:35:10,964:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:35:10,968:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:35:10,988:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:35:11,073:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:35:11,187:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:35:11,204:INFO:Calculating mean and std
2025-10-09 02:35:11,205:INFO:Creating metrics dataframe
2025-10-09 02:35:11,207:INFO:Finalizing model
2025-10-09 02:35:11,281:INFO:[LightGBM] [Info] Number of positive: 18, number of negative: 87
2025-10-09 02:35:11,281:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000058 seconds.
2025-10-09 02:35:11,281:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-09 02:35:11,281:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-09 02:35:11,281:INFO:[LightGBM] [Info] Total Bins 117
2025-10-09 02:35:11,281:INFO:[LightGBM] [Info] Number of data points in the train set: 105, number of used features: 10
2025-10-09 02:35:11,282:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.171429 -> initscore=-1.575536
2025-10-09 02:35:11,282:INFO:[LightGBM] [Info] Start training from score -1.575536
2025-10-09 02:35:11,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-09 02:35:11,318:INFO:Uploading results into container
2025-10-09 02:35:11,319:INFO:Uploading model into container now
2025-10-09 02:35:11,320:INFO:_master_model_container: 45
2025-10-09 02:35:11,320:INFO:_display_container: 7
2025-10-09 02:35:11,321:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-09 02:35:11,321:INFO:create_model() successfully completed......................................
2025-10-09 02:35:11,424:INFO:SubProcess create_model() end ==================================
2025-10-09 02:35:11,425:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.7891
2025-10-09 02:35:11,425:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.8291
2025-10-09 02:35:11,426:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-10-09 02:35:11,426:INFO:choose_better completed
2025-10-09 02:35:11,434:INFO:_master_model_container: 45
2025-10-09 02:35:11,434:INFO:_display_container: 6
2025-10-09 02:35:11,435:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-09 02:35:11,435:INFO:tune_model() successfully completed......................................
2025-10-09 02:35:16,025:INFO:Initializing evaluate_model()
2025-10-09 02:35:16,025:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A0ADFF950>, estimator=LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-10-09 02:35:16,036:INFO:Initializing plot_model()
2025-10-09 02:35:16,036:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A0ADFF950>, estimator=LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-09 02:35:16,036:INFO:Checking exceptions
2025-10-09 02:35:16,038:INFO:Preloading libraries
2025-10-09 02:35:16,075:INFO:Copying training dataset
2025-10-09 02:35:16,075:INFO:Plot type: pipeline
2025-10-09 02:35:16,278:INFO:Visual Rendered Successfully
2025-10-09 02:35:16,378:INFO:plot_model() successfully completed......................................
2025-10-09 02:35:20,578:INFO:Initializing predict_model()
2025-10-09 02:35:20,578:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025A0ADFF950>, estimator=LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000025A0AF713A0>)
2025-10-09 02:35:20,578:INFO:Checking exceptions
2025-10-09 02:35:20,578:INFO:Preloading libraries
2025-10-09 02:35:20,629:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-09 02:37:27,998:INFO:Initializing save_model()
2025-10-09 02:37:27,998:INFO:save_model(model=LGBMClassifier(bagging_fraction=0.5, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=1e-07, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.5,
               n_estimators=130, n_jobs=-1, num_leaves=80, objective=None,
               random_state=123, reg_alpha=4, reg_lambda=1e-06, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), model_name=modelo_vehicular_final, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\jjqs_\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'ingresos_mensuales',
                                             'nro_creditos_previos',
                                             'cuota_vs_ingreso'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'...
                                    include=['estado_civil',
                                             'historia_credito'],
                                    transformer=OneHotEncoder(cols=['estado_civil',
                                                                    'historia_credito'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-10-09 02:37:27,998:INFO:Adding model into prep_pipe
2025-10-09 02:37:28,349:INFO:modelo_vehicular_final.pkl saved in current working directory
2025-10-09 02:37:28,380:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'ingresos_mensuales',
                                             'nro_creditos_previos',
                                             'cuota_vs_ingreso'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWr...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.9,
                                importance_type='split', learning_rate=1e-07,
                                max_depth=-1, min_child_samples=91,
                                min_child_weight=0.001, min_split_gain=0.5,
                                n_estimators=130, n_jobs=-1, num_leaves=80,
                                objective=None, random_state=123, reg_alpha=4,
                                reg_lambda=1e-06, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2025-10-09 02:37:28,380:INFO:save_model() successfully completed......................................
2025-10-10 00:18:13,608:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-10 00:18:13,939:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-10 00:18:13,939:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-10 00:18:13,939:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-10 00:25:39,570:INFO:PyCaret ClassificationExperiment
2025-10-10 00:25:39,570:INFO:Logging name: clf-default-name
2025-10-10 00:25:39,570:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-10-10 00:25:39,571:INFO:version 3.3.2
2025-10-10 00:25:39,571:INFO:Initializing setup()
2025-10-10 00:25:39,571:INFO:self.USI: c45e
2025-10-10 00:25:39,571:INFO:self._variable_keys: {'fold_generator', 'n_jobs_param', '_available_plots', 'X', 'is_multiclass', 'logging_param', 'data', 'seed', 'target_param', 'html_param', 'USI', 'X_train', 'fix_imbalance', 'log_plots_param', 'y_test', '_ml_usecase', 'pipeline', 'y', 'exp_id', 'X_test', 'exp_name_log', 'idx', 'memory', 'fold_shuffle_param', 'y_train', 'gpu_param', 'fold_groups_param', 'gpu_n_jobs_param'}
2025-10-10 00:25:39,571:INFO:Checking environment
2025-10-10 00:25:39,571:INFO:python_version: 3.11.0
2025-10-10 00:25:39,571:INFO:python_build: ('main', 'Oct 24 2022 18:26:48')
2025-10-10 00:25:39,571:INFO:machine: AMD64
2025-10-10 00:25:39,571:INFO:platform: Windows-10-10.0.19045-SP0
2025-10-10 00:25:39,578:INFO:Memory: svmem(total=12713988096, available=1221681152, percent=90.4, used=11492306944, free=1221681152)
2025-10-10 00:25:39,578:INFO:Physical Core: 4
2025-10-10 00:25:39,578:INFO:Logical Core: 8
2025-10-10 00:25:39,578:INFO:Checking libraries
2025-10-10 00:25:39,578:INFO:System:
2025-10-10 00:25:39,578:INFO:    python: 3.11.0 (main, Oct 24 2022, 18:26:48) [MSC v.1933 64 bit (AMD64)]
2025-10-10 00:25:39,578:INFO:executable: c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\python.exe
2025-10-10 00:25:39,578:INFO:   machine: Windows-10-10.0.19045-SP0
2025-10-10 00:25:39,578:INFO:PyCaret required dependencies:
2025-10-10 00:25:39,706:INFO:                 pip: 25.2
2025-10-10 00:25:39,706:INFO:          setuptools: 65.5.0
2025-10-10 00:25:39,706:INFO:             pycaret: 3.3.2
2025-10-10 00:25:39,706:INFO:             IPython: 9.6.0
2025-10-10 00:25:39,706:INFO:          ipywidgets: 8.1.7
2025-10-10 00:25:39,706:INFO:                tqdm: 4.67.1
2025-10-10 00:25:39,706:INFO:               numpy: 1.26.4
2025-10-10 00:25:39,706:INFO:              pandas: 2.1.4
2025-10-10 00:25:39,706:INFO:              jinja2: 3.1.6
2025-10-10 00:25:39,706:INFO:               scipy: 1.11.4
2025-10-10 00:25:39,706:INFO:              joblib: 1.3.2
2025-10-10 00:25:39,707:INFO:             sklearn: 1.4.2
2025-10-10 00:25:39,707:INFO:                pyod: 2.0.5
2025-10-10 00:25:39,707:INFO:            imblearn: 0.14.0
2025-10-10 00:25:39,707:INFO:   category_encoders: 2.7.0
2025-10-10 00:25:39,707:INFO:            lightgbm: 4.6.0
2025-10-10 00:25:39,707:INFO:               numba: 0.62.1
2025-10-10 00:25:39,707:INFO:            requests: 2.32.5
2025-10-10 00:25:39,707:INFO:          matplotlib: 3.7.5
2025-10-10 00:25:39,707:INFO:          scikitplot: 0.3.7
2025-10-10 00:25:39,707:INFO:         yellowbrick: 1.5
2025-10-10 00:25:39,707:INFO:              plotly: 6.3.1
2025-10-10 00:25:39,707:INFO:    plotly-resampler: Not installed
2025-10-10 00:25:39,707:INFO:             kaleido: 1.1.0
2025-10-10 00:25:39,707:INFO:           schemdraw: 0.15
2025-10-10 00:25:39,707:INFO:         statsmodels: 0.14.5
2025-10-10 00:25:39,707:INFO:              sktime: 0.26.0
2025-10-10 00:25:39,707:INFO:               tbats: 1.1.3
2025-10-10 00:25:39,707:INFO:            pmdarima: 2.0.4
2025-10-10 00:25:39,707:INFO:              psutil: 7.1.0
2025-10-10 00:25:39,707:INFO:          markupsafe: 3.0.3
2025-10-10 00:25:39,707:INFO:             pickle5: Not installed
2025-10-10 00:25:39,707:INFO:         cloudpickle: 3.1.1
2025-10-10 00:25:39,707:INFO:         deprecation: 2.1.0
2025-10-10 00:25:39,707:INFO:              xxhash: 3.6.0
2025-10-10 00:25:39,707:INFO:           wurlitzer: Not installed
2025-10-10 00:25:39,708:INFO:PyCaret optional dependencies:
2025-10-10 00:25:39,728:INFO:                shap: Not installed
2025-10-10 00:25:39,728:INFO:           interpret: Not installed
2025-10-10 00:25:39,728:INFO:                umap: Not installed
2025-10-10 00:25:39,728:INFO:     ydata_profiling: Not installed
2025-10-10 00:25:39,728:INFO:  explainerdashboard: Not installed
2025-10-10 00:25:39,728:INFO:             autoviz: Not installed
2025-10-10 00:25:39,728:INFO:           fairlearn: Not installed
2025-10-10 00:25:39,728:INFO:          deepchecks: Not installed
2025-10-10 00:25:39,728:INFO:             xgboost: Not installed
2025-10-10 00:25:39,728:INFO:            catboost: Not installed
2025-10-10 00:25:39,728:INFO:              kmodes: Not installed
2025-10-10 00:25:39,728:INFO:             mlxtend: Not installed
2025-10-10 00:25:39,729:INFO:       statsforecast: Not installed
2025-10-10 00:25:39,729:INFO:        tune_sklearn: Not installed
2025-10-10 00:25:39,729:INFO:                 ray: Not installed
2025-10-10 00:25:39,729:INFO:            hyperopt: Not installed
2025-10-10 00:25:39,729:INFO:              optuna: Not installed
2025-10-10 00:25:39,729:INFO:               skopt: Not installed
2025-10-10 00:25:39,729:INFO:              mlflow: Not installed
2025-10-10 00:25:39,729:INFO:              gradio: Not installed
2025-10-10 00:25:39,729:INFO:             fastapi: Not installed
2025-10-10 00:25:39,729:INFO:             uvicorn: Not installed
2025-10-10 00:25:39,729:INFO:              m2cgen: Not installed
2025-10-10 00:25:39,729:INFO:           evidently: Not installed
2025-10-10 00:25:39,729:INFO:               fugue: Not installed
2025-10-10 00:25:39,729:INFO:           streamlit: Not installed
2025-10-10 00:25:39,729:INFO:             prophet: Not installed
2025-10-10 00:25:39,729:INFO:None
2025-10-10 00:25:39,729:INFO:Set up data.
2025-10-10 00:25:39,747:INFO:Set up folding strategy.
2025-10-10 00:25:39,747:INFO:Set up train/test split.
2025-10-10 00:25:39,793:INFO:Set up index.
2025-10-10 00:25:39,794:INFO:Assigning column types.
2025-10-10 00:25:39,798:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-10 00:25:39,839:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-10 00:25:39,843:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-10 00:25:39,875:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-10 00:25:39,875:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-10 00:25:39,913:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-10 00:25:39,914:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-10 00:25:39,946:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-10 00:25:39,947:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-10 00:25:39,947:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-10 00:25:39,985:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-10 00:25:40,009:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-10 00:25:40,010:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-10 00:25:40,047:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-10 00:25:40,071:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-10 00:25:40,071:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-10 00:25:40,071:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-10-10 00:25:40,136:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-10 00:25:40,137:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-10 00:25:40,204:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-10 00:25:40,205:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-10 00:25:40,207:INFO:Preparing preprocessing pipeline...
2025-10-10 00:25:40,209:INFO:Set up simple imputation.
2025-10-10 00:25:40,211:INFO:Set up encoding of ordinal features.
2025-10-10 00:25:40,213:INFO:Set up encoding of categorical features.
2025-10-10 00:25:40,213:INFO:Set up feature normalization.
2025-10-10 00:25:40,318:INFO:Finished creating preprocessing pipeline.
2025-10-10 00:25:40,342:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\jjqs_\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'meses_como_cliente',
                                             'frecuencia_uso',
                                             'soporte_llamadas'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('...
                 TransformerWrapper(exclude=None, include=['tipo_plan'],
                                    transformer=OneHotEncoder(cols=['tipo_plan'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2025-10-10 00:25:40,342:INFO:Creating final display dataframe.
2025-10-10 00:25:40,537:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target             churn
2                   Target type            Binary
3           Original data shape          (300, 7)
4        Transformed data shape          (300, 9)
5   Transformed train set shape          (210, 9)
6    Transformed test set shape           (90, 9)
7              Numeric features                 4
8          Categorical features                 2
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                    Normalize              True
16             Normalize method            zscore
17               Fold Generator   StratifiedKFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  clf-default-name
23                          USI              c45e
2025-10-10 00:25:40,636:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-10 00:25:40,636:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-10 00:25:40,715:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-10 00:25:40,715:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-10 00:25:40,716:INFO:setup() successfully completed in 1.16s...............
2025-10-10 00:25:52,802:INFO:Initializing compare_models()
2025-10-10 00:25:52,802:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029AC8C7E750>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000029AC8C7E750>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-10-10 00:25:52,803:INFO:Checking exceptions
2025-10-10 00:25:52,812:INFO:Preparing display monitor
2025-10-10 00:25:52,871:INFO:Initializing Logistic Regression
2025-10-10 00:25:52,871:INFO:Total runtime is 0.0 minutes
2025-10-10 00:25:52,876:INFO:SubProcess create_model() called ==================================
2025-10-10 00:25:52,877:INFO:Initializing create_model()
2025-10-10 00:25:52,877:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029AC8C7E750>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029AC90F5AD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-10 00:25:52,877:INFO:Checking exceptions
2025-10-10 00:25:52,877:INFO:Importing libraries
2025-10-10 00:25:52,877:INFO:Copying training dataset
2025-10-10 00:25:52,883:INFO:Defining folds
2025-10-10 00:25:52,883:INFO:Declaring metric variables
2025-10-10 00:25:52,889:INFO:Importing untrained model
2025-10-10 00:25:52,895:INFO:Logistic Regression Imported successfully
2025-10-10 00:25:52,910:INFO:Starting cross validation
2025-10-10 00:25:52,912:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-10 00:26:03,922:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-10 00:26:04,296:INFO:Calculating mean and std
2025-10-10 00:26:04,299:INFO:Creating metrics dataframe
2025-10-10 00:26:04,304:INFO:Uploading results into container
2025-10-10 00:26:04,305:INFO:Uploading model into container now
2025-10-10 00:26:04,306:INFO:_master_model_container: 1
2025-10-10 00:26:04,306:INFO:_display_container: 2
2025-10-10 00:26:04,307:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-10 00:26:04,307:INFO:create_model() successfully completed......................................
2025-10-10 00:26:04,456:INFO:SubProcess create_model() end ==================================
2025-10-10 00:26:04,456:INFO:Creating metrics dataframe
2025-10-10 00:26:04,465:INFO:Initializing K Neighbors Classifier
2025-10-10 00:26:04,465:INFO:Total runtime is 0.19322408437728883 minutes
2025-10-10 00:26:04,471:INFO:SubProcess create_model() called ==================================
2025-10-10 00:26:04,471:INFO:Initializing create_model()
2025-10-10 00:26:04,471:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029AC8C7E750>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029AC90F5AD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-10 00:26:04,471:INFO:Checking exceptions
2025-10-10 00:26:04,471:INFO:Importing libraries
2025-10-10 00:26:04,472:INFO:Copying training dataset
2025-10-10 00:26:04,478:INFO:Defining folds
2025-10-10 00:26:04,478:INFO:Declaring metric variables
2025-10-10 00:26:04,484:INFO:Importing untrained model
2025-10-10 00:26:04,492:INFO:K Neighbors Classifier Imported successfully
2025-10-10 00:26:04,507:INFO:Starting cross validation
2025-10-10 00:26:04,509:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-10 00:26:04,887:INFO:Calculating mean and std
2025-10-10 00:26:04,888:INFO:Creating metrics dataframe
2025-10-10 00:26:04,890:INFO:Uploading results into container
2025-10-10 00:26:04,891:INFO:Uploading model into container now
2025-10-10 00:26:04,892:INFO:_master_model_container: 2
2025-10-10 00:26:04,893:INFO:_display_container: 2
2025-10-10 00:26:04,893:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-10-10 00:26:04,893:INFO:create_model() successfully completed......................................
2025-10-10 00:26:04,994:INFO:SubProcess create_model() end ==================================
2025-10-10 00:26:04,994:INFO:Creating metrics dataframe
2025-10-10 00:26:05,002:INFO:Initializing Naive Bayes
2025-10-10 00:26:05,003:INFO:Total runtime is 0.20218496322631838 minutes
2025-10-10 00:26:05,007:INFO:SubProcess create_model() called ==================================
2025-10-10 00:26:05,007:INFO:Initializing create_model()
2025-10-10 00:26:05,007:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029AC8C7E750>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029AC90F5AD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-10 00:26:05,008:INFO:Checking exceptions
2025-10-10 00:26:05,008:INFO:Importing libraries
2025-10-10 00:26:05,008:INFO:Copying training dataset
2025-10-10 00:26:05,013:INFO:Defining folds
2025-10-10 00:26:05,013:INFO:Declaring metric variables
2025-10-10 00:26:05,018:INFO:Importing untrained model
2025-10-10 00:26:05,024:INFO:Naive Bayes Imported successfully
2025-10-10 00:26:05,035:INFO:Starting cross validation
2025-10-10 00:26:05,037:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-10 00:26:05,290:INFO:Calculating mean and std
2025-10-10 00:26:05,291:INFO:Creating metrics dataframe
2025-10-10 00:26:05,293:INFO:Uploading results into container
2025-10-10 00:26:05,294:INFO:Uploading model into container now
2025-10-10 00:26:05,295:INFO:_master_model_container: 3
2025-10-10 00:26:05,295:INFO:_display_container: 2
2025-10-10 00:26:05,295:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-10-10 00:26:05,295:INFO:create_model() successfully completed......................................
2025-10-10 00:26:05,366:INFO:SubProcess create_model() end ==================================
2025-10-10 00:26:05,367:INFO:Creating metrics dataframe
2025-10-10 00:26:05,375:INFO:Initializing Decision Tree Classifier
2025-10-10 00:26:05,375:INFO:Total runtime is 0.2083863655726115 minutes
2025-10-10 00:26:05,379:INFO:SubProcess create_model() called ==================================
2025-10-10 00:26:05,380:INFO:Initializing create_model()
2025-10-10 00:26:05,380:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029AC8C7E750>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029AC90F5AD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-10 00:26:05,380:INFO:Checking exceptions
2025-10-10 00:26:05,380:INFO:Importing libraries
2025-10-10 00:26:05,380:INFO:Copying training dataset
2025-10-10 00:26:05,384:INFO:Defining folds
2025-10-10 00:26:05,384:INFO:Declaring metric variables
2025-10-10 00:26:05,388:INFO:Importing untrained model
2025-10-10 00:26:05,392:INFO:Decision Tree Classifier Imported successfully
2025-10-10 00:26:05,402:INFO:Starting cross validation
2025-10-10 00:26:05,404:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-10 00:26:05,667:INFO:Calculating mean and std
2025-10-10 00:26:05,668:INFO:Creating metrics dataframe
2025-10-10 00:26:05,671:INFO:Uploading results into container
2025-10-10 00:26:05,672:INFO:Uploading model into container now
2025-10-10 00:26:05,672:INFO:_master_model_container: 4
2025-10-10 00:26:05,673:INFO:_display_container: 2
2025-10-10 00:26:05,673:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-10-10 00:26:05,673:INFO:create_model() successfully completed......................................
2025-10-10 00:26:05,767:INFO:SubProcess create_model() end ==================================
2025-10-10 00:26:05,767:INFO:Creating metrics dataframe
2025-10-10 00:26:05,777:INFO:Initializing SVM - Linear Kernel
2025-10-10 00:26:05,777:INFO:Total runtime is 0.21508690516153972 minutes
2025-10-10 00:26:05,782:INFO:SubProcess create_model() called ==================================
2025-10-10 00:26:05,782:INFO:Initializing create_model()
2025-10-10 00:26:05,783:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029AC8C7E750>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029AC90F5AD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-10 00:26:05,783:INFO:Checking exceptions
2025-10-10 00:26:05,783:INFO:Importing libraries
2025-10-10 00:26:05,783:INFO:Copying training dataset
2025-10-10 00:26:05,787:INFO:Defining folds
2025-10-10 00:26:05,788:INFO:Declaring metric variables
2025-10-10 00:26:05,792:INFO:Importing untrained model
2025-10-10 00:26:05,797:INFO:SVM - Linear Kernel Imported successfully
2025-10-10 00:26:05,809:INFO:Starting cross validation
2025-10-10 00:26:05,813:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-10 00:26:06,067:INFO:Calculating mean and std
2025-10-10 00:26:06,067:INFO:Creating metrics dataframe
2025-10-10 00:26:06,069:INFO:Uploading results into container
2025-10-10 00:26:06,070:INFO:Uploading model into container now
2025-10-10 00:26:06,070:INFO:_master_model_container: 5
2025-10-10 00:26:06,070:INFO:_display_container: 2
2025-10-10 00:26:06,071:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-10-10 00:26:06,071:INFO:create_model() successfully completed......................................
2025-10-10 00:26:06,144:INFO:SubProcess create_model() end ==================================
2025-10-10 00:26:06,144:INFO:Creating metrics dataframe
2025-10-10 00:26:06,151:INFO:Initializing Ridge Classifier
2025-10-10 00:26:06,151:INFO:Total runtime is 0.22132161458333335 minutes
2025-10-10 00:26:06,154:INFO:SubProcess create_model() called ==================================
2025-10-10 00:26:06,154:INFO:Initializing create_model()
2025-10-10 00:26:06,154:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029AC8C7E750>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029AC90F5AD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-10 00:26:06,154:INFO:Checking exceptions
2025-10-10 00:26:06,154:INFO:Importing libraries
2025-10-10 00:26:06,155:INFO:Copying training dataset
2025-10-10 00:26:06,159:INFO:Defining folds
2025-10-10 00:26:06,159:INFO:Declaring metric variables
2025-10-10 00:26:06,161:INFO:Importing untrained model
2025-10-10 00:26:06,164:INFO:Ridge Classifier Imported successfully
2025-10-10 00:26:06,174:INFO:Starting cross validation
2025-10-10 00:26:06,175:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-10 00:26:06,333:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-10 00:26:06,337:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-10 00:26:06,349:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-10 00:26:06,434:INFO:Calculating mean and std
2025-10-10 00:26:06,435:INFO:Creating metrics dataframe
2025-10-10 00:26:06,437:INFO:Uploading results into container
2025-10-10 00:26:06,437:INFO:Uploading model into container now
2025-10-10 00:26:06,438:INFO:_master_model_container: 6
2025-10-10 00:26:06,438:INFO:_display_container: 2
2025-10-10 00:26:06,438:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-10-10 00:26:06,438:INFO:create_model() successfully completed......................................
2025-10-10 00:26:06,519:INFO:SubProcess create_model() end ==================================
2025-10-10 00:26:06,519:INFO:Creating metrics dataframe
2025-10-10 00:26:06,528:INFO:Initializing Random Forest Classifier
2025-10-10 00:26:06,528:INFO:Total runtime is 0.22761411666870118 minutes
2025-10-10 00:26:06,532:INFO:SubProcess create_model() called ==================================
2025-10-10 00:26:06,533:INFO:Initializing create_model()
2025-10-10 00:26:06,533:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029AC8C7E750>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029AC90F5AD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-10 00:26:06,533:INFO:Checking exceptions
2025-10-10 00:26:06,533:INFO:Importing libraries
2025-10-10 00:26:06,533:INFO:Copying training dataset
2025-10-10 00:26:06,539:INFO:Defining folds
2025-10-10 00:26:06,539:INFO:Declaring metric variables
2025-10-10 00:26:06,543:INFO:Importing untrained model
2025-10-10 00:26:06,548:INFO:Random Forest Classifier Imported successfully
2025-10-10 00:26:06,559:INFO:Starting cross validation
2025-10-10 00:26:06,561:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-10 00:26:07,127:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-10 00:26:07,451:INFO:Calculating mean and std
2025-10-10 00:26:07,452:INFO:Creating metrics dataframe
2025-10-10 00:26:07,455:INFO:Uploading results into container
2025-10-10 00:26:07,455:INFO:Uploading model into container now
2025-10-10 00:26:07,457:INFO:_master_model_container: 7
2025-10-10 00:26:07,457:INFO:_display_container: 2
2025-10-10 00:26:07,458:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-10-10 00:26:07,458:INFO:create_model() successfully completed......................................
2025-10-10 00:26:07,531:INFO:SubProcess create_model() end ==================================
2025-10-10 00:26:07,531:INFO:Creating metrics dataframe
2025-10-10 00:26:07,541:INFO:Initializing Quadratic Discriminant Analysis
2025-10-10 00:26:07,541:INFO:Total runtime is 0.2444928010304769 minutes
2025-10-10 00:26:07,546:INFO:SubProcess create_model() called ==================================
2025-10-10 00:26:07,546:INFO:Initializing create_model()
2025-10-10 00:26:07,546:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029AC8C7E750>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029AC90F5AD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-10 00:26:07,546:INFO:Checking exceptions
2025-10-10 00:26:07,546:INFO:Importing libraries
2025-10-10 00:26:07,547:INFO:Copying training dataset
2025-10-10 00:26:07,551:INFO:Defining folds
2025-10-10 00:26:07,551:INFO:Declaring metric variables
2025-10-10 00:26:07,554:INFO:Importing untrained model
2025-10-10 00:26:07,559:INFO:Quadratic Discriminant Analysis Imported successfully
2025-10-10 00:26:07,567:INFO:Starting cross validation
2025-10-10 00:26:07,569:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-10 00:26:07,707:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-10 00:26:07,707:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-10 00:26:07,707:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-10 00:26:07,708:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-10 00:26:07,708:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-10 00:26:07,708:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-10 00:26:07,818:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-10 00:26:07,818:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-10-10 00:26:07,865:INFO:Calculating mean and std
2025-10-10 00:26:07,865:INFO:Creating metrics dataframe
2025-10-10 00:26:07,868:INFO:Uploading results into container
2025-10-10 00:26:07,868:INFO:Uploading model into container now
2025-10-10 00:26:07,869:INFO:_master_model_container: 8
2025-10-10 00:26:07,869:INFO:_display_container: 2
2025-10-10 00:26:07,869:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-10-10 00:26:07,869:INFO:create_model() successfully completed......................................
2025-10-10 00:26:07,947:INFO:SubProcess create_model() end ==================================
2025-10-10 00:26:07,947:INFO:Creating metrics dataframe
2025-10-10 00:26:07,956:INFO:Initializing Ada Boost Classifier
2025-10-10 00:26:07,956:INFO:Total runtime is 0.25140250126520797 minutes
2025-10-10 00:26:07,959:INFO:SubProcess create_model() called ==================================
2025-10-10 00:26:07,959:INFO:Initializing create_model()
2025-10-10 00:26:07,960:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029AC8C7E750>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029AC90F5AD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-10 00:26:07,960:INFO:Checking exceptions
2025-10-10 00:26:07,960:INFO:Importing libraries
2025-10-10 00:26:07,960:INFO:Copying training dataset
2025-10-10 00:26:07,964:INFO:Defining folds
2025-10-10 00:26:07,964:INFO:Declaring metric variables
2025-10-10 00:26:07,967:INFO:Importing untrained model
2025-10-10 00:26:07,971:INFO:Ada Boost Classifier Imported successfully
2025-10-10 00:26:07,978:INFO:Starting cross validation
2025-10-10 00:26:07,980:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-10 00:26:08,090:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-10 00:26:08,090:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-10 00:26:08,090:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-10 00:26:08,090:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-10 00:26:08,090:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-10 00:26:08,097:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-10 00:26:08,347:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-10 00:26:08,352:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-10 00:26:08,369:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-10 00:26:08,555:INFO:Calculating mean and std
2025-10-10 00:26:08,555:INFO:Creating metrics dataframe
2025-10-10 00:26:08,557:INFO:Uploading results into container
2025-10-10 00:26:08,558:INFO:Uploading model into container now
2025-10-10 00:26:08,559:INFO:_master_model_container: 9
2025-10-10 00:26:08,559:INFO:_display_container: 2
2025-10-10 00:26:08,559:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-10-10 00:26:08,560:INFO:create_model() successfully completed......................................
2025-10-10 00:26:08,686:INFO:SubProcess create_model() end ==================================
2025-10-10 00:26:08,686:INFO:Creating metrics dataframe
2025-10-10 00:26:08,701:INFO:Initializing Gradient Boosting Classifier
2025-10-10 00:26:08,701:INFO:Total runtime is 0.26382236480712895 minutes
2025-10-10 00:26:08,705:INFO:SubProcess create_model() called ==================================
2025-10-10 00:26:08,705:INFO:Initializing create_model()
2025-10-10 00:26:08,705:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029AC8C7E750>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029AC90F5AD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-10 00:26:08,706:INFO:Checking exceptions
2025-10-10 00:26:08,706:INFO:Importing libraries
2025-10-10 00:26:08,706:INFO:Copying training dataset
2025-10-10 00:26:08,712:INFO:Defining folds
2025-10-10 00:26:08,713:INFO:Declaring metric variables
2025-10-10 00:26:08,717:INFO:Importing untrained model
2025-10-10 00:26:08,723:INFO:Gradient Boosting Classifier Imported successfully
2025-10-10 00:26:08,743:INFO:Starting cross validation
2025-10-10 00:26:08,747:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-10 00:26:09,561:INFO:Calculating mean and std
2025-10-10 00:26:09,562:INFO:Creating metrics dataframe
2025-10-10 00:26:09,565:INFO:Uploading results into container
2025-10-10 00:26:09,565:INFO:Uploading model into container now
2025-10-10 00:26:09,566:INFO:_master_model_container: 10
2025-10-10 00:26:09,566:INFO:_display_container: 2
2025-10-10 00:26:09,567:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-10 00:26:09,567:INFO:create_model() successfully completed......................................
2025-10-10 00:26:09,658:INFO:SubProcess create_model() end ==================================
2025-10-10 00:26:09,658:INFO:Creating metrics dataframe
2025-10-10 00:26:09,671:INFO:Initializing Linear Discriminant Analysis
2025-10-10 00:26:09,671:INFO:Total runtime is 0.2799907326698304 minutes
2025-10-10 00:26:09,675:INFO:SubProcess create_model() called ==================================
2025-10-10 00:26:09,778:INFO:Initializing create_model()
2025-10-10 00:26:09,779:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029AC8C7E750>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029AC90F5AD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-10 00:26:09,779:INFO:Checking exceptions
2025-10-10 00:26:09,779:INFO:Importing libraries
2025-10-10 00:26:09,779:INFO:Copying training dataset
2025-10-10 00:26:09,784:INFO:Defining folds
2025-10-10 00:26:09,784:INFO:Declaring metric variables
2025-10-10 00:26:09,790:INFO:Importing untrained model
2025-10-10 00:26:09,794:INFO:Linear Discriminant Analysis Imported successfully
2025-10-10 00:26:09,802:INFO:Starting cross validation
2025-10-10 00:26:09,805:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-10 00:26:09,964:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-10 00:26:10,082:INFO:Calculating mean and std
2025-10-10 00:26:10,084:INFO:Creating metrics dataframe
2025-10-10 00:26:10,087:INFO:Uploading results into container
2025-10-10 00:26:10,088:INFO:Uploading model into container now
2025-10-10 00:26:10,089:INFO:_master_model_container: 11
2025-10-10 00:26:10,089:INFO:_display_container: 2
2025-10-10 00:26:10,089:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-10 00:26:10,090:INFO:create_model() successfully completed......................................
2025-10-10 00:26:10,173:INFO:SubProcess create_model() end ==================================
2025-10-10 00:26:10,173:INFO:Creating metrics dataframe
2025-10-10 00:26:10,186:INFO:Initializing Extra Trees Classifier
2025-10-10 00:26:10,186:INFO:Total runtime is 0.28856795231501264 minutes
2025-10-10 00:26:10,189:INFO:SubProcess create_model() called ==================================
2025-10-10 00:26:10,189:INFO:Initializing create_model()
2025-10-10 00:26:10,189:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029AC8C7E750>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029AC90F5AD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-10 00:26:10,189:INFO:Checking exceptions
2025-10-10 00:26:10,189:INFO:Importing libraries
2025-10-10 00:26:10,189:INFO:Copying training dataset
2025-10-10 00:26:10,195:INFO:Defining folds
2025-10-10 00:26:10,195:INFO:Declaring metric variables
2025-10-10 00:26:10,198:INFO:Importing untrained model
2025-10-10 00:26:10,203:INFO:Extra Trees Classifier Imported successfully
2025-10-10 00:26:10,213:INFO:Starting cross validation
2025-10-10 00:26:10,215:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-10 00:26:10,685:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-10 00:26:11,038:INFO:Calculating mean and std
2025-10-10 00:26:11,039:INFO:Creating metrics dataframe
2025-10-10 00:26:11,042:INFO:Uploading results into container
2025-10-10 00:26:11,043:INFO:Uploading model into container now
2025-10-10 00:26:11,043:INFO:_master_model_container: 12
2025-10-10 00:26:11,044:INFO:_display_container: 2
2025-10-10 00:26:11,044:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-10-10 00:26:11,044:INFO:create_model() successfully completed......................................
2025-10-10 00:26:11,129:INFO:SubProcess create_model() end ==================================
2025-10-10 00:26:11,130:INFO:Creating metrics dataframe
2025-10-10 00:26:11,139:INFO:Initializing Light Gradient Boosting Machine
2025-10-10 00:26:11,139:INFO:Total runtime is 0.3044646581013998 minutes
2025-10-10 00:26:11,142:INFO:SubProcess create_model() called ==================================
2025-10-10 00:26:11,143:INFO:Initializing create_model()
2025-10-10 00:26:11,143:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029AC8C7E750>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029AC90F5AD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-10 00:26:11,143:INFO:Checking exceptions
2025-10-10 00:26:11,143:INFO:Importing libraries
2025-10-10 00:26:11,143:INFO:Copying training dataset
2025-10-10 00:26:11,147:INFO:Defining folds
2025-10-10 00:26:11,147:INFO:Declaring metric variables
2025-10-10 00:26:11,150:INFO:Importing untrained model
2025-10-10 00:26:11,160:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-10 00:26:11,177:INFO:Starting cross validation
2025-10-10 00:26:11,179:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-10 00:26:11,742:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-10 00:26:11,865:INFO:Calculating mean and std
2025-10-10 00:26:11,867:INFO:Creating metrics dataframe
2025-10-10 00:26:11,869:INFO:Uploading results into container
2025-10-10 00:26:11,870:INFO:Uploading model into container now
2025-10-10 00:26:11,871:INFO:_master_model_container: 13
2025-10-10 00:26:11,872:INFO:_display_container: 2
2025-10-10 00:26:11,872:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-10 00:26:11,873:INFO:create_model() successfully completed......................................
2025-10-10 00:26:12,046:INFO:SubProcess create_model() end ==================================
2025-10-10 00:26:12,046:INFO:Creating metrics dataframe
2025-10-10 00:26:12,055:INFO:Initializing Dummy Classifier
2025-10-10 00:26:12,055:INFO:Total runtime is 0.3197215835253398 minutes
2025-10-10 00:26:12,059:INFO:SubProcess create_model() called ==================================
2025-10-10 00:26:12,059:INFO:Initializing create_model()
2025-10-10 00:26:12,059:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029AC8C7E750>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029AC90F5AD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-10 00:26:12,059:INFO:Checking exceptions
2025-10-10 00:26:12,059:INFO:Importing libraries
2025-10-10 00:26:12,059:INFO:Copying training dataset
2025-10-10 00:26:12,063:INFO:Defining folds
2025-10-10 00:26:12,064:INFO:Declaring metric variables
2025-10-10 00:26:12,068:INFO:Importing untrained model
2025-10-10 00:26:12,071:INFO:Dummy Classifier Imported successfully
2025-10-10 00:26:12,078:INFO:Starting cross validation
2025-10-10 00:26:12,080:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-10 00:26:12,210:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-10 00:26:12,214:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-10 00:26:12,219:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-10 00:26:12,222:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-10 00:26:12,227:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-10 00:26:12,236:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-10 00:26:12,240:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-10 00:26:12,268:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-10 00:26:12,297:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-10 00:26:12,303:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-10 00:26:12,311:INFO:Calculating mean and std
2025-10-10 00:26:12,312:INFO:Creating metrics dataframe
2025-10-10 00:26:12,314:INFO:Uploading results into container
2025-10-10 00:26:12,315:INFO:Uploading model into container now
2025-10-10 00:26:12,316:INFO:_master_model_container: 14
2025-10-10 00:26:12,316:INFO:_display_container: 2
2025-10-10 00:26:12,316:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-10-10 00:26:12,316:INFO:create_model() successfully completed......................................
2025-10-10 00:26:12,410:INFO:SubProcess create_model() end ==================================
2025-10-10 00:26:12,410:INFO:Creating metrics dataframe
2025-10-10 00:26:12,425:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-10-10 00:26:12,437:INFO:Initializing create_model()
2025-10-10 00:26:12,437:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029AC8C7E750>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-10 00:26:12,437:INFO:Checking exceptions
2025-10-10 00:26:12,440:INFO:Importing libraries
2025-10-10 00:26:12,440:INFO:Copying training dataset
2025-10-10 00:26:12,446:INFO:Defining folds
2025-10-10 00:26:12,446:INFO:Declaring metric variables
2025-10-10 00:26:12,447:INFO:Importing untrained model
2025-10-10 00:26:12,447:INFO:Declaring custom model
2025-10-10 00:26:12,448:INFO:Ridge Classifier Imported successfully
2025-10-10 00:26:12,449:INFO:Cross validation set to False
2025-10-10 00:26:12,449:INFO:Fitting Model
2025-10-10 00:26:12,499:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-10-10 00:26:12,499:INFO:create_model() successfully completed......................................
2025-10-10 00:26:12,602:INFO:_master_model_container: 14
2025-10-10 00:26:12,603:INFO:_display_container: 2
2025-10-10 00:26:12,603:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-10-10 00:26:12,603:INFO:compare_models() successfully completed......................................
2025-10-10 00:31:36,441:INFO:Initializing create_model()
2025-10-10 00:31:36,441:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029AC8C7E750>, estimator=nb, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-10 00:31:36,441:INFO:Checking exceptions
2025-10-10 00:31:36,461:INFO:Importing libraries
2025-10-10 00:31:36,461:INFO:Copying training dataset
2025-10-10 00:31:36,465:INFO:Defining folds
2025-10-10 00:31:36,465:INFO:Declaring metric variables
2025-10-10 00:31:36,471:INFO:Importing untrained model
2025-10-10 00:31:36,476:INFO:Naive Bayes Imported successfully
2025-10-10 00:31:36,486:INFO:Starting cross validation
2025-10-10 00:31:36,489:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-10 00:31:54,885:INFO:Calculating mean and std
2025-10-10 00:31:54,888:INFO:Creating metrics dataframe
2025-10-10 00:31:54,897:INFO:Finalizing model
2025-10-10 00:31:54,963:INFO:Uploading results into container
2025-10-10 00:31:54,964:INFO:Uploading model into container now
2025-10-10 00:31:54,978:INFO:_master_model_container: 15
2025-10-10 00:31:54,978:INFO:_display_container: 3
2025-10-10 00:31:54,979:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-10-10 00:31:54,979:INFO:create_model() successfully completed......................................
2025-10-10 00:32:09,904:INFO:Initializing tune_model()
2025-10-10 00:32:09,904:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029AC8C7E750>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-10-10 00:32:09,904:INFO:Checking exceptions
2025-10-10 00:32:09,926:INFO:Copying training dataset
2025-10-10 00:32:09,931:INFO:Checking base model
2025-10-10 00:32:09,931:INFO:Base model : Naive Bayes
2025-10-10 00:32:09,936:INFO:Declaring metric variables
2025-10-10 00:32:09,942:INFO:Defining Hyperparameters
2025-10-10 00:32:10,103:INFO:Tuning with n_jobs=-1
2025-10-10 00:32:10,105:INFO:Initializing RandomizedSearchCV
2025-10-10 00:32:12,331:INFO:best_params: {'actual_estimator__var_smoothing': 1}
2025-10-10 00:32:12,332:INFO:Hyperparameter search completed
2025-10-10 00:32:12,332:INFO:SubProcess create_model() called ==================================
2025-10-10 00:32:12,332:INFO:Initializing create_model()
2025-10-10 00:32:12,333:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029AC8C7E750>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029AC841D210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'var_smoothing': 1})
2025-10-10 00:32:12,333:INFO:Checking exceptions
2025-10-10 00:32:12,333:INFO:Importing libraries
2025-10-10 00:32:12,333:INFO:Copying training dataset
2025-10-10 00:32:12,339:INFO:Defining folds
2025-10-10 00:32:12,339:INFO:Declaring metric variables
2025-10-10 00:32:12,344:INFO:Importing untrained model
2025-10-10 00:32:12,344:INFO:Declaring custom model
2025-10-10 00:32:12,349:INFO:Naive Bayes Imported successfully
2025-10-10 00:32:12,358:INFO:Starting cross validation
2025-10-10 00:32:12,360:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-10 00:32:12,552:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-10 00:32:12,552:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-10 00:32:12,552:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-10 00:32:12,553:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-10 00:32:12,560:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-10 00:32:12,650:INFO:Calculating mean and std
2025-10-10 00:32:12,651:INFO:Creating metrics dataframe
2025-10-10 00:32:12,655:INFO:Finalizing model
2025-10-10 00:32:12,707:INFO:Uploading results into container
2025-10-10 00:32:12,708:INFO:Uploading model into container now
2025-10-10 00:32:12,708:INFO:_master_model_container: 16
2025-10-10 00:32:12,709:INFO:_display_container: 4
2025-10-10 00:32:12,709:INFO:GaussianNB(priors=None, var_smoothing=1)
2025-10-10 00:32:12,709:INFO:create_model() successfully completed......................................
2025-10-10 00:32:12,801:INFO:SubProcess create_model() end ==================================
2025-10-10 00:32:12,801:INFO:choose_better activated
2025-10-10 00:32:12,804:INFO:SubProcess create_model() called ==================================
2025-10-10 00:32:12,804:INFO:Initializing create_model()
2025-10-10 00:32:12,804:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029AC8C7E750>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-10 00:32:12,804:INFO:Checking exceptions
2025-10-10 00:32:12,806:INFO:Importing libraries
2025-10-10 00:32:12,807:INFO:Copying training dataset
2025-10-10 00:32:12,810:INFO:Defining folds
2025-10-10 00:32:12,810:INFO:Declaring metric variables
2025-10-10 00:32:12,810:INFO:Importing untrained model
2025-10-10 00:32:12,810:INFO:Declaring custom model
2025-10-10 00:32:12,810:INFO:Naive Bayes Imported successfully
2025-10-10 00:32:12,810:INFO:Starting cross validation
2025-10-10 00:32:12,812:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-10 00:32:13,111:INFO:Calculating mean and std
2025-10-10 00:32:13,111:INFO:Creating metrics dataframe
2025-10-10 00:32:13,113:INFO:Finalizing model
2025-10-10 00:32:13,182:INFO:Uploading results into container
2025-10-10 00:32:13,183:INFO:Uploading model into container now
2025-10-10 00:32:13,183:INFO:_master_model_container: 17
2025-10-10 00:32:13,183:INFO:_display_container: 5
2025-10-10 00:32:13,183:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-10-10 00:32:13,183:INFO:create_model() successfully completed......................................
2025-10-10 00:32:13,259:INFO:SubProcess create_model() end ==================================
2025-10-10 00:32:13,260:INFO:GaussianNB(priors=None, var_smoothing=1e-09) result for Accuracy is 0.7
2025-10-10 00:32:13,260:INFO:GaussianNB(priors=None, var_smoothing=1) result for Accuracy is 0.7238
2025-10-10 00:32:13,260:INFO:GaussianNB(priors=None, var_smoothing=1) is best model
2025-10-10 00:32:13,260:INFO:choose_better completed
2025-10-10 00:32:13,269:INFO:_master_model_container: 17
2025-10-10 00:32:13,270:INFO:_display_container: 4
2025-10-10 00:32:13,270:INFO:GaussianNB(priors=None, var_smoothing=1)
2025-10-10 00:32:13,270:INFO:tune_model() successfully completed......................................
2025-10-10 00:32:35,547:INFO:Initializing evaluate_model()
2025-10-10 00:32:35,547:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029AC8C7E750>, estimator=GaussianNB(priors=None, var_smoothing=1), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-10-10 00:32:35,557:INFO:Initializing plot_model()
2025-10-10 00:32:35,557:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029AC8C7E750>, estimator=GaussianNB(priors=None, var_smoothing=1), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-10 00:32:35,557:INFO:Checking exceptions
2025-10-10 00:32:35,559:INFO:Preloading libraries
2025-10-10 00:32:35,559:INFO:Copying training dataset
2025-10-10 00:32:35,559:INFO:Plot type: pipeline
2025-10-10 00:32:35,854:INFO:Visual Rendered Successfully
2025-10-10 00:32:35,964:INFO:plot_model() successfully completed......................................
2025-10-10 00:32:40,068:INFO:Initializing plot_model()
2025-10-10 00:32:40,068:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029AC8C7E750>, estimator=GaussianNB(priors=None, var_smoothing=1), plot=parameter, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-10 00:32:40,068:INFO:Checking exceptions
2025-10-10 00:32:40,071:INFO:Preloading libraries
2025-10-10 00:32:40,072:INFO:Copying training dataset
2025-10-10 00:32:40,072:INFO:Plot type: parameter
2025-10-10 00:32:40,075:INFO:Visual Rendered Successfully
2025-10-10 00:32:40,165:INFO:plot_model() successfully completed......................................
2025-10-10 00:32:40,786:INFO:Initializing plot_model()
2025-10-10 00:32:40,786:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029AC8C7E750>, estimator=GaussianNB(priors=None, var_smoothing=1), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-10 00:32:40,786:INFO:Checking exceptions
2025-10-10 00:32:40,788:INFO:Preloading libraries
2025-10-10 00:32:40,789:INFO:Copying training dataset
2025-10-10 00:32:40,789:INFO:Plot type: pipeline
2025-10-10 00:32:40,901:INFO:Visual Rendered Successfully
2025-10-10 00:32:41,079:INFO:plot_model() successfully completed......................................
2025-10-10 00:32:41,460:INFO:Initializing plot_model()
2025-10-10 00:32:41,460:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029AC8C7E750>, estimator=GaussianNB(priors=None, var_smoothing=1), plot=parameter, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-10 00:32:41,461:INFO:Checking exceptions
2025-10-10 00:32:41,462:INFO:Preloading libraries
2025-10-10 00:32:41,462:INFO:Copying training dataset
2025-10-10 00:32:41,462:INFO:Plot type: parameter
2025-10-10 00:32:41,465:INFO:Visual Rendered Successfully
2025-10-10 00:32:41,543:INFO:plot_model() successfully completed......................................
2025-10-10 00:32:42,122:INFO:Initializing plot_model()
2025-10-10 00:32:42,122:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029AC8C7E750>, estimator=GaussianNB(priors=None, var_smoothing=1), plot=auc, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-10 00:32:42,122:INFO:Checking exceptions
2025-10-10 00:32:42,124:INFO:Preloading libraries
2025-10-10 00:32:42,125:INFO:Copying training dataset
2025-10-10 00:32:42,125:INFO:Plot type: auc
2025-10-10 00:32:42,290:INFO:Fitting Model
2025-10-10 00:32:42,303:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GaussianNB was fitted with feature names
  warnings.warn(

2025-10-10 00:32:42,304:INFO:Scoring test/hold-out set
2025-10-10 00:32:42,468:INFO:Visual Rendered Successfully
2025-10-10 00:32:42,534:INFO:plot_model() successfully completed......................................
2025-10-10 00:32:49,675:INFO:Initializing plot_model()
2025-10-10 00:32:49,676:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029AC8C7E750>, estimator=GaussianNB(priors=None, var_smoothing=1), plot=rfe, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-10 00:32:49,676:INFO:Checking exceptions
2025-10-10 00:32:53,758:INFO:Initializing plot_model()
2025-10-10 00:32:53,758:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029AC8C7E750>, estimator=GaussianNB(priors=None, var_smoothing=1), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-10 00:32:53,758:INFO:Checking exceptions
2025-10-10 00:32:53,760:INFO:Preloading libraries
2025-10-10 00:32:53,761:INFO:Copying training dataset
2025-10-10 00:32:53,761:INFO:Plot type: pipeline
2025-10-10 00:32:53,876:INFO:Visual Rendered Successfully
2025-10-10 00:32:54,004:INFO:plot_model() successfully completed......................................
2025-10-10 00:32:55,012:INFO:Initializing plot_model()
2025-10-10 00:32:55,012:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029AC8C7E750>, estimator=GaussianNB(priors=None, var_smoothing=1), plot=auc, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-10 00:32:55,013:INFO:Checking exceptions
2025-10-10 00:32:55,014:INFO:Preloading libraries
2025-10-10 00:32:55,015:INFO:Copying training dataset
2025-10-10 00:32:55,015:INFO:Plot type: auc
2025-10-10 00:32:55,197:INFO:Fitting Model
2025-10-10 00:32:55,197:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GaussianNB was fitted with feature names
  warnings.warn(

2025-10-10 00:32:55,198:INFO:Scoring test/hold-out set
2025-10-10 00:32:55,410:INFO:Visual Rendered Successfully
2025-10-10 00:32:55,496:INFO:plot_model() successfully completed......................................
2025-10-10 00:32:56,042:INFO:Initializing plot_model()
2025-10-10 00:32:56,043:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029AC8C7E750>, estimator=GaussianNB(priors=None, var_smoothing=1), plot=confusion_matrix, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-10-10 00:32:56,043:INFO:Checking exceptions
2025-10-10 00:32:56,044:INFO:Preloading libraries
2025-10-10 00:32:56,044:INFO:Copying training dataset
2025-10-10 00:32:56,044:INFO:Plot type: confusion_matrix
2025-10-10 00:32:56,196:INFO:Fitting Model
2025-10-10 00:32:56,197:WARNING:c:\Users\jjqs_\AppData\Local\Programs\Python\Python311\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GaussianNB was fitted with feature names
  warnings.warn(

2025-10-10 00:32:56,197:INFO:Scoring test/hold-out set
2025-10-10 00:32:56,306:INFO:Visual Rendered Successfully
2025-10-10 00:32:56,384:INFO:plot_model() successfully completed......................................
